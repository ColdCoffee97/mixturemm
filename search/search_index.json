{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to mixturemm \u00b6 A python package for large-scale simulation and analysis of molecule mixtures, espacially solvents, in openMM on high performance clusters. Ideal for solvent parameter studies \u00b6 Automated simulation setup \u00b6 covers wished parameter space for temperature, pressure and dilutions with water creates predefined folder structure packs simulation boxes (by packmol ) stores short project description with metadata and input parameters as JSON Simulation \u00b6 with the fast simulation engine OpenMM NpT to NVT to NVE ensemble according to simulation Best Practices semi-automated job submission to High Performance Computing Centers via SLURM Analyses \u00b6 density self-diffusion-coefficients as well as finite size corrected self-diffusion-coefficient viscosity hydrogen bonds outputted as JSON Free sofware under the MIT license.","title":"Home"},{"location":"#welcome-to-mixturemm","text":"A python package for large-scale simulation and analysis of molecule mixtures, espacially solvents, in openMM on high performance clusters.","title":"Welcome to mixturemm"},{"location":"#ideal-for-solvent-parameter-studies","text":"","title":"Ideal for solvent parameter studies"},{"location":"#automated-simulation-setup","text":"covers wished parameter space for temperature, pressure and dilutions with water creates predefined folder structure packs simulation boxes (by packmol ) stores short project description with metadata and input parameters as JSON","title":"Automated simulation setup"},{"location":"#simulation","text":"with the fast simulation engine OpenMM NpT to NVT to NVE ensemble according to simulation Best Practices semi-automated job submission to High Performance Computing Centers via SLURM","title":"Simulation"},{"location":"#analyses","text":"density self-diffusion-coefficients as well as finite size corrected self-diffusion-coefficient viscosity hydrogen bonds outputted as JSON Free sofware under the MIT license.","title":"Analyses"},{"location":"background/","text":"background \u00b6 Module with indirectly used classes. MIT License Copyright (c) 2021, Benjamin Schmitz Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Replica \u00b6 Source code in mixturemm/background.py 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 class Replica : def __init__ ( self , Project , Simulationsystem , replica_number ): \"\"\"The replica of a simulationsystem contains the parameters for the NVT equilibration and the NVE production. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Simulationsystem (object): The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. replica_number (int): The number assigned to this replica. \"\"\" self . folder = f ' { Simulationsystem . folder } /replica_ { replica_number } ' directory_maker ( self . folder ) self . npt_equilibration_subfolder = Simulationsystem . npt_equilibration_subfolder self . name = Simulationsystem . name self . simulationbox_path = Simulationsystem . simulationbox_path self . replica_number = replica_number self . chi_water = Simulationsystem . chi_water self . temperature = Simulationsystem . temperature self . pressure = Simulationsystem . pressure self . total_number_molecules = Simulationsystem . total_number_molecules self . simulationbox_name = Simulationsystem . simulationbox_name self . nvt_equilibration_temperature_coupling_frequency = Project . nvt_equilibration_temperature_coupling_frequency self . nvt_equilibration_timestep_fs = Project . nvt_equilibration_timestep_fs self . nvt_equilibration_duration_ns = Project . nvt_equilibration_duration_ns self . nve_production_timestep_fs = Project . nve_production_timestep_fs self . nve_production_duration_ns = Project . nve_production_duration_ns self . reporting_frequency_coordinates_unwrapped = Project . reporting_frequency_coordinates_unwrapped self . reporting_frequency_coordinates_wrapped = Project . reporting_frequency_coordinates_wrapped self . reporting_frequency_state_nvt_equilibration = Project . reporting_frequency_state_nvt_equilibration self . reporting_frequency_state_nve_production = Project . reporting_frequency_state_nve_production self . cutoff_distance_nm = Project . cutoff_distance_nm self . cutoff_switch_distance_nm = Project . cutoff_switch_distance_nm self . simulation_platform = Project . simulation_platform self . half_npt_equilibration_csv_columns = Project . half_npt_equilibration_csv_columns self . forcefields = Project . forcefields self . nvt_equilibration_steps = int (( self . nvt_equilibration_duration_ns / self . nvt_equilibration_timestep_fs ) * ( 10 ** 6 )) self . nve_production_steps = int (( self . nve_production_duration_ns / self . nve_production_timestep_fs ) * ( 10 ** 6 )) self . openmm_forcefield = ForceField ( * self . forcefields ) self . openmm_platform = Platform . getPlatformByName ( f ' { self . simulation_platform } ' ) self . openmm_properties = Project . simulation_properties self . pme_error_tolerance = Project . pme_error_tolerance self . constraint_tolerance = Project . constraint_tolerance def nvt_equilibration ( self ): \"\"\"Runs a NVT equilibration of the system. \"\"\" folder = self . folder npt_equilibration_subfolder = self . npt_equilibration_subfolder npt_equilibration_state = f ' { npt_equilibration_subfolder } /npt_equilibration_state.xml' npt_equilibration_end_simulationbox = f ' { npt_equilibration_subfolder } /npt_equilibration_end.pdb' openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm temperature = self . temperature openmm_forcefield = self . openmm_forcefield nvt_equilibration_temperature_coupling_frequency = self . nvt_equilibration_temperature_coupling_frequency nvt_equilibration_timestep_ps = self . nvt_equilibration_timestep_fs * ( 10 ** ( - 3 )) nvt_equilibration_steps = self . nvt_equilibration_steps half_npt_equilibration_csv_columns = self . half_npt_equilibration_csv_columns reporting_frequency_state_nvt_equilibration = self . reporting_frequency_state_nvt_equilibration constraint_tolerance = self . constraint_tolerance topology_nvt_equilibration = PDBFile ( f ' { npt_equilibration_end_simulationbox } ' ) system_nvt_equilibration = openmm_forcefield . createSystem ( topology_nvt_equilibration . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_nvt_equilibration = LangevinMiddleIntegrator ( temperature * kelvin , nvt_equilibration_temperature_coupling_frequency / picosecond , nvt_equilibration_timestep_ps * picoseconds ) integrator_nvt_equilibration . setConstraintTolerance ( constraint_tolerance ) simulation_nvt_equilibration = Simulation ( topology_nvt_equilibration . topology , system_nvt_equilibration , integrator_nvt_equilibration , openmm_platform , openmm_properties , state = npt_equilibration_state ) npt_equilibration_df = pd . read_csv ( f ' { npt_equilibration_subfolder } /npt_equilibration.csv' ) half_npt_equilibration_df = npt_equilibration_df . tail ( n = half_npt_equilibration_csv_columns ) volume_npt_equilibration = half_npt_equilibration_df . loc [:, 'Box Volume (nm^3)' ] average_volume_npt_equilibration = volume_npt_equilibration . mean () estimated_new_side_length = ( average_volume_npt_equilibration ** ( 1 / 3 )) positions = simulation_nvt_equilibration . context . getState ( getPositions = True ) . getPositions () simulation_nvt_equilibration . context . reinitialize () simulation_nvt_equilibration . context . setPositions ( positions ) simulation_nvt_equilibration . context . setPeriodicBoxVectors ( Vec3 ( x = estimated_new_side_length , y = 0.0 , z = 0.0 ), Vec3 ( x = 0.0 , y = estimated_new_side_length , z = 0.0 ), Vec3 ( x = 0.0 , y = 0.0 , z = estimated_new_side_length )) simulation_nvt_equilibration . minimizeEnergy ( tolerance = 0.1 * kilojoule / mole , maxIterations = 500000 ) simulation_nvt_equilibration . context . setVelocitiesToTemperature ( temperature * kelvin ) simulation_nvt_equilibration . reporters . append ( StateDataReporter ( f ' { folder } /nvt_equilibration.csv' , reporting_frequency_state_nvt_equilibration , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) simulation_nvt_equilibration . step ( nvt_equilibration_steps ) simulation_nvt_equilibration . saveState ( f ' { folder } /nvt_equilibration_state.xml' ) endpositions_nvt_equilibration = simulation_nvt_equilibration . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_nvt_equilibration . topology , endpositions_nvt_equilibration , open ( f ' { folder } /nvt_equilibration_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /nvt_equilibration.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /nvt_equilibration.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /nvt_equilibration.png' , dpi = 300 ) def nve_production ( self ): \"\"\"Runs a NVE production of the system during which two trajectories are written, one with unwrapped and one with wrapped coordinates. \"\"\" folder = self . folder nvt_equilibration_state = f ' { folder } /nvt_equilibration_state.xml' nvt_equilibration_end_simulationbox = f ' { folder } /nvt_equilibration_end.pdb' openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm openmm_forcefield = self . openmm_forcefield production_timestep_ps = self . nve_production_timestep_fs * ( 10 ** ( - 3 )) production_steps = self . nve_production_steps reporting_frequency_coordinates_unwrapped = self . reporting_frequency_coordinates_unwrapped reporting_frequency_coordinates_wrapped = self . reporting_frequency_coordinates_wrapped reporting_frequency_state_nve_production = self . reporting_frequency_state_nve_production constraint_tolerance = self . constraint_tolerance topology_nve_production = PDBFile ( f ' { nvt_equilibration_end_simulationbox } ' ) system_nve_production = openmm_forcefield . createSystem ( topology_nve_production . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_nve_production = VerletIntegrator ( production_timestep_ps * picoseconds ) integrator_nve_production . setConstraintTolerance ( constraint_tolerance ) simulation_nve_production = Simulation ( topology_nve_production . topology , system_nve_production , integrator_nve_production , openmm_platform , openmm_properties , state = nvt_equilibration_state ) simulation_nve_production . reporters . append ( StateDataReporter ( f ' { folder } /nve_production.csv' , reporting_frequency_state_nve_production , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) simulation_nve_production . reporters . append ( DCDReporter ( f ' { folder } /nve_production_unwrapped.dcd' , reporting_frequency_coordinates_unwrapped , enforcePeriodicBox = False )) simulation_nve_production . reporters . append ( DCDReporter ( f ' { folder } /nve_production_wrapped.dcd' , reporting_frequency_coordinates_wrapped )) simulation_nve_production . step ( production_steps ) simulation_nve_production . saveState ( f ' { folder } /nve_production_state.xml' ) endpositions_nve_production = simulation_nve_production . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_nve_production . topology , endpositions_nve_production , open ( f ' { folder } /nve_production_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /nve_production.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /nve_production.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /nve_production.png' , dpi = 300 ) __init__ ( Project , Simulationsystem , replica_number ) \u00b6 The replica of a simulationsystem contains the parameters for the NVT equilibration and the NVE production. Parameters: Name Type Description Default Project object The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. required Simulationsystem object The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. required replica_number int The number assigned to this replica. required Source code in mixturemm/background.py 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def __init__ ( self , Project , Simulationsystem , replica_number ): \"\"\"The replica of a simulationsystem contains the parameters for the NVT equilibration and the NVE production. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Simulationsystem (object): The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. replica_number (int): The number assigned to this replica. \"\"\" self . folder = f ' { Simulationsystem . folder } /replica_ { replica_number } ' directory_maker ( self . folder ) self . npt_equilibration_subfolder = Simulationsystem . npt_equilibration_subfolder self . name = Simulationsystem . name self . simulationbox_path = Simulationsystem . simulationbox_path self . replica_number = replica_number self . chi_water = Simulationsystem . chi_water self . temperature = Simulationsystem . temperature self . pressure = Simulationsystem . pressure self . total_number_molecules = Simulationsystem . total_number_molecules self . simulationbox_name = Simulationsystem . simulationbox_name self . nvt_equilibration_temperature_coupling_frequency = Project . nvt_equilibration_temperature_coupling_frequency self . nvt_equilibration_timestep_fs = Project . nvt_equilibration_timestep_fs self . nvt_equilibration_duration_ns = Project . nvt_equilibration_duration_ns self . nve_production_timestep_fs = Project . nve_production_timestep_fs self . nve_production_duration_ns = Project . nve_production_duration_ns self . reporting_frequency_coordinates_unwrapped = Project . reporting_frequency_coordinates_unwrapped self . reporting_frequency_coordinates_wrapped = Project . reporting_frequency_coordinates_wrapped self . reporting_frequency_state_nvt_equilibration = Project . reporting_frequency_state_nvt_equilibration self . reporting_frequency_state_nve_production = Project . reporting_frequency_state_nve_production self . cutoff_distance_nm = Project . cutoff_distance_nm self . cutoff_switch_distance_nm = Project . cutoff_switch_distance_nm self . simulation_platform = Project . simulation_platform self . half_npt_equilibration_csv_columns = Project . half_npt_equilibration_csv_columns self . forcefields = Project . forcefields self . nvt_equilibration_steps = int (( self . nvt_equilibration_duration_ns / self . nvt_equilibration_timestep_fs ) * ( 10 ** 6 )) self . nve_production_steps = int (( self . nve_production_duration_ns / self . nve_production_timestep_fs ) * ( 10 ** 6 )) self . openmm_forcefield = ForceField ( * self . forcefields ) self . openmm_platform = Platform . getPlatformByName ( f ' { self . simulation_platform } ' ) self . openmm_properties = Project . simulation_properties self . pme_error_tolerance = Project . pme_error_tolerance self . constraint_tolerance = Project . constraint_tolerance nve_production () \u00b6 Runs a NVE production of the system during which two trajectories are written, one with unwrapped and one with wrapped coordinates. Source code in mixturemm/background.py 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 def nve_production ( self ): \"\"\"Runs a NVE production of the system during which two trajectories are written, one with unwrapped and one with wrapped coordinates. \"\"\" folder = self . folder nvt_equilibration_state = f ' { folder } /nvt_equilibration_state.xml' nvt_equilibration_end_simulationbox = f ' { folder } /nvt_equilibration_end.pdb' openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm openmm_forcefield = self . openmm_forcefield production_timestep_ps = self . nve_production_timestep_fs * ( 10 ** ( - 3 )) production_steps = self . nve_production_steps reporting_frequency_coordinates_unwrapped = self . reporting_frequency_coordinates_unwrapped reporting_frequency_coordinates_wrapped = self . reporting_frequency_coordinates_wrapped reporting_frequency_state_nve_production = self . reporting_frequency_state_nve_production constraint_tolerance = self . constraint_tolerance topology_nve_production = PDBFile ( f ' { nvt_equilibration_end_simulationbox } ' ) system_nve_production = openmm_forcefield . createSystem ( topology_nve_production . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_nve_production = VerletIntegrator ( production_timestep_ps * picoseconds ) integrator_nve_production . setConstraintTolerance ( constraint_tolerance ) simulation_nve_production = Simulation ( topology_nve_production . topology , system_nve_production , integrator_nve_production , openmm_platform , openmm_properties , state = nvt_equilibration_state ) simulation_nve_production . reporters . append ( StateDataReporter ( f ' { folder } /nve_production.csv' , reporting_frequency_state_nve_production , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) simulation_nve_production . reporters . append ( DCDReporter ( f ' { folder } /nve_production_unwrapped.dcd' , reporting_frequency_coordinates_unwrapped , enforcePeriodicBox = False )) simulation_nve_production . reporters . append ( DCDReporter ( f ' { folder } /nve_production_wrapped.dcd' , reporting_frequency_coordinates_wrapped )) simulation_nve_production . step ( production_steps ) simulation_nve_production . saveState ( f ' { folder } /nve_production_state.xml' ) endpositions_nve_production = simulation_nve_production . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_nve_production . topology , endpositions_nve_production , open ( f ' { folder } /nve_production_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /nve_production.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /nve_production.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /nve_production.png' , dpi = 300 ) nvt_equilibration () \u00b6 Runs a NVT equilibration of the system. Source code in mixturemm/background.py 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 def nvt_equilibration ( self ): \"\"\"Runs a NVT equilibration of the system. \"\"\" folder = self . folder npt_equilibration_subfolder = self . npt_equilibration_subfolder npt_equilibration_state = f ' { npt_equilibration_subfolder } /npt_equilibration_state.xml' npt_equilibration_end_simulationbox = f ' { npt_equilibration_subfolder } /npt_equilibration_end.pdb' openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm temperature = self . temperature openmm_forcefield = self . openmm_forcefield nvt_equilibration_temperature_coupling_frequency = self . nvt_equilibration_temperature_coupling_frequency nvt_equilibration_timestep_ps = self . nvt_equilibration_timestep_fs * ( 10 ** ( - 3 )) nvt_equilibration_steps = self . nvt_equilibration_steps half_npt_equilibration_csv_columns = self . half_npt_equilibration_csv_columns reporting_frequency_state_nvt_equilibration = self . reporting_frequency_state_nvt_equilibration constraint_tolerance = self . constraint_tolerance topology_nvt_equilibration = PDBFile ( f ' { npt_equilibration_end_simulationbox } ' ) system_nvt_equilibration = openmm_forcefield . createSystem ( topology_nvt_equilibration . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_nvt_equilibration = LangevinMiddleIntegrator ( temperature * kelvin , nvt_equilibration_temperature_coupling_frequency / picosecond , nvt_equilibration_timestep_ps * picoseconds ) integrator_nvt_equilibration . setConstraintTolerance ( constraint_tolerance ) simulation_nvt_equilibration = Simulation ( topology_nvt_equilibration . topology , system_nvt_equilibration , integrator_nvt_equilibration , openmm_platform , openmm_properties , state = npt_equilibration_state ) npt_equilibration_df = pd . read_csv ( f ' { npt_equilibration_subfolder } /npt_equilibration.csv' ) half_npt_equilibration_df = npt_equilibration_df . tail ( n = half_npt_equilibration_csv_columns ) volume_npt_equilibration = half_npt_equilibration_df . loc [:, 'Box Volume (nm^3)' ] average_volume_npt_equilibration = volume_npt_equilibration . mean () estimated_new_side_length = ( average_volume_npt_equilibration ** ( 1 / 3 )) positions = simulation_nvt_equilibration . context . getState ( getPositions = True ) . getPositions () simulation_nvt_equilibration . context . reinitialize () simulation_nvt_equilibration . context . setPositions ( positions ) simulation_nvt_equilibration . context . setPeriodicBoxVectors ( Vec3 ( x = estimated_new_side_length , y = 0.0 , z = 0.0 ), Vec3 ( x = 0.0 , y = estimated_new_side_length , z = 0.0 ), Vec3 ( x = 0.0 , y = 0.0 , z = estimated_new_side_length )) simulation_nvt_equilibration . minimizeEnergy ( tolerance = 0.1 * kilojoule / mole , maxIterations = 500000 ) simulation_nvt_equilibration . context . setVelocitiesToTemperature ( temperature * kelvin ) simulation_nvt_equilibration . reporters . append ( StateDataReporter ( f ' { folder } /nvt_equilibration.csv' , reporting_frequency_state_nvt_equilibration , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) simulation_nvt_equilibration . step ( nvt_equilibration_steps ) simulation_nvt_equilibration . saveState ( f ' { folder } /nvt_equilibration_state.xml' ) endpositions_nvt_equilibration = simulation_nvt_equilibration . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_nvt_equilibration . topology , endpositions_nvt_equilibration , open ( f ' { folder } /nvt_equilibration_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /nvt_equilibration.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /nvt_equilibration.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /nvt_equilibration.png' , dpi = 300 ) Simulationbox \u00b6 Source code in mixturemm/background.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 class Simulationbox : def __init__ ( self , Project , total_number_molecules , init_box_side_length , chi_water , water_name , mixture_name ): \"\"\"The simulationbox contains all information that is needed to pack each simulation box in packmol. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. total_number_molecules (int): A list with the number of molecules that should be placed in the simulation box. init_box_side_length (int): The initial box side length that should be used by packmol. chi_water (flot): The molar fraction of water of this simulation box. water_name (str): The name that was assigned to the water molecule. mixture_name (str): The name created from a tuple of total_number_molecules, init_box_side_length and chi_water. \"\"\" self . boxdir = Project . boxdir self . moldir = Project . moldir self . molecule_names = Project . molecule_names self . molecule_number_of_atoms = Project . molecule_number_of_atoms self . mixture_dict = Project . mixture_dict self . total_number_molecules = total_number_molecules self . init_box_side_length = init_box_side_length self . chi_water = chi_water self . water_name = water_name self . mixture_name = mixture_name self . path = f ' { self . boxdir } /mixture_ { mixture_name } .pdb' self . skip_bonds = False def pack ( self ): \"\"\"Creates an input file for packmol with the initial box side length and the exact number of each involved molecule and runs packmol with it. \"\"\" if os . path . isfile ( f ' { self . path } ' ): self . skip_bonds = True else : mixture_name = self . mixture_name operating_folder = self . boxdir moldir = self . moldir molecule_number_of_atoms = self . molecule_number_of_atoms total_number_molecules = int ( self . total_number_molecules ) init_box_side_length = int ( self . init_box_side_length ) mixture_dict = self . mixture_dict molecule_type_beginning_count = [ 0 ] COUNTER = 0 chi_water = float ( self . chi_water ) water_number_molecules_ = chi_water * total_number_molecules water_number_molecules = int ( water_number_molecules_ ) remaining_number_molecules = total_number_molecules - water_number_molecules with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'w' ) as file : file . write ( f 'tolerance 2.0 \\n filetype pdb \\n output { operating_folder } /mixture_ { mixture_name } .pdb \\n\\n ' ) with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'a' ) as file : if chi_water < 1 : for molecule_name in mixture_dict : number = int ( round ( mixture_dict [ molecule_name ] * remaining_number_molecules )) file . write ( f 'structure { moldir } / { molecule_name } .pdb \\n\\t number { number } \\n\\t inside box 0. 0. 0. { init_box_side_length } . { init_box_side_length } . { init_box_side_length } . \\n end structure \\n\\n ' ) if water_number_molecules == 0 : number_each_molecule_ = [ mixture_dict [ molecule_name ] * remaining_number_molecules for molecule_name in mixture_dict ] number_each_molecule = [ int ( x ) for x in number_each_molecule_ ] for x , y in zip ( number_each_molecule , molecule_number_of_atoms ): molecule_type_beginning_count . append ( sum ( molecule_type_beginning_count [ COUNTER :]) + x * y ) COUNTER += 1 del molecule_type_beginning_count [ - 1 ] self . molecule_type_beginning_count = molecule_type_beginning_count self . number_each_molecule = number_each_molecule else : file . write ( f 'structure { moldir } / { self . water_name } .pdb \\n\\t number { water_number_molecules } \\n\\t inside box 0. 0. 0. { init_box_side_length } . { init_box_side_length } . { init_box_side_length } . \\n end structure \\n\\n ' ) number_each_molecule_ = [ mixture_dict [ molecule_name ] * remaining_number_molecules for molecule_name in mixture_dict ] + [ water_number_molecules ] number_each_molecule = [ int ( x ) for x in number_each_molecule_ ] for x , y in zip ( number_each_molecule , molecule_number_of_atoms ): molecule_type_beginning_count . append ( sum ( molecule_type_beginning_count [ COUNTER :]) + x * y ) COUNTER += 1 self . molecule_type_beginning_count = molecule_type_beginning_count self . number_each_molecule = number_each_molecule with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'a' ) as file : file . write ( f 'add_box_sides 1.0' ) arguments = f 'packmol < { operating_folder } /mixture_ { mixture_name } .inp' _ = subprocess . run ( arguments , shell = True ) def conect_creator ( self ): \"\"\"Takes the CONECT entries of all involved molecules from their PDB files and creates the CONECT entry for the simulation box accordingly. \"\"\" if self . skip_bonds : pass else : path = self . path moldir = self . moldir molecule_names = self . molecule_names number_each_molecule = self . number_each_molecule number_each_molecule_dict = dict ( zip ( molecule_names , number_each_molecule )) molecule_atnums = self . molecule_number_of_atoms molecule_atnums_dict = dict ( zip ( molecule_names , molecule_atnums )) molecule_type_beginning_count = self . molecule_type_beginning_count molecule_type_beginning_count_dict = dict ( zip ( molecule_names , molecule_type_beginning_count )) COUNTER = 0 conect_raw_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_raw_dict . items (): conect_raw_ = [] for line in open ( f ' { moldir } / { name } .pdb' ): if line [: 6 ] == 'CONECT' : conect_raw_ . append ( line ) conect_raw_string = '' . join ( conect_raw_ ) conect_raw = [ int ( s ) for s in conect_raw_string . split () if s . isdigit ()] conect_raw_dict [ name ] = conect_raw conect_extended_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_extended_dict . items (): conect_extend = [] range_index = number_each_molecule_dict [ name ] for _ in range ( range_index ): conect_extend . append ([]) for x in range ( range_index ): conect_extend [ x ] . append ([( f + (( molecule_atnums_dict [ name ]) * x ) + molecule_type_beginning_count_dict [ name ]) for f in conect_raw_dict [ name ]]) conect_extended_dict [ name ] = conect_extend conect_frame_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_frame_dict . items (): conect_frame = [] for line in open ( f ' { moldir } / { name } .pdb' ): column_1 = line [ 12 : 16 ] . strip () column_2 = line [ 17 : 21 ] . strip () column_3 = line [ 22 : 26 ] . strip () column_4 = line [ 27 : 31 ] . strip () if line [: 6 ] == 'CONECT' and column_4 . isdigit () == True : conect_frame . append ( 5 ) elif line [: 6 ] == 'CONECT' and column_3 . isdigit () == True : conect_frame . append ( 4 ) elif line [: 6 ] == 'CONECT' and column_2 . isdigit () == True : conect_frame . append ( 3 ) elif line [: 6 ] == 'CONECT' and column_1 . isdigit () == True : conect_frame . append ( 2 ) else : pass conect_frame_dict [ name ] = conect_frame conect_extended_flat_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_extended_flat_dict . items (): flattend_ = list ( itertools . chain . from_iterable ( conect_extended_dict [ name ])) flattend = list ( itertools . chain . from_iterable ( flattend_ )) conect_extended_flat_dict [ name ] = flattend conect_frame_extended_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_frame_extended_dict . items (): conect_frame_extend = [] for __ in itertools . repeat ( None , number_each_molecule_dict [ name ]): conect_frame_extend . extend ( conect_frame_dict [ name ]) conect_frame_extended_dict [ name ] = conect_frame_extend conect_cleaned = { k : v for k , v in conect_extended_flat_dict . items () if v is not None } conect_frame_cleaned = { k : v for k , v in conect_frame_extended_dict . items () if v is not None } conect_final = [] conect_frame_final = [] for name , _ in conect_cleaned . items (): conect_final . extend ( conect_cleaned [ name ]) for name , _ in conect_frame_cleaned . items (): conect_frame_final . extend ( conect_frame_cleaned [ name ]) file = open ( f ' { path } ' , 'rt' ) data = file . read () data = data . replace ( 'END \\n ' , '' ) file . close () file = open ( f ' { path } ' , 'wt' ) file . write ( data ) file . close () with open ( f ' { path } ' , 'a' ) as file : for identifier , _ in itertools . zip_longest ( conect_frame_final , conect_final ): if identifier == 1 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 } \\n ' ) COUNTER += 1 elif identifier == 2 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 } \\n ' ) COUNTER += 2 elif identifier == 3 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 } \\n ' ) COUNTER += 3 elif identifier == 4 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 }{ conect_final [ COUNTER + 3 ] : 5 } \\n ' ) COUNTER += 4 elif identifier == 5 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 }{ conect_final [ COUNTER + 3 ] : 5 }{ conect_final [ COUNTER + 4 ] : 5 } \\n ' ) COUNTER += 5 else : pass file . write ( 'END' ) __init__ ( Project , total_number_molecules , init_box_side_length , chi_water , water_name , mixture_name ) \u00b6 The simulationbox contains all information that is needed to pack each simulation box in packmol. Parameters: Name Type Description Default Project object The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. required total_number_molecules int A list with the number of molecules that should be placed in the simulation box. required init_box_side_length int The initial box side length that should be used by packmol. required chi_water flot The molar fraction of water of this simulation box. required water_name str The name that was assigned to the water molecule. required mixture_name str The name created from a tuple of total_number_molecules, init_box_side_length and chi_water. required Source code in mixturemm/background.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 def __init__ ( self , Project , total_number_molecules , init_box_side_length , chi_water , water_name , mixture_name ): \"\"\"The simulationbox contains all information that is needed to pack each simulation box in packmol. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. total_number_molecules (int): A list with the number of molecules that should be placed in the simulation box. init_box_side_length (int): The initial box side length that should be used by packmol. chi_water (flot): The molar fraction of water of this simulation box. water_name (str): The name that was assigned to the water molecule. mixture_name (str): The name created from a tuple of total_number_molecules, init_box_side_length and chi_water. \"\"\" self . boxdir = Project . boxdir self . moldir = Project . moldir self . molecule_names = Project . molecule_names self . molecule_number_of_atoms = Project . molecule_number_of_atoms self . mixture_dict = Project . mixture_dict self . total_number_molecules = total_number_molecules self . init_box_side_length = init_box_side_length self . chi_water = chi_water self . water_name = water_name self . mixture_name = mixture_name self . path = f ' { self . boxdir } /mixture_ { mixture_name } .pdb' self . skip_bonds = False conect_creator () \u00b6 Takes the CONECT entries of all involved molecules from their PDB files and creates the CONECT entry for the simulation box accordingly. Source code in mixturemm/background.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 def conect_creator ( self ): \"\"\"Takes the CONECT entries of all involved molecules from their PDB files and creates the CONECT entry for the simulation box accordingly. \"\"\" if self . skip_bonds : pass else : path = self . path moldir = self . moldir molecule_names = self . molecule_names number_each_molecule = self . number_each_molecule number_each_molecule_dict = dict ( zip ( molecule_names , number_each_molecule )) molecule_atnums = self . molecule_number_of_atoms molecule_atnums_dict = dict ( zip ( molecule_names , molecule_atnums )) molecule_type_beginning_count = self . molecule_type_beginning_count molecule_type_beginning_count_dict = dict ( zip ( molecule_names , molecule_type_beginning_count )) COUNTER = 0 conect_raw_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_raw_dict . items (): conect_raw_ = [] for line in open ( f ' { moldir } / { name } .pdb' ): if line [: 6 ] == 'CONECT' : conect_raw_ . append ( line ) conect_raw_string = '' . join ( conect_raw_ ) conect_raw = [ int ( s ) for s in conect_raw_string . split () if s . isdigit ()] conect_raw_dict [ name ] = conect_raw conect_extended_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_extended_dict . items (): conect_extend = [] range_index = number_each_molecule_dict [ name ] for _ in range ( range_index ): conect_extend . append ([]) for x in range ( range_index ): conect_extend [ x ] . append ([( f + (( molecule_atnums_dict [ name ]) * x ) + molecule_type_beginning_count_dict [ name ]) for f in conect_raw_dict [ name ]]) conect_extended_dict [ name ] = conect_extend conect_frame_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_frame_dict . items (): conect_frame = [] for line in open ( f ' { moldir } / { name } .pdb' ): column_1 = line [ 12 : 16 ] . strip () column_2 = line [ 17 : 21 ] . strip () column_3 = line [ 22 : 26 ] . strip () column_4 = line [ 27 : 31 ] . strip () if line [: 6 ] == 'CONECT' and column_4 . isdigit () == True : conect_frame . append ( 5 ) elif line [: 6 ] == 'CONECT' and column_3 . isdigit () == True : conect_frame . append ( 4 ) elif line [: 6 ] == 'CONECT' and column_2 . isdigit () == True : conect_frame . append ( 3 ) elif line [: 6 ] == 'CONECT' and column_1 . isdigit () == True : conect_frame . append ( 2 ) else : pass conect_frame_dict [ name ] = conect_frame conect_extended_flat_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_extended_flat_dict . items (): flattend_ = list ( itertools . chain . from_iterable ( conect_extended_dict [ name ])) flattend = list ( itertools . chain . from_iterable ( flattend_ )) conect_extended_flat_dict [ name ] = flattend conect_frame_extended_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_frame_extended_dict . items (): conect_frame_extend = [] for __ in itertools . repeat ( None , number_each_molecule_dict [ name ]): conect_frame_extend . extend ( conect_frame_dict [ name ]) conect_frame_extended_dict [ name ] = conect_frame_extend conect_cleaned = { k : v for k , v in conect_extended_flat_dict . items () if v is not None } conect_frame_cleaned = { k : v for k , v in conect_frame_extended_dict . items () if v is not None } conect_final = [] conect_frame_final = [] for name , _ in conect_cleaned . items (): conect_final . extend ( conect_cleaned [ name ]) for name , _ in conect_frame_cleaned . items (): conect_frame_final . extend ( conect_frame_cleaned [ name ]) file = open ( f ' { path } ' , 'rt' ) data = file . read () data = data . replace ( 'END \\n ' , '' ) file . close () file = open ( f ' { path } ' , 'wt' ) file . write ( data ) file . close () with open ( f ' { path } ' , 'a' ) as file : for identifier , _ in itertools . zip_longest ( conect_frame_final , conect_final ): if identifier == 1 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 } \\n ' ) COUNTER += 1 elif identifier == 2 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 } \\n ' ) COUNTER += 2 elif identifier == 3 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 } \\n ' ) COUNTER += 3 elif identifier == 4 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 }{ conect_final [ COUNTER + 3 ] : 5 } \\n ' ) COUNTER += 4 elif identifier == 5 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 }{ conect_final [ COUNTER + 3 ] : 5 }{ conect_final [ COUNTER + 4 ] : 5 } \\n ' ) COUNTER += 5 else : pass file . write ( 'END' ) pack () \u00b6 Creates an input file for packmol with the initial box side length and the exact number of each involved molecule and runs packmol with it. Source code in mixturemm/background.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def pack ( self ): \"\"\"Creates an input file for packmol with the initial box side length and the exact number of each involved molecule and runs packmol with it. \"\"\" if os . path . isfile ( f ' { self . path } ' ): self . skip_bonds = True else : mixture_name = self . mixture_name operating_folder = self . boxdir moldir = self . moldir molecule_number_of_atoms = self . molecule_number_of_atoms total_number_molecules = int ( self . total_number_molecules ) init_box_side_length = int ( self . init_box_side_length ) mixture_dict = self . mixture_dict molecule_type_beginning_count = [ 0 ] COUNTER = 0 chi_water = float ( self . chi_water ) water_number_molecules_ = chi_water * total_number_molecules water_number_molecules = int ( water_number_molecules_ ) remaining_number_molecules = total_number_molecules - water_number_molecules with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'w' ) as file : file . write ( f 'tolerance 2.0 \\n filetype pdb \\n output { operating_folder } /mixture_ { mixture_name } .pdb \\n\\n ' ) with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'a' ) as file : if chi_water < 1 : for molecule_name in mixture_dict : number = int ( round ( mixture_dict [ molecule_name ] * remaining_number_molecules )) file . write ( f 'structure { moldir } / { molecule_name } .pdb \\n\\t number { number } \\n\\t inside box 0. 0. 0. { init_box_side_length } . { init_box_side_length } . { init_box_side_length } . \\n end structure \\n\\n ' ) if water_number_molecules == 0 : number_each_molecule_ = [ mixture_dict [ molecule_name ] * remaining_number_molecules for molecule_name in mixture_dict ] number_each_molecule = [ int ( x ) for x in number_each_molecule_ ] for x , y in zip ( number_each_molecule , molecule_number_of_atoms ): molecule_type_beginning_count . append ( sum ( molecule_type_beginning_count [ COUNTER :]) + x * y ) COUNTER += 1 del molecule_type_beginning_count [ - 1 ] self . molecule_type_beginning_count = molecule_type_beginning_count self . number_each_molecule = number_each_molecule else : file . write ( f 'structure { moldir } / { self . water_name } .pdb \\n\\t number { water_number_molecules } \\n\\t inside box 0. 0. 0. { init_box_side_length } . { init_box_side_length } . { init_box_side_length } . \\n end structure \\n\\n ' ) number_each_molecule_ = [ mixture_dict [ molecule_name ] * remaining_number_molecules for molecule_name in mixture_dict ] + [ water_number_molecules ] number_each_molecule = [ int ( x ) for x in number_each_molecule_ ] for x , y in zip ( number_each_molecule , molecule_number_of_atoms ): molecule_type_beginning_count . append ( sum ( molecule_type_beginning_count [ COUNTER :]) + x * y ) COUNTER += 1 self . molecule_type_beginning_count = molecule_type_beginning_count self . number_each_molecule = number_each_molecule with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'a' ) as file : file . write ( f 'add_box_sides 1.0' ) arguments = f 'packmol < { operating_folder } /mixture_ { mixture_name } .inp' _ = subprocess . run ( arguments , shell = True ) Simulationsystem \u00b6 Source code in mixturemm/background.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 class Simulationsystem : def __init__ ( self , Project , Simulationbox , temperature , pressure , ): \"\"\"The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Simulationbox (object): The simulationbox contains all information that is needed to pack each simulation box in packmol. temperature (float): Temperature in kelvin at which the system should be simulated. pressure (float): Pressures in bar at which the system should be simulated. \"\"\" LINKER = '-' self . temperature = temperature self . pressure = pressure self . total_number_molecules = Simulationbox . total_number_molecules self . simulationbox_name = Simulationbox . mixture_name temperature_string = str ( temperature ) pressure_string = str ( pressure ) combined_strings = ( self . simulationbox_name , temperature_string , pressure_string ) system_name = LINKER . join ( combined_strings ) self . name = f ' { system_name } ' self . folder = f ' { Project . workdir } / { system_name } ' self . npt_equilibration_subfolder = f ' { self . folder } /npt_equilibration' self . simulationbox_path = Simulationbox . path self . chi_water = Simulationbox . chi_water directory_maker ( self . folder ) directory_maker ( self . npt_equilibration_subfolder ) self . npt_equilibration_pressure_s = Project . npt_equilibration_pressure_s self . npt_equilibration_pressure_coupling_frequency = Project . npt_equilibration_pressure_coupling_frequency self . npt_equilibration_temperature_coupling_frequency = Project . npt_equilibration_temperature_coupling_frequency self . npt_equilibration_timestep_fs = Project . npt_equilibration_timestep_fs self . npt_equilibration_duration_ns = Project . npt_equilibration_duration_ns self . reporting_frequency_state_npt_equilibration = Project . reporting_frequency_state_npt_equilibration self . cutoff_distance_nm = Project . cutoff_distance_nm self . cutoff_switch_distance_nm = Project . cutoff_switch_distance_nm self . simulation_platform = Project . simulation_platform self . forcefields = Project . forcefields self . npt_equilibration_steps = int (( self . npt_equilibration_duration_ns / self . npt_equilibration_timestep_fs ) * ( 10 ** 6 )) self . openmm_forcefield = ForceField ( * self . forcefields ) self . openmm_platform = Platform . getPlatformByName ( f ' { self . simulation_platform } ' ) self . openmm_properties = Project . simulation_properties self . pme_error_tolerance = Project . pme_error_tolerance self . constraint_tolerance = Project . constraint_tolerance def npt_equilibration ( self ): \"\"\"Runs a NpT equilibration to adjust the box to the correct density using a Monte Carlo barostat. \"\"\" START_TEMPERATURE = 1 TEMPERATURE_STEP = 0.1 heating_interval_steps = int ( 1000 / self . npt_equilibration_timestep_fs ) folder = self . npt_equilibration_subfolder openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm temperature = self . temperature pressure = self . pressure openmm_forcefield = self . openmm_forcefield simulationbox_path = self . simulationbox_path npt_equilibration_pressure_coupling_frequency = self . npt_equilibration_pressure_coupling_frequency npt_equilibration_temperature_coupling_frequency = self . npt_equilibration_temperature_coupling_frequency npt_equilibration_timestep_ps = self . npt_equilibration_timestep_fs * ( 10 ** ( - 3 )) npt_equilibration_steps = self . npt_equilibration_steps reporting_frequency_state_npt_equilibration = self . reporting_frequency_state_npt_equilibration constraint_tolerance = self . constraint_tolerance topology_npt_equilibration = PDBFile ( f ' { simulationbox_path } ' ) system_npt_equilibration = openmm_forcefield . createSystem ( topology_npt_equilibration . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_npt_equilibration = LangevinMiddleIntegrator ( START_TEMPERATURE * kelvin , 10 / picosecond , npt_equilibration_timestep_ps * picoseconds ) integrator_npt_equilibration . setConstraintTolerance ( constraint_tolerance ) barostat_monte_carlo = MonteCarloBarostat ( pressure * bar , temperature * kelvin , 0 ) system_npt_equilibration . addForce ( barostat_monte_carlo ) simulation_npt_equilibration = Simulation ( topology_npt_equilibration . topology , system_npt_equilibration , integrator_npt_equilibration , openmm_platform , openmm_properties ) simulation_npt_equilibration . context . setPositions ( topology_npt_equilibration . positions ) simulation_npt_equilibration . minimizeEnergy ( tolerance = 0.1 * kilojoule / mole , maxIterations = 50000 ) simulation_npt_equilibration . context . setVelocitiesToTemperature ( START_TEMPERATURE * kelvin ) simulation_npt_equilibration . reporters . append ( StateDataReporter ( f ' { folder } /npt_equilibration.csv' , reporting_frequency_state_npt_equilibration , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) for temp in np . arange ( START_TEMPERATURE , temperature , TEMPERATURE_STEP ): integrator_npt_equilibration . setTemperature ( temp * kelvin ) simulation_npt_equilibration . step ( heating_interval_steps ) simulation_npt_equilibration . step ( heating_interval_steps * 10 ) integrator_npt_equilibration . setTemperature ( temperature * kelvin ) integrator_npt_equilibration . setFriction ( npt_equilibration_temperature_coupling_frequency ) barostat_monte_carlo . setFrequency ( npt_equilibration_pressure_coupling_frequency ) simulation_npt_equilibration . step ( npt_equilibration_steps ) system_npt_equilibration . removeForce ( system_npt_equilibration . getNumForces () - 1 ) simulation_npt_equilibration . saveState ( f ' { folder } /npt_equilibration_state.xml' ) endpositions_npt_equilibration = simulation_npt_equilibration . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_npt_equilibration . topology , endpositions_npt_equilibration , open ( f ' { folder } /npt_equilibration_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /npt_equilibration.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /npt_equilibration.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /npt_equilibration.png' , dpi = 300 ) __init__ ( Project , Simulationbox , temperature , pressure ) \u00b6 The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. Parameters: Name Type Description Default Project object The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. required Simulationbox object The simulationbox contains all information that is needed to pack each simulation box in packmol. required temperature float Temperature in kelvin at which the system should be simulated. required pressure float Pressures in bar at which the system should be simulated. required Source code in mixturemm/background.py 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def __init__ ( self , Project , Simulationbox , temperature , pressure , ): \"\"\"The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Simulationbox (object): The simulationbox contains all information that is needed to pack each simulation box in packmol. temperature (float): Temperature in kelvin at which the system should be simulated. pressure (float): Pressures in bar at which the system should be simulated. \"\"\" LINKER = '-' self . temperature = temperature self . pressure = pressure self . total_number_molecules = Simulationbox . total_number_molecules self . simulationbox_name = Simulationbox . mixture_name temperature_string = str ( temperature ) pressure_string = str ( pressure ) combined_strings = ( self . simulationbox_name , temperature_string , pressure_string ) system_name = LINKER . join ( combined_strings ) self . name = f ' { system_name } ' self . folder = f ' { Project . workdir } / { system_name } ' self . npt_equilibration_subfolder = f ' { self . folder } /npt_equilibration' self . simulationbox_path = Simulationbox . path self . chi_water = Simulationbox . chi_water directory_maker ( self . folder ) directory_maker ( self . npt_equilibration_subfolder ) self . npt_equilibration_pressure_s = Project . npt_equilibration_pressure_s self . npt_equilibration_pressure_coupling_frequency = Project . npt_equilibration_pressure_coupling_frequency self . npt_equilibration_temperature_coupling_frequency = Project . npt_equilibration_temperature_coupling_frequency self . npt_equilibration_timestep_fs = Project . npt_equilibration_timestep_fs self . npt_equilibration_duration_ns = Project . npt_equilibration_duration_ns self . reporting_frequency_state_npt_equilibration = Project . reporting_frequency_state_npt_equilibration self . cutoff_distance_nm = Project . cutoff_distance_nm self . cutoff_switch_distance_nm = Project . cutoff_switch_distance_nm self . simulation_platform = Project . simulation_platform self . forcefields = Project . forcefields self . npt_equilibration_steps = int (( self . npt_equilibration_duration_ns / self . npt_equilibration_timestep_fs ) * ( 10 ** 6 )) self . openmm_forcefield = ForceField ( * self . forcefields ) self . openmm_platform = Platform . getPlatformByName ( f ' { self . simulation_platform } ' ) self . openmm_properties = Project . simulation_properties self . pme_error_tolerance = Project . pme_error_tolerance self . constraint_tolerance = Project . constraint_tolerance npt_equilibration () \u00b6 Runs a NpT equilibration to adjust the box to the correct density using a Monte Carlo barostat. Source code in mixturemm/background.py 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 def npt_equilibration ( self ): \"\"\"Runs a NpT equilibration to adjust the box to the correct density using a Monte Carlo barostat. \"\"\" START_TEMPERATURE = 1 TEMPERATURE_STEP = 0.1 heating_interval_steps = int ( 1000 / self . npt_equilibration_timestep_fs ) folder = self . npt_equilibration_subfolder openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm temperature = self . temperature pressure = self . pressure openmm_forcefield = self . openmm_forcefield simulationbox_path = self . simulationbox_path npt_equilibration_pressure_coupling_frequency = self . npt_equilibration_pressure_coupling_frequency npt_equilibration_temperature_coupling_frequency = self . npt_equilibration_temperature_coupling_frequency npt_equilibration_timestep_ps = self . npt_equilibration_timestep_fs * ( 10 ** ( - 3 )) npt_equilibration_steps = self . npt_equilibration_steps reporting_frequency_state_npt_equilibration = self . reporting_frequency_state_npt_equilibration constraint_tolerance = self . constraint_tolerance topology_npt_equilibration = PDBFile ( f ' { simulationbox_path } ' ) system_npt_equilibration = openmm_forcefield . createSystem ( topology_npt_equilibration . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_npt_equilibration = LangevinMiddleIntegrator ( START_TEMPERATURE * kelvin , 10 / picosecond , npt_equilibration_timestep_ps * picoseconds ) integrator_npt_equilibration . setConstraintTolerance ( constraint_tolerance ) barostat_monte_carlo = MonteCarloBarostat ( pressure * bar , temperature * kelvin , 0 ) system_npt_equilibration . addForce ( barostat_monte_carlo ) simulation_npt_equilibration = Simulation ( topology_npt_equilibration . topology , system_npt_equilibration , integrator_npt_equilibration , openmm_platform , openmm_properties ) simulation_npt_equilibration . context . setPositions ( topology_npt_equilibration . positions ) simulation_npt_equilibration . minimizeEnergy ( tolerance = 0.1 * kilojoule / mole , maxIterations = 50000 ) simulation_npt_equilibration . context . setVelocitiesToTemperature ( START_TEMPERATURE * kelvin ) simulation_npt_equilibration . reporters . append ( StateDataReporter ( f ' { folder } /npt_equilibration.csv' , reporting_frequency_state_npt_equilibration , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) for temp in np . arange ( START_TEMPERATURE , temperature , TEMPERATURE_STEP ): integrator_npt_equilibration . setTemperature ( temp * kelvin ) simulation_npt_equilibration . step ( heating_interval_steps ) simulation_npt_equilibration . step ( heating_interval_steps * 10 ) integrator_npt_equilibration . setTemperature ( temperature * kelvin ) integrator_npt_equilibration . setFriction ( npt_equilibration_temperature_coupling_frequency ) barostat_monte_carlo . setFrequency ( npt_equilibration_pressure_coupling_frequency ) simulation_npt_equilibration . step ( npt_equilibration_steps ) system_npt_equilibration . removeForce ( system_npt_equilibration . getNumForces () - 1 ) simulation_npt_equilibration . saveState ( f ' { folder } /npt_equilibration_state.xml' ) endpositions_npt_equilibration = simulation_npt_equilibration . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_npt_equilibration . topology , endpositions_npt_equilibration , open ( f ' { folder } /npt_equilibration_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /npt_equilibration.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /npt_equilibration.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /npt_equilibration.png' , dpi = 300 )","title":"background modue"},{"location":"background/#background","text":"Module with indirectly used classes. MIT License Copyright (c) 2021, Benjamin Schmitz Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"background"},{"location":"background/#mixturemm.background.Replica","text":"Source code in mixturemm/background.py 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 class Replica : def __init__ ( self , Project , Simulationsystem , replica_number ): \"\"\"The replica of a simulationsystem contains the parameters for the NVT equilibration and the NVE production. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Simulationsystem (object): The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. replica_number (int): The number assigned to this replica. \"\"\" self . folder = f ' { Simulationsystem . folder } /replica_ { replica_number } ' directory_maker ( self . folder ) self . npt_equilibration_subfolder = Simulationsystem . npt_equilibration_subfolder self . name = Simulationsystem . name self . simulationbox_path = Simulationsystem . simulationbox_path self . replica_number = replica_number self . chi_water = Simulationsystem . chi_water self . temperature = Simulationsystem . temperature self . pressure = Simulationsystem . pressure self . total_number_molecules = Simulationsystem . total_number_molecules self . simulationbox_name = Simulationsystem . simulationbox_name self . nvt_equilibration_temperature_coupling_frequency = Project . nvt_equilibration_temperature_coupling_frequency self . nvt_equilibration_timestep_fs = Project . nvt_equilibration_timestep_fs self . nvt_equilibration_duration_ns = Project . nvt_equilibration_duration_ns self . nve_production_timestep_fs = Project . nve_production_timestep_fs self . nve_production_duration_ns = Project . nve_production_duration_ns self . reporting_frequency_coordinates_unwrapped = Project . reporting_frequency_coordinates_unwrapped self . reporting_frequency_coordinates_wrapped = Project . reporting_frequency_coordinates_wrapped self . reporting_frequency_state_nvt_equilibration = Project . reporting_frequency_state_nvt_equilibration self . reporting_frequency_state_nve_production = Project . reporting_frequency_state_nve_production self . cutoff_distance_nm = Project . cutoff_distance_nm self . cutoff_switch_distance_nm = Project . cutoff_switch_distance_nm self . simulation_platform = Project . simulation_platform self . half_npt_equilibration_csv_columns = Project . half_npt_equilibration_csv_columns self . forcefields = Project . forcefields self . nvt_equilibration_steps = int (( self . nvt_equilibration_duration_ns / self . nvt_equilibration_timestep_fs ) * ( 10 ** 6 )) self . nve_production_steps = int (( self . nve_production_duration_ns / self . nve_production_timestep_fs ) * ( 10 ** 6 )) self . openmm_forcefield = ForceField ( * self . forcefields ) self . openmm_platform = Platform . getPlatformByName ( f ' { self . simulation_platform } ' ) self . openmm_properties = Project . simulation_properties self . pme_error_tolerance = Project . pme_error_tolerance self . constraint_tolerance = Project . constraint_tolerance def nvt_equilibration ( self ): \"\"\"Runs a NVT equilibration of the system. \"\"\" folder = self . folder npt_equilibration_subfolder = self . npt_equilibration_subfolder npt_equilibration_state = f ' { npt_equilibration_subfolder } /npt_equilibration_state.xml' npt_equilibration_end_simulationbox = f ' { npt_equilibration_subfolder } /npt_equilibration_end.pdb' openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm temperature = self . temperature openmm_forcefield = self . openmm_forcefield nvt_equilibration_temperature_coupling_frequency = self . nvt_equilibration_temperature_coupling_frequency nvt_equilibration_timestep_ps = self . nvt_equilibration_timestep_fs * ( 10 ** ( - 3 )) nvt_equilibration_steps = self . nvt_equilibration_steps half_npt_equilibration_csv_columns = self . half_npt_equilibration_csv_columns reporting_frequency_state_nvt_equilibration = self . reporting_frequency_state_nvt_equilibration constraint_tolerance = self . constraint_tolerance topology_nvt_equilibration = PDBFile ( f ' { npt_equilibration_end_simulationbox } ' ) system_nvt_equilibration = openmm_forcefield . createSystem ( topology_nvt_equilibration . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_nvt_equilibration = LangevinMiddleIntegrator ( temperature * kelvin , nvt_equilibration_temperature_coupling_frequency / picosecond , nvt_equilibration_timestep_ps * picoseconds ) integrator_nvt_equilibration . setConstraintTolerance ( constraint_tolerance ) simulation_nvt_equilibration = Simulation ( topology_nvt_equilibration . topology , system_nvt_equilibration , integrator_nvt_equilibration , openmm_platform , openmm_properties , state = npt_equilibration_state ) npt_equilibration_df = pd . read_csv ( f ' { npt_equilibration_subfolder } /npt_equilibration.csv' ) half_npt_equilibration_df = npt_equilibration_df . tail ( n = half_npt_equilibration_csv_columns ) volume_npt_equilibration = half_npt_equilibration_df . loc [:, 'Box Volume (nm^3)' ] average_volume_npt_equilibration = volume_npt_equilibration . mean () estimated_new_side_length = ( average_volume_npt_equilibration ** ( 1 / 3 )) positions = simulation_nvt_equilibration . context . getState ( getPositions = True ) . getPositions () simulation_nvt_equilibration . context . reinitialize () simulation_nvt_equilibration . context . setPositions ( positions ) simulation_nvt_equilibration . context . setPeriodicBoxVectors ( Vec3 ( x = estimated_new_side_length , y = 0.0 , z = 0.0 ), Vec3 ( x = 0.0 , y = estimated_new_side_length , z = 0.0 ), Vec3 ( x = 0.0 , y = 0.0 , z = estimated_new_side_length )) simulation_nvt_equilibration . minimizeEnergy ( tolerance = 0.1 * kilojoule / mole , maxIterations = 500000 ) simulation_nvt_equilibration . context . setVelocitiesToTemperature ( temperature * kelvin ) simulation_nvt_equilibration . reporters . append ( StateDataReporter ( f ' { folder } /nvt_equilibration.csv' , reporting_frequency_state_nvt_equilibration , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) simulation_nvt_equilibration . step ( nvt_equilibration_steps ) simulation_nvt_equilibration . saveState ( f ' { folder } /nvt_equilibration_state.xml' ) endpositions_nvt_equilibration = simulation_nvt_equilibration . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_nvt_equilibration . topology , endpositions_nvt_equilibration , open ( f ' { folder } /nvt_equilibration_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /nvt_equilibration.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /nvt_equilibration.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /nvt_equilibration.png' , dpi = 300 ) def nve_production ( self ): \"\"\"Runs a NVE production of the system during which two trajectories are written, one with unwrapped and one with wrapped coordinates. \"\"\" folder = self . folder nvt_equilibration_state = f ' { folder } /nvt_equilibration_state.xml' nvt_equilibration_end_simulationbox = f ' { folder } /nvt_equilibration_end.pdb' openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm openmm_forcefield = self . openmm_forcefield production_timestep_ps = self . nve_production_timestep_fs * ( 10 ** ( - 3 )) production_steps = self . nve_production_steps reporting_frequency_coordinates_unwrapped = self . reporting_frequency_coordinates_unwrapped reporting_frequency_coordinates_wrapped = self . reporting_frequency_coordinates_wrapped reporting_frequency_state_nve_production = self . reporting_frequency_state_nve_production constraint_tolerance = self . constraint_tolerance topology_nve_production = PDBFile ( f ' { nvt_equilibration_end_simulationbox } ' ) system_nve_production = openmm_forcefield . createSystem ( topology_nve_production . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_nve_production = VerletIntegrator ( production_timestep_ps * picoseconds ) integrator_nve_production . setConstraintTolerance ( constraint_tolerance ) simulation_nve_production = Simulation ( topology_nve_production . topology , system_nve_production , integrator_nve_production , openmm_platform , openmm_properties , state = nvt_equilibration_state ) simulation_nve_production . reporters . append ( StateDataReporter ( f ' { folder } /nve_production.csv' , reporting_frequency_state_nve_production , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) simulation_nve_production . reporters . append ( DCDReporter ( f ' { folder } /nve_production_unwrapped.dcd' , reporting_frequency_coordinates_unwrapped , enforcePeriodicBox = False )) simulation_nve_production . reporters . append ( DCDReporter ( f ' { folder } /nve_production_wrapped.dcd' , reporting_frequency_coordinates_wrapped )) simulation_nve_production . step ( production_steps ) simulation_nve_production . saveState ( f ' { folder } /nve_production_state.xml' ) endpositions_nve_production = simulation_nve_production . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_nve_production . topology , endpositions_nve_production , open ( f ' { folder } /nve_production_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /nve_production.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /nve_production.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /nve_production.png' , dpi = 300 )","title":"Replica"},{"location":"background/#mixturemm.background.Replica.__init__","text":"The replica of a simulationsystem contains the parameters for the NVT equilibration and the NVE production. Parameters: Name Type Description Default Project object The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. required Simulationsystem object The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. required replica_number int The number assigned to this replica. required Source code in mixturemm/background.py 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 def __init__ ( self , Project , Simulationsystem , replica_number ): \"\"\"The replica of a simulationsystem contains the parameters for the NVT equilibration and the NVE production. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Simulationsystem (object): The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. replica_number (int): The number assigned to this replica. \"\"\" self . folder = f ' { Simulationsystem . folder } /replica_ { replica_number } ' directory_maker ( self . folder ) self . npt_equilibration_subfolder = Simulationsystem . npt_equilibration_subfolder self . name = Simulationsystem . name self . simulationbox_path = Simulationsystem . simulationbox_path self . replica_number = replica_number self . chi_water = Simulationsystem . chi_water self . temperature = Simulationsystem . temperature self . pressure = Simulationsystem . pressure self . total_number_molecules = Simulationsystem . total_number_molecules self . simulationbox_name = Simulationsystem . simulationbox_name self . nvt_equilibration_temperature_coupling_frequency = Project . nvt_equilibration_temperature_coupling_frequency self . nvt_equilibration_timestep_fs = Project . nvt_equilibration_timestep_fs self . nvt_equilibration_duration_ns = Project . nvt_equilibration_duration_ns self . nve_production_timestep_fs = Project . nve_production_timestep_fs self . nve_production_duration_ns = Project . nve_production_duration_ns self . reporting_frequency_coordinates_unwrapped = Project . reporting_frequency_coordinates_unwrapped self . reporting_frequency_coordinates_wrapped = Project . reporting_frequency_coordinates_wrapped self . reporting_frequency_state_nvt_equilibration = Project . reporting_frequency_state_nvt_equilibration self . reporting_frequency_state_nve_production = Project . reporting_frequency_state_nve_production self . cutoff_distance_nm = Project . cutoff_distance_nm self . cutoff_switch_distance_nm = Project . cutoff_switch_distance_nm self . simulation_platform = Project . simulation_platform self . half_npt_equilibration_csv_columns = Project . half_npt_equilibration_csv_columns self . forcefields = Project . forcefields self . nvt_equilibration_steps = int (( self . nvt_equilibration_duration_ns / self . nvt_equilibration_timestep_fs ) * ( 10 ** 6 )) self . nve_production_steps = int (( self . nve_production_duration_ns / self . nve_production_timestep_fs ) * ( 10 ** 6 )) self . openmm_forcefield = ForceField ( * self . forcefields ) self . openmm_platform = Platform . getPlatformByName ( f ' { self . simulation_platform } ' ) self . openmm_properties = Project . simulation_properties self . pme_error_tolerance = Project . pme_error_tolerance self . constraint_tolerance = Project . constraint_tolerance","title":"__init__()"},{"location":"background/#mixturemm.background.Replica.nve_production","text":"Runs a NVE production of the system during which two trajectories are written, one with unwrapped and one with wrapped coordinates. Source code in mixturemm/background.py 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 def nve_production ( self ): \"\"\"Runs a NVE production of the system during which two trajectories are written, one with unwrapped and one with wrapped coordinates. \"\"\" folder = self . folder nvt_equilibration_state = f ' { folder } /nvt_equilibration_state.xml' nvt_equilibration_end_simulationbox = f ' { folder } /nvt_equilibration_end.pdb' openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm openmm_forcefield = self . openmm_forcefield production_timestep_ps = self . nve_production_timestep_fs * ( 10 ** ( - 3 )) production_steps = self . nve_production_steps reporting_frequency_coordinates_unwrapped = self . reporting_frequency_coordinates_unwrapped reporting_frequency_coordinates_wrapped = self . reporting_frequency_coordinates_wrapped reporting_frequency_state_nve_production = self . reporting_frequency_state_nve_production constraint_tolerance = self . constraint_tolerance topology_nve_production = PDBFile ( f ' { nvt_equilibration_end_simulationbox } ' ) system_nve_production = openmm_forcefield . createSystem ( topology_nve_production . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_nve_production = VerletIntegrator ( production_timestep_ps * picoseconds ) integrator_nve_production . setConstraintTolerance ( constraint_tolerance ) simulation_nve_production = Simulation ( topology_nve_production . topology , system_nve_production , integrator_nve_production , openmm_platform , openmm_properties , state = nvt_equilibration_state ) simulation_nve_production . reporters . append ( StateDataReporter ( f ' { folder } /nve_production.csv' , reporting_frequency_state_nve_production , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) simulation_nve_production . reporters . append ( DCDReporter ( f ' { folder } /nve_production_unwrapped.dcd' , reporting_frequency_coordinates_unwrapped , enforcePeriodicBox = False )) simulation_nve_production . reporters . append ( DCDReporter ( f ' { folder } /nve_production_wrapped.dcd' , reporting_frequency_coordinates_wrapped )) simulation_nve_production . step ( production_steps ) simulation_nve_production . saveState ( f ' { folder } /nve_production_state.xml' ) endpositions_nve_production = simulation_nve_production . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_nve_production . topology , endpositions_nve_production , open ( f ' { folder } /nve_production_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /nve_production.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /nve_production.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /nve_production.png' , dpi = 300 )","title":"nve_production()"},{"location":"background/#mixturemm.background.Replica.nvt_equilibration","text":"Runs a NVT equilibration of the system. Source code in mixturemm/background.py 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 def nvt_equilibration ( self ): \"\"\"Runs a NVT equilibration of the system. \"\"\" folder = self . folder npt_equilibration_subfolder = self . npt_equilibration_subfolder npt_equilibration_state = f ' { npt_equilibration_subfolder } /npt_equilibration_state.xml' npt_equilibration_end_simulationbox = f ' { npt_equilibration_subfolder } /npt_equilibration_end.pdb' openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm temperature = self . temperature openmm_forcefield = self . openmm_forcefield nvt_equilibration_temperature_coupling_frequency = self . nvt_equilibration_temperature_coupling_frequency nvt_equilibration_timestep_ps = self . nvt_equilibration_timestep_fs * ( 10 ** ( - 3 )) nvt_equilibration_steps = self . nvt_equilibration_steps half_npt_equilibration_csv_columns = self . half_npt_equilibration_csv_columns reporting_frequency_state_nvt_equilibration = self . reporting_frequency_state_nvt_equilibration constraint_tolerance = self . constraint_tolerance topology_nvt_equilibration = PDBFile ( f ' { npt_equilibration_end_simulationbox } ' ) system_nvt_equilibration = openmm_forcefield . createSystem ( topology_nvt_equilibration . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_nvt_equilibration = LangevinMiddleIntegrator ( temperature * kelvin , nvt_equilibration_temperature_coupling_frequency / picosecond , nvt_equilibration_timestep_ps * picoseconds ) integrator_nvt_equilibration . setConstraintTolerance ( constraint_tolerance ) simulation_nvt_equilibration = Simulation ( topology_nvt_equilibration . topology , system_nvt_equilibration , integrator_nvt_equilibration , openmm_platform , openmm_properties , state = npt_equilibration_state ) npt_equilibration_df = pd . read_csv ( f ' { npt_equilibration_subfolder } /npt_equilibration.csv' ) half_npt_equilibration_df = npt_equilibration_df . tail ( n = half_npt_equilibration_csv_columns ) volume_npt_equilibration = half_npt_equilibration_df . loc [:, 'Box Volume (nm^3)' ] average_volume_npt_equilibration = volume_npt_equilibration . mean () estimated_new_side_length = ( average_volume_npt_equilibration ** ( 1 / 3 )) positions = simulation_nvt_equilibration . context . getState ( getPositions = True ) . getPositions () simulation_nvt_equilibration . context . reinitialize () simulation_nvt_equilibration . context . setPositions ( positions ) simulation_nvt_equilibration . context . setPeriodicBoxVectors ( Vec3 ( x = estimated_new_side_length , y = 0.0 , z = 0.0 ), Vec3 ( x = 0.0 , y = estimated_new_side_length , z = 0.0 ), Vec3 ( x = 0.0 , y = 0.0 , z = estimated_new_side_length )) simulation_nvt_equilibration . minimizeEnergy ( tolerance = 0.1 * kilojoule / mole , maxIterations = 500000 ) simulation_nvt_equilibration . context . setVelocitiesToTemperature ( temperature * kelvin ) simulation_nvt_equilibration . reporters . append ( StateDataReporter ( f ' { folder } /nvt_equilibration.csv' , reporting_frequency_state_nvt_equilibration , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) simulation_nvt_equilibration . step ( nvt_equilibration_steps ) simulation_nvt_equilibration . saveState ( f ' { folder } /nvt_equilibration_state.xml' ) endpositions_nvt_equilibration = simulation_nvt_equilibration . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_nvt_equilibration . topology , endpositions_nvt_equilibration , open ( f ' { folder } /nvt_equilibration_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /nvt_equilibration.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /nvt_equilibration.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /nvt_equilibration.png' , dpi = 300 )","title":"nvt_equilibration()"},{"location":"background/#mixturemm.background.Simulationbox","text":"Source code in mixturemm/background.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 class Simulationbox : def __init__ ( self , Project , total_number_molecules , init_box_side_length , chi_water , water_name , mixture_name ): \"\"\"The simulationbox contains all information that is needed to pack each simulation box in packmol. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. total_number_molecules (int): A list with the number of molecules that should be placed in the simulation box. init_box_side_length (int): The initial box side length that should be used by packmol. chi_water (flot): The molar fraction of water of this simulation box. water_name (str): The name that was assigned to the water molecule. mixture_name (str): The name created from a tuple of total_number_molecules, init_box_side_length and chi_water. \"\"\" self . boxdir = Project . boxdir self . moldir = Project . moldir self . molecule_names = Project . molecule_names self . molecule_number_of_atoms = Project . molecule_number_of_atoms self . mixture_dict = Project . mixture_dict self . total_number_molecules = total_number_molecules self . init_box_side_length = init_box_side_length self . chi_water = chi_water self . water_name = water_name self . mixture_name = mixture_name self . path = f ' { self . boxdir } /mixture_ { mixture_name } .pdb' self . skip_bonds = False def pack ( self ): \"\"\"Creates an input file for packmol with the initial box side length and the exact number of each involved molecule and runs packmol with it. \"\"\" if os . path . isfile ( f ' { self . path } ' ): self . skip_bonds = True else : mixture_name = self . mixture_name operating_folder = self . boxdir moldir = self . moldir molecule_number_of_atoms = self . molecule_number_of_atoms total_number_molecules = int ( self . total_number_molecules ) init_box_side_length = int ( self . init_box_side_length ) mixture_dict = self . mixture_dict molecule_type_beginning_count = [ 0 ] COUNTER = 0 chi_water = float ( self . chi_water ) water_number_molecules_ = chi_water * total_number_molecules water_number_molecules = int ( water_number_molecules_ ) remaining_number_molecules = total_number_molecules - water_number_molecules with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'w' ) as file : file . write ( f 'tolerance 2.0 \\n filetype pdb \\n output { operating_folder } /mixture_ { mixture_name } .pdb \\n\\n ' ) with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'a' ) as file : if chi_water < 1 : for molecule_name in mixture_dict : number = int ( round ( mixture_dict [ molecule_name ] * remaining_number_molecules )) file . write ( f 'structure { moldir } / { molecule_name } .pdb \\n\\t number { number } \\n\\t inside box 0. 0. 0. { init_box_side_length } . { init_box_side_length } . { init_box_side_length } . \\n end structure \\n\\n ' ) if water_number_molecules == 0 : number_each_molecule_ = [ mixture_dict [ molecule_name ] * remaining_number_molecules for molecule_name in mixture_dict ] number_each_molecule = [ int ( x ) for x in number_each_molecule_ ] for x , y in zip ( number_each_molecule , molecule_number_of_atoms ): molecule_type_beginning_count . append ( sum ( molecule_type_beginning_count [ COUNTER :]) + x * y ) COUNTER += 1 del molecule_type_beginning_count [ - 1 ] self . molecule_type_beginning_count = molecule_type_beginning_count self . number_each_molecule = number_each_molecule else : file . write ( f 'structure { moldir } / { self . water_name } .pdb \\n\\t number { water_number_molecules } \\n\\t inside box 0. 0. 0. { init_box_side_length } . { init_box_side_length } . { init_box_side_length } . \\n end structure \\n\\n ' ) number_each_molecule_ = [ mixture_dict [ molecule_name ] * remaining_number_molecules for molecule_name in mixture_dict ] + [ water_number_molecules ] number_each_molecule = [ int ( x ) for x in number_each_molecule_ ] for x , y in zip ( number_each_molecule , molecule_number_of_atoms ): molecule_type_beginning_count . append ( sum ( molecule_type_beginning_count [ COUNTER :]) + x * y ) COUNTER += 1 self . molecule_type_beginning_count = molecule_type_beginning_count self . number_each_molecule = number_each_molecule with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'a' ) as file : file . write ( f 'add_box_sides 1.0' ) arguments = f 'packmol < { operating_folder } /mixture_ { mixture_name } .inp' _ = subprocess . run ( arguments , shell = True ) def conect_creator ( self ): \"\"\"Takes the CONECT entries of all involved molecules from their PDB files and creates the CONECT entry for the simulation box accordingly. \"\"\" if self . skip_bonds : pass else : path = self . path moldir = self . moldir molecule_names = self . molecule_names number_each_molecule = self . number_each_molecule number_each_molecule_dict = dict ( zip ( molecule_names , number_each_molecule )) molecule_atnums = self . molecule_number_of_atoms molecule_atnums_dict = dict ( zip ( molecule_names , molecule_atnums )) molecule_type_beginning_count = self . molecule_type_beginning_count molecule_type_beginning_count_dict = dict ( zip ( molecule_names , molecule_type_beginning_count )) COUNTER = 0 conect_raw_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_raw_dict . items (): conect_raw_ = [] for line in open ( f ' { moldir } / { name } .pdb' ): if line [: 6 ] == 'CONECT' : conect_raw_ . append ( line ) conect_raw_string = '' . join ( conect_raw_ ) conect_raw = [ int ( s ) for s in conect_raw_string . split () if s . isdigit ()] conect_raw_dict [ name ] = conect_raw conect_extended_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_extended_dict . items (): conect_extend = [] range_index = number_each_molecule_dict [ name ] for _ in range ( range_index ): conect_extend . append ([]) for x in range ( range_index ): conect_extend [ x ] . append ([( f + (( molecule_atnums_dict [ name ]) * x ) + molecule_type_beginning_count_dict [ name ]) for f in conect_raw_dict [ name ]]) conect_extended_dict [ name ] = conect_extend conect_frame_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_frame_dict . items (): conect_frame = [] for line in open ( f ' { moldir } / { name } .pdb' ): column_1 = line [ 12 : 16 ] . strip () column_2 = line [ 17 : 21 ] . strip () column_3 = line [ 22 : 26 ] . strip () column_4 = line [ 27 : 31 ] . strip () if line [: 6 ] == 'CONECT' and column_4 . isdigit () == True : conect_frame . append ( 5 ) elif line [: 6 ] == 'CONECT' and column_3 . isdigit () == True : conect_frame . append ( 4 ) elif line [: 6 ] == 'CONECT' and column_2 . isdigit () == True : conect_frame . append ( 3 ) elif line [: 6 ] == 'CONECT' and column_1 . isdigit () == True : conect_frame . append ( 2 ) else : pass conect_frame_dict [ name ] = conect_frame conect_extended_flat_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_extended_flat_dict . items (): flattend_ = list ( itertools . chain . from_iterable ( conect_extended_dict [ name ])) flattend = list ( itertools . chain . from_iterable ( flattend_ )) conect_extended_flat_dict [ name ] = flattend conect_frame_extended_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_frame_extended_dict . items (): conect_frame_extend = [] for __ in itertools . repeat ( None , number_each_molecule_dict [ name ]): conect_frame_extend . extend ( conect_frame_dict [ name ]) conect_frame_extended_dict [ name ] = conect_frame_extend conect_cleaned = { k : v for k , v in conect_extended_flat_dict . items () if v is not None } conect_frame_cleaned = { k : v for k , v in conect_frame_extended_dict . items () if v is not None } conect_final = [] conect_frame_final = [] for name , _ in conect_cleaned . items (): conect_final . extend ( conect_cleaned [ name ]) for name , _ in conect_frame_cleaned . items (): conect_frame_final . extend ( conect_frame_cleaned [ name ]) file = open ( f ' { path } ' , 'rt' ) data = file . read () data = data . replace ( 'END \\n ' , '' ) file . close () file = open ( f ' { path } ' , 'wt' ) file . write ( data ) file . close () with open ( f ' { path } ' , 'a' ) as file : for identifier , _ in itertools . zip_longest ( conect_frame_final , conect_final ): if identifier == 1 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 } \\n ' ) COUNTER += 1 elif identifier == 2 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 } \\n ' ) COUNTER += 2 elif identifier == 3 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 } \\n ' ) COUNTER += 3 elif identifier == 4 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 }{ conect_final [ COUNTER + 3 ] : 5 } \\n ' ) COUNTER += 4 elif identifier == 5 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 }{ conect_final [ COUNTER + 3 ] : 5 }{ conect_final [ COUNTER + 4 ] : 5 } \\n ' ) COUNTER += 5 else : pass file . write ( 'END' )","title":"Simulationbox"},{"location":"background/#mixturemm.background.Simulationbox.__init__","text":"The simulationbox contains all information that is needed to pack each simulation box in packmol. Parameters: Name Type Description Default Project object The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. required total_number_molecules int A list with the number of molecules that should be placed in the simulation box. required init_box_side_length int The initial box side length that should be used by packmol. required chi_water flot The molar fraction of water of this simulation box. required water_name str The name that was assigned to the water molecule. required mixture_name str The name created from a tuple of total_number_molecules, init_box_side_length and chi_water. required Source code in mixturemm/background.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 def __init__ ( self , Project , total_number_molecules , init_box_side_length , chi_water , water_name , mixture_name ): \"\"\"The simulationbox contains all information that is needed to pack each simulation box in packmol. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. total_number_molecules (int): A list with the number of molecules that should be placed in the simulation box. init_box_side_length (int): The initial box side length that should be used by packmol. chi_water (flot): The molar fraction of water of this simulation box. water_name (str): The name that was assigned to the water molecule. mixture_name (str): The name created from a tuple of total_number_molecules, init_box_side_length and chi_water. \"\"\" self . boxdir = Project . boxdir self . moldir = Project . moldir self . molecule_names = Project . molecule_names self . molecule_number_of_atoms = Project . molecule_number_of_atoms self . mixture_dict = Project . mixture_dict self . total_number_molecules = total_number_molecules self . init_box_side_length = init_box_side_length self . chi_water = chi_water self . water_name = water_name self . mixture_name = mixture_name self . path = f ' { self . boxdir } /mixture_ { mixture_name } .pdb' self . skip_bonds = False","title":"__init__()"},{"location":"background/#mixturemm.background.Simulationbox.conect_creator","text":"Takes the CONECT entries of all involved molecules from their PDB files and creates the CONECT entry for the simulation box accordingly. Source code in mixturemm/background.py 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 def conect_creator ( self ): \"\"\"Takes the CONECT entries of all involved molecules from their PDB files and creates the CONECT entry for the simulation box accordingly. \"\"\" if self . skip_bonds : pass else : path = self . path moldir = self . moldir molecule_names = self . molecule_names number_each_molecule = self . number_each_molecule number_each_molecule_dict = dict ( zip ( molecule_names , number_each_molecule )) molecule_atnums = self . molecule_number_of_atoms molecule_atnums_dict = dict ( zip ( molecule_names , molecule_atnums )) molecule_type_beginning_count = self . molecule_type_beginning_count molecule_type_beginning_count_dict = dict ( zip ( molecule_names , molecule_type_beginning_count )) COUNTER = 0 conect_raw_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_raw_dict . items (): conect_raw_ = [] for line in open ( f ' { moldir } / { name } .pdb' ): if line [: 6 ] == 'CONECT' : conect_raw_ . append ( line ) conect_raw_string = '' . join ( conect_raw_ ) conect_raw = [ int ( s ) for s in conect_raw_string . split () if s . isdigit ()] conect_raw_dict [ name ] = conect_raw conect_extended_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_extended_dict . items (): conect_extend = [] range_index = number_each_molecule_dict [ name ] for _ in range ( range_index ): conect_extend . append ([]) for x in range ( range_index ): conect_extend [ x ] . append ([( f + (( molecule_atnums_dict [ name ]) * x ) + molecule_type_beginning_count_dict [ name ]) for f in conect_raw_dict [ name ]]) conect_extended_dict [ name ] = conect_extend conect_frame_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_frame_dict . items (): conect_frame = [] for line in open ( f ' { moldir } / { name } .pdb' ): column_1 = line [ 12 : 16 ] . strip () column_2 = line [ 17 : 21 ] . strip () column_3 = line [ 22 : 26 ] . strip () column_4 = line [ 27 : 31 ] . strip () if line [: 6 ] == 'CONECT' and column_4 . isdigit () == True : conect_frame . append ( 5 ) elif line [: 6 ] == 'CONECT' and column_3 . isdigit () == True : conect_frame . append ( 4 ) elif line [: 6 ] == 'CONECT' and column_2 . isdigit () == True : conect_frame . append ( 3 ) elif line [: 6 ] == 'CONECT' and column_1 . isdigit () == True : conect_frame . append ( 2 ) else : pass conect_frame_dict [ name ] = conect_frame conect_extended_flat_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_extended_flat_dict . items (): flattend_ = list ( itertools . chain . from_iterable ( conect_extended_dict [ name ])) flattend = list ( itertools . chain . from_iterable ( flattend_ )) conect_extended_flat_dict [ name ] = flattend conect_frame_extended_dict = dict . fromkeys ( molecule_names ) for name , _ in conect_frame_extended_dict . items (): conect_frame_extend = [] for __ in itertools . repeat ( None , number_each_molecule_dict [ name ]): conect_frame_extend . extend ( conect_frame_dict [ name ]) conect_frame_extended_dict [ name ] = conect_frame_extend conect_cleaned = { k : v for k , v in conect_extended_flat_dict . items () if v is not None } conect_frame_cleaned = { k : v for k , v in conect_frame_extended_dict . items () if v is not None } conect_final = [] conect_frame_final = [] for name , _ in conect_cleaned . items (): conect_final . extend ( conect_cleaned [ name ]) for name , _ in conect_frame_cleaned . items (): conect_frame_final . extend ( conect_frame_cleaned [ name ]) file = open ( f ' { path } ' , 'rt' ) data = file . read () data = data . replace ( 'END \\n ' , '' ) file . close () file = open ( f ' { path } ' , 'wt' ) file . write ( data ) file . close () with open ( f ' { path } ' , 'a' ) as file : for identifier , _ in itertools . zip_longest ( conect_frame_final , conect_final ): if identifier == 1 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 } \\n ' ) COUNTER += 1 elif identifier == 2 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 } \\n ' ) COUNTER += 2 elif identifier == 3 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 } \\n ' ) COUNTER += 3 elif identifier == 4 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 }{ conect_final [ COUNTER + 3 ] : 5 } \\n ' ) COUNTER += 4 elif identifier == 5 : file . write ( f 'CONECT { conect_final [ COUNTER ] : 5 }{ conect_final [ COUNTER + 1 ] : 5 }{ conect_final [ COUNTER + 2 ] : 5 }{ conect_final [ COUNTER + 3 ] : 5 }{ conect_final [ COUNTER + 4 ] : 5 } \\n ' ) COUNTER += 5 else : pass file . write ( 'END' )","title":"conect_creator()"},{"location":"background/#mixturemm.background.Simulationbox.pack","text":"Creates an input file for packmol with the initial box side length and the exact number of each involved molecule and runs packmol with it. Source code in mixturemm/background.py 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 def pack ( self ): \"\"\"Creates an input file for packmol with the initial box side length and the exact number of each involved molecule and runs packmol with it. \"\"\" if os . path . isfile ( f ' { self . path } ' ): self . skip_bonds = True else : mixture_name = self . mixture_name operating_folder = self . boxdir moldir = self . moldir molecule_number_of_atoms = self . molecule_number_of_atoms total_number_molecules = int ( self . total_number_molecules ) init_box_side_length = int ( self . init_box_side_length ) mixture_dict = self . mixture_dict molecule_type_beginning_count = [ 0 ] COUNTER = 0 chi_water = float ( self . chi_water ) water_number_molecules_ = chi_water * total_number_molecules water_number_molecules = int ( water_number_molecules_ ) remaining_number_molecules = total_number_molecules - water_number_molecules with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'w' ) as file : file . write ( f 'tolerance 2.0 \\n filetype pdb \\n output { operating_folder } /mixture_ { mixture_name } .pdb \\n\\n ' ) with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'a' ) as file : if chi_water < 1 : for molecule_name in mixture_dict : number = int ( round ( mixture_dict [ molecule_name ] * remaining_number_molecules )) file . write ( f 'structure { moldir } / { molecule_name } .pdb \\n\\t number { number } \\n\\t inside box 0. 0. 0. { init_box_side_length } . { init_box_side_length } . { init_box_side_length } . \\n end structure \\n\\n ' ) if water_number_molecules == 0 : number_each_molecule_ = [ mixture_dict [ molecule_name ] * remaining_number_molecules for molecule_name in mixture_dict ] number_each_molecule = [ int ( x ) for x in number_each_molecule_ ] for x , y in zip ( number_each_molecule , molecule_number_of_atoms ): molecule_type_beginning_count . append ( sum ( molecule_type_beginning_count [ COUNTER :]) + x * y ) COUNTER += 1 del molecule_type_beginning_count [ - 1 ] self . molecule_type_beginning_count = molecule_type_beginning_count self . number_each_molecule = number_each_molecule else : file . write ( f 'structure { moldir } / { self . water_name } .pdb \\n\\t number { water_number_molecules } \\n\\t inside box 0. 0. 0. { init_box_side_length } . { init_box_side_length } . { init_box_side_length } . \\n end structure \\n\\n ' ) number_each_molecule_ = [ mixture_dict [ molecule_name ] * remaining_number_molecules for molecule_name in mixture_dict ] + [ water_number_molecules ] number_each_molecule = [ int ( x ) for x in number_each_molecule_ ] for x , y in zip ( number_each_molecule , molecule_number_of_atoms ): molecule_type_beginning_count . append ( sum ( molecule_type_beginning_count [ COUNTER :]) + x * y ) COUNTER += 1 self . molecule_type_beginning_count = molecule_type_beginning_count self . number_each_molecule = number_each_molecule with open ( f ' { operating_folder } /mixture_ { mixture_name } .inp' , 'a' ) as file : file . write ( f 'add_box_sides 1.0' ) arguments = f 'packmol < { operating_folder } /mixture_ { mixture_name } .inp' _ = subprocess . run ( arguments , shell = True )","title":"pack()"},{"location":"background/#mixturemm.background.Simulationsystem","text":"Source code in mixturemm/background.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 class Simulationsystem : def __init__ ( self , Project , Simulationbox , temperature , pressure , ): \"\"\"The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Simulationbox (object): The simulationbox contains all information that is needed to pack each simulation box in packmol. temperature (float): Temperature in kelvin at which the system should be simulated. pressure (float): Pressures in bar at which the system should be simulated. \"\"\" LINKER = '-' self . temperature = temperature self . pressure = pressure self . total_number_molecules = Simulationbox . total_number_molecules self . simulationbox_name = Simulationbox . mixture_name temperature_string = str ( temperature ) pressure_string = str ( pressure ) combined_strings = ( self . simulationbox_name , temperature_string , pressure_string ) system_name = LINKER . join ( combined_strings ) self . name = f ' { system_name } ' self . folder = f ' { Project . workdir } / { system_name } ' self . npt_equilibration_subfolder = f ' { self . folder } /npt_equilibration' self . simulationbox_path = Simulationbox . path self . chi_water = Simulationbox . chi_water directory_maker ( self . folder ) directory_maker ( self . npt_equilibration_subfolder ) self . npt_equilibration_pressure_s = Project . npt_equilibration_pressure_s self . npt_equilibration_pressure_coupling_frequency = Project . npt_equilibration_pressure_coupling_frequency self . npt_equilibration_temperature_coupling_frequency = Project . npt_equilibration_temperature_coupling_frequency self . npt_equilibration_timestep_fs = Project . npt_equilibration_timestep_fs self . npt_equilibration_duration_ns = Project . npt_equilibration_duration_ns self . reporting_frequency_state_npt_equilibration = Project . reporting_frequency_state_npt_equilibration self . cutoff_distance_nm = Project . cutoff_distance_nm self . cutoff_switch_distance_nm = Project . cutoff_switch_distance_nm self . simulation_platform = Project . simulation_platform self . forcefields = Project . forcefields self . npt_equilibration_steps = int (( self . npt_equilibration_duration_ns / self . npt_equilibration_timestep_fs ) * ( 10 ** 6 )) self . openmm_forcefield = ForceField ( * self . forcefields ) self . openmm_platform = Platform . getPlatformByName ( f ' { self . simulation_platform } ' ) self . openmm_properties = Project . simulation_properties self . pme_error_tolerance = Project . pme_error_tolerance self . constraint_tolerance = Project . constraint_tolerance def npt_equilibration ( self ): \"\"\"Runs a NpT equilibration to adjust the box to the correct density using a Monte Carlo barostat. \"\"\" START_TEMPERATURE = 1 TEMPERATURE_STEP = 0.1 heating_interval_steps = int ( 1000 / self . npt_equilibration_timestep_fs ) folder = self . npt_equilibration_subfolder openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm temperature = self . temperature pressure = self . pressure openmm_forcefield = self . openmm_forcefield simulationbox_path = self . simulationbox_path npt_equilibration_pressure_coupling_frequency = self . npt_equilibration_pressure_coupling_frequency npt_equilibration_temperature_coupling_frequency = self . npt_equilibration_temperature_coupling_frequency npt_equilibration_timestep_ps = self . npt_equilibration_timestep_fs * ( 10 ** ( - 3 )) npt_equilibration_steps = self . npt_equilibration_steps reporting_frequency_state_npt_equilibration = self . reporting_frequency_state_npt_equilibration constraint_tolerance = self . constraint_tolerance topology_npt_equilibration = PDBFile ( f ' { simulationbox_path } ' ) system_npt_equilibration = openmm_forcefield . createSystem ( topology_npt_equilibration . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_npt_equilibration = LangevinMiddleIntegrator ( START_TEMPERATURE * kelvin , 10 / picosecond , npt_equilibration_timestep_ps * picoseconds ) integrator_npt_equilibration . setConstraintTolerance ( constraint_tolerance ) barostat_monte_carlo = MonteCarloBarostat ( pressure * bar , temperature * kelvin , 0 ) system_npt_equilibration . addForce ( barostat_monte_carlo ) simulation_npt_equilibration = Simulation ( topology_npt_equilibration . topology , system_npt_equilibration , integrator_npt_equilibration , openmm_platform , openmm_properties ) simulation_npt_equilibration . context . setPositions ( topology_npt_equilibration . positions ) simulation_npt_equilibration . minimizeEnergy ( tolerance = 0.1 * kilojoule / mole , maxIterations = 50000 ) simulation_npt_equilibration . context . setVelocitiesToTemperature ( START_TEMPERATURE * kelvin ) simulation_npt_equilibration . reporters . append ( StateDataReporter ( f ' { folder } /npt_equilibration.csv' , reporting_frequency_state_npt_equilibration , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) for temp in np . arange ( START_TEMPERATURE , temperature , TEMPERATURE_STEP ): integrator_npt_equilibration . setTemperature ( temp * kelvin ) simulation_npt_equilibration . step ( heating_interval_steps ) simulation_npt_equilibration . step ( heating_interval_steps * 10 ) integrator_npt_equilibration . setTemperature ( temperature * kelvin ) integrator_npt_equilibration . setFriction ( npt_equilibration_temperature_coupling_frequency ) barostat_monte_carlo . setFrequency ( npt_equilibration_pressure_coupling_frequency ) simulation_npt_equilibration . step ( npt_equilibration_steps ) system_npt_equilibration . removeForce ( system_npt_equilibration . getNumForces () - 1 ) simulation_npt_equilibration . saveState ( f ' { folder } /npt_equilibration_state.xml' ) endpositions_npt_equilibration = simulation_npt_equilibration . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_npt_equilibration . topology , endpositions_npt_equilibration , open ( f ' { folder } /npt_equilibration_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /npt_equilibration.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /npt_equilibration.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /npt_equilibration.png' , dpi = 300 )","title":"Simulationsystem"},{"location":"background/#mixturemm.background.Simulationsystem.__init__","text":"The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. Parameters: Name Type Description Default Project object The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. required Simulationbox object The simulationbox contains all information that is needed to pack each simulation box in packmol. required temperature float Temperature in kelvin at which the system should be simulated. required pressure float Pressures in bar at which the system should be simulated. required Source code in mixturemm/background.py 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def __init__ ( self , Project , Simulationbox , temperature , pressure , ): \"\"\"The simulationsystem adds the respective temperature and pressure to each box and contains the parameters for the NpT equilibration that is done to adjust the system to the correct density. Args: Project (object): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Simulationbox (object): The simulationbox contains all information that is needed to pack each simulation box in packmol. temperature (float): Temperature in kelvin at which the system should be simulated. pressure (float): Pressures in bar at which the system should be simulated. \"\"\" LINKER = '-' self . temperature = temperature self . pressure = pressure self . total_number_molecules = Simulationbox . total_number_molecules self . simulationbox_name = Simulationbox . mixture_name temperature_string = str ( temperature ) pressure_string = str ( pressure ) combined_strings = ( self . simulationbox_name , temperature_string , pressure_string ) system_name = LINKER . join ( combined_strings ) self . name = f ' { system_name } ' self . folder = f ' { Project . workdir } / { system_name } ' self . npt_equilibration_subfolder = f ' { self . folder } /npt_equilibration' self . simulationbox_path = Simulationbox . path self . chi_water = Simulationbox . chi_water directory_maker ( self . folder ) directory_maker ( self . npt_equilibration_subfolder ) self . npt_equilibration_pressure_s = Project . npt_equilibration_pressure_s self . npt_equilibration_pressure_coupling_frequency = Project . npt_equilibration_pressure_coupling_frequency self . npt_equilibration_temperature_coupling_frequency = Project . npt_equilibration_temperature_coupling_frequency self . npt_equilibration_timestep_fs = Project . npt_equilibration_timestep_fs self . npt_equilibration_duration_ns = Project . npt_equilibration_duration_ns self . reporting_frequency_state_npt_equilibration = Project . reporting_frequency_state_npt_equilibration self . cutoff_distance_nm = Project . cutoff_distance_nm self . cutoff_switch_distance_nm = Project . cutoff_switch_distance_nm self . simulation_platform = Project . simulation_platform self . forcefields = Project . forcefields self . npt_equilibration_steps = int (( self . npt_equilibration_duration_ns / self . npt_equilibration_timestep_fs ) * ( 10 ** 6 )) self . openmm_forcefield = ForceField ( * self . forcefields ) self . openmm_platform = Platform . getPlatformByName ( f ' { self . simulation_platform } ' ) self . openmm_properties = Project . simulation_properties self . pme_error_tolerance = Project . pme_error_tolerance self . constraint_tolerance = Project . constraint_tolerance","title":"__init__()"},{"location":"background/#mixturemm.background.Simulationsystem.npt_equilibration","text":"Runs a NpT equilibration to adjust the box to the correct density using a Monte Carlo barostat. Source code in mixturemm/background.py 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 def npt_equilibration ( self ): \"\"\"Runs a NpT equilibration to adjust the box to the correct density using a Monte Carlo barostat. \"\"\" START_TEMPERATURE = 1 TEMPERATURE_STEP = 0.1 heating_interval_steps = int ( 1000 / self . npt_equilibration_timestep_fs ) folder = self . npt_equilibration_subfolder openmm_properties = self . openmm_properties openmm_platform = self . openmm_platform pme_error_tolerance = self . pme_error_tolerance cutoff_distance_nm = self . cutoff_distance_nm cutoff_switch_distance_nm = self . cutoff_switch_distance_nm temperature = self . temperature pressure = self . pressure openmm_forcefield = self . openmm_forcefield simulationbox_path = self . simulationbox_path npt_equilibration_pressure_coupling_frequency = self . npt_equilibration_pressure_coupling_frequency npt_equilibration_temperature_coupling_frequency = self . npt_equilibration_temperature_coupling_frequency npt_equilibration_timestep_ps = self . npt_equilibration_timestep_fs * ( 10 ** ( - 3 )) npt_equilibration_steps = self . npt_equilibration_steps reporting_frequency_state_npt_equilibration = self . reporting_frequency_state_npt_equilibration constraint_tolerance = self . constraint_tolerance topology_npt_equilibration = PDBFile ( f ' { simulationbox_path } ' ) system_npt_equilibration = openmm_forcefield . createSystem ( topology_npt_equilibration . topology , nonbondedMethod = PME , nonbondedCutoff = cutoff_distance_nm * nanometer , switchDistance = cutoff_switch_distance_nm * nanometer , constraints = HBonds , rigidWater = True , ewaldErrorTolerance = pme_error_tolerance , useDispersionCorrection = True ) integrator_npt_equilibration = LangevinMiddleIntegrator ( START_TEMPERATURE * kelvin , 10 / picosecond , npt_equilibration_timestep_ps * picoseconds ) integrator_npt_equilibration . setConstraintTolerance ( constraint_tolerance ) barostat_monte_carlo = MonteCarloBarostat ( pressure * bar , temperature * kelvin , 0 ) system_npt_equilibration . addForce ( barostat_monte_carlo ) simulation_npt_equilibration = Simulation ( topology_npt_equilibration . topology , system_npt_equilibration , integrator_npt_equilibration , openmm_platform , openmm_properties ) simulation_npt_equilibration . context . setPositions ( topology_npt_equilibration . positions ) simulation_npt_equilibration . minimizeEnergy ( tolerance = 0.1 * kilojoule / mole , maxIterations = 50000 ) simulation_npt_equilibration . context . setVelocitiesToTemperature ( START_TEMPERATURE * kelvin ) simulation_npt_equilibration . reporters . append ( StateDataReporter ( f ' { folder } /npt_equilibration.csv' , reporting_frequency_state_npt_equilibration , time = True , totalEnergy = True , density = True , volume = True , potentialEnergy = True , kineticEnergy = True , temperature = True )) for temp in np . arange ( START_TEMPERATURE , temperature , TEMPERATURE_STEP ): integrator_npt_equilibration . setTemperature ( temp * kelvin ) simulation_npt_equilibration . step ( heating_interval_steps ) simulation_npt_equilibration . step ( heating_interval_steps * 10 ) integrator_npt_equilibration . setTemperature ( temperature * kelvin ) integrator_npt_equilibration . setFriction ( npt_equilibration_temperature_coupling_frequency ) barostat_monte_carlo . setFrequency ( npt_equilibration_pressure_coupling_frequency ) simulation_npt_equilibration . step ( npt_equilibration_steps ) system_npt_equilibration . removeForce ( system_npt_equilibration . getNumForces () - 1 ) simulation_npt_equilibration . saveState ( f ' { folder } /npt_equilibration_state.xml' ) endpositions_npt_equilibration = simulation_npt_equilibration . context . getState ( getPositions = True ) . getPositions () PDBFile . writeFile ( topology_npt_equilibration . topology , endpositions_npt_equilibration , open ( f ' { folder } /npt_equilibration_end.pdb' , 'w' )) df = pd . read_csv ( f ' { folder } /npt_equilibration.csv' ) df . columns = [ \"Time (ps)\" , \"Potential Energy (kJ/mole)\" , \"Kinetic Energy (kJ/mole)\" , \"Total Energy (kJ/mole)\" , \"Temperature (K)\" , \"Box Volume (nm^3)\" , \"Density (g/mL)\" ] fig , axes = plt . subplots ( 2 , 3 , figsize = ( 40 , 20 )) sns . scatterplot ( data = df , ax = axes [ 0 , 0 ], x = \"Time (ps)\" , y = \"Box Volume (nm^3)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 1 ], x = \"Time (ps)\" , y = \"Density (g/mL)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 0 , 2 ], x = \"Time (ps)\" , y = \"Total Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 0 ], x = \"Time (ps)\" , y = \"Temperature (K)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 1 ], x = \"Time (ps)\" , y = \"Potential Energy (kJ/mole)\" , s = 2 , marker = 'o' ) sns . scatterplot ( data = df , ax = axes [ 1 , 2 ], x = \"Time (ps)\" , y = \"Kinetic Energy (kJ/mole)\" , s = 2 , marker = 'o' ) plt . savefig ( f ' { folder } /npt_equilibration.svg' , dpi = 300 ) plt . savefig ( f ' { folder } /npt_equilibration.png' , dpi = 300 )","title":"npt_equilibration()"},{"location":"installation/","text":"Installation \u00b6 Dependencies Be aware that not all dependencies of the package are available on pip. It is therefore recommended to install it into a anaconda environment with OpenMM , packmol , MDAnalysis , mdtraj , seaborn , more-itertools and tidynamics . Alternatively, you can use this txt-file to create an environment with all dependencies on Windows. Stable release \u00b6 To install mixturemm, run this command in your terminal: 1 pip install mixturemm Warning The release is currently under construction, until it is available please use the git clone method. This is the preferred method to install mixturemm, as it will always install the most recent stable release. From sources \u00b6 The sources for mixturemm can be downloaded from the Github repo. You can clone the public repository: 1 git clone git://github.com/FAIRChemistry/mixturemm","title":"Installation"},{"location":"installation/#installation","text":"Dependencies Be aware that not all dependencies of the package are available on pip. It is therefore recommended to install it into a anaconda environment with OpenMM , packmol , MDAnalysis , mdtraj , seaborn , more-itertools and tidynamics . Alternatively, you can use this txt-file to create an environment with all dependencies on Windows.","title":"Installation"},{"location":"installation/#stable-release","text":"To install mixturemm, run this command in your terminal: 1 pip install mixturemm Warning The release is currently under construction, until it is available please use the git clone method. This is the preferred method to install mixturemm, as it will always install the most recent stable release.","title":"Stable release"},{"location":"installation/#from-sources","text":"The sources for mixturemm can be downloaded from the Github repo. You can clone the public repository: 1 git clone git://github.com/FAIRChemistry/mixturemm","title":"From sources"},{"location":"mixturemm/","text":"mixturemm \u00b6 Main module. MIT License Copyright (c) 2021, Benjamin Schmitz Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Forcefield \u00b6 Source code in mixturemm/mixturemm.py 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 class Forcefield : def __init__ ( self , workdir , path_to_XML , ff_name , built_in = True , elements = None ) -> None : \"\"\"Contains information on the force field. Args: workdir (str): The path at which the project is stored. path_to_XML (str): The path to the force field XML file. ff_name (str): The name under which the force field should be stored. built_in (bool, optional): Decides whether the fore field is part of openMM or from an external source. If true, declares that a built in forcefield of openmm will be used. Defaults to True. elements (dict, optional): OpenMM uses Elements to match molecules to the force field. If atomtypes in the force field are unknown to OpenMM, they are registered by giving their name and mass in the form {'name' : mass}. Defaults to None. \"\"\" self . forcedir = f ' { workdir } /forcefield' self . ff_name = ff_name self . built_in = built_in self . elements = elements if built_in == False : shutil . copy ( path_to_XML , f ' { self . forcedir } / { ff_name } .xml' ) self . path = f ' { self . forcedir } / { ff_name } .xml' else : self . path = path_to_XML if elements is not None : for name , mass in elements . items (): _ = elem . Element ( number = 0 , name = name , symbol = name , mass = mass * amu ) __init__ ( workdir , path_to_XML , ff_name , built_in = True , elements = None ) \u00b6 Contains information on the force field. Parameters: Name Type Description Default workdir str The path at which the project is stored. required path_to_XML str The path to the force field XML file. required ff_name str The name under which the force field should be stored. required built_in bool Decides whether the fore field is part of openMM or from an external source. If true, declares that a built in forcefield of openmm will be used. Defaults to True. True elements dict OpenMM uses Elements to match molecules to the force field. If atomtypes in the force field are unknown to OpenMM, they are registered by giving their name and mass in the form {'name' : mass}. Defaults to None. None Source code in mixturemm/mixturemm.py 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 def __init__ ( self , workdir , path_to_XML , ff_name , built_in = True , elements = None ) -> None : \"\"\"Contains information on the force field. Args: workdir (str): The path at which the project is stored. path_to_XML (str): The path to the force field XML file. ff_name (str): The name under which the force field should be stored. built_in (bool, optional): Decides whether the fore field is part of openMM or from an external source. If true, declares that a built in forcefield of openmm will be used. Defaults to True. elements (dict, optional): OpenMM uses Elements to match molecules to the force field. If atomtypes in the force field are unknown to OpenMM, they are registered by giving their name and mass in the form {'name' : mass}. Defaults to None. \"\"\" self . forcedir = f ' { workdir } /forcefield' self . ff_name = ff_name self . built_in = built_in self . elements = elements if built_in == False : shutil . copy ( path_to_XML , f ' { self . forcedir } / { ff_name } .xml' ) self . path = f ' { self . forcedir } / { ff_name } .xml' else : self . path = path_to_XML if elements is not None : for name , mass in elements . items (): _ = elem . Element ( number = 0 , name = name , symbol = name , mass = mass * amu ) Mixture \u00b6 Source code in mixturemm/mixturemm.py 863 864 865 866 867 868 869 870 871 872 873 874 class Mixture : def __init__ ( self , mixture_dict ) -> None : \"\"\"Contains information on the mixture that is simulated. Args: mixture_dict (dict): Dictionary with molecule names and their corresponding mole fraction in the mixture. \"\"\" self . mixture_dict = mixture_dict __init__ ( mixture_dict ) \u00b6 Contains information on the mixture that is simulated. Parameters: Name Type Description Default mixture_dict dict Dictionary with molecule names and their corresponding mole fraction in the mixture. required Source code in mixturemm/mixturemm.py 865 866 867 868 869 870 871 872 873 874 def __init__ ( self , mixture_dict ) -> None : \"\"\"Contains information on the mixture that is simulated. Args: mixture_dict (dict): Dictionary with molecule names and their corresponding mole fraction in the mixture. \"\"\" self . mixture_dict = mixture_dict Molecule \u00b6 Source code in mixturemm/mixturemm.py 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 class Molecule : def __init__ ( self , workdir , name , number_of_atoms , path_to_pdb , abbreviation , smiles , inchi , molar_mass , use_as_water = False ) -> None : \"\"\"Contains information on the molecule that is used for packing with packmol and to identify it. Args: workdir (str): The path at which the project is stored. name (str): Name of the molecule. number_of_atoms (int): The number of atoms that the molecule consists of. path_to_pdb (str): The path to the molecule PDB file. abbreviation (str): The abbreviation of the molecule that is used inside the PDB file. smiles (str): The SMILES code of the molecule. inchi (str): The InChI code of the molecule. molar_mass (str): The molar mass of the molecule. use_as_water (bool, optional): Decides whether the molecule is used as water or not. If used as water, the water molar fraction is applied to it while packing boxes. Defaults to False. \"\"\" self . moldir = f ' { workdir } /molecules' self . name = name self . number_of_atoms = number_of_atoms self . abbreviation = abbreviation self . smiles = smiles self . inchi = inchi self . molar_mass = molar_mass self . use_as_water = False if use_as_water : self . use_as_water = True shutil . copy ( path_to_pdb , f ' { self . moldir } / { self . name } .pdb' ) self . path = f ' { self . moldir } / { self . name } .pdb' __init__ ( workdir , name , number_of_atoms , path_to_pdb , abbreviation , smiles , inchi , molar_mass , use_as_water = False ) \u00b6 Contains information on the molecule that is used for packing with packmol and to identify it. Parameters: Name Type Description Default workdir str The path at which the project is stored. required name str Name of the molecule. required number_of_atoms int The number of atoms that the molecule consists of. required path_to_pdb str The path to the molecule PDB file. required abbreviation str The abbreviation of the molecule that is used inside the PDB file. required smiles str The SMILES code of the molecule. required inchi str The InChI code of the molecule. required molar_mass str The molar mass of the molecule. required use_as_water bool Decides whether the molecule is used as water or not. If used as water, the water molar fraction is applied to it while packing boxes. Defaults to False. False Source code in mixturemm/mixturemm.py 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 def __init__ ( self , workdir , name , number_of_atoms , path_to_pdb , abbreviation , smiles , inchi , molar_mass , use_as_water = False ) -> None : \"\"\"Contains information on the molecule that is used for packing with packmol and to identify it. Args: workdir (str): The path at which the project is stored. name (str): Name of the molecule. number_of_atoms (int): The number of atoms that the molecule consists of. path_to_pdb (str): The path to the molecule PDB file. abbreviation (str): The abbreviation of the molecule that is used inside the PDB file. smiles (str): The SMILES code of the molecule. inchi (str): The InChI code of the molecule. molar_mass (str): The molar mass of the molecule. use_as_water (bool, optional): Decides whether the molecule is used as water or not. If used as water, the water molar fraction is applied to it while packing boxes. Defaults to False. \"\"\" self . moldir = f ' { workdir } /molecules' self . name = name self . number_of_atoms = number_of_atoms self . abbreviation = abbreviation self . smiles = smiles self . inchi = inchi self . molar_mass = molar_mass self . use_as_water = False if use_as_water : self . use_as_water = True shutil . copy ( path_to_pdb , f ' { self . moldir } / { self . name } .pdb' ) self . path = f ' { self . moldir } / { self . name } .pdb' Project \u00b6 Source code in mixturemm/mixturemm.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 class Project : def __init__ ( self , workdir , simulation_platform = 'CUDA' , simulation_properties = { 'DeviceIndex' : '0' , 'Precision' : 'double' }, total_number_molecules = [ 1000 ], init_box_side_length = [ 30 ], chi_water_s = [ 0 , 0.5 , 1 ], temperature_s = [ 298.15 ], npt_equilibration_pressure_s = [ 1 ], npt_equilibration_pressure_coupling_frequency = 25 , npt_equilibration_temperature_coupling_frequency = 0.1 , npt_equilibration_timestep_fs = 2 , npt_equilibration_duration_ns = 10 , reporting_frequency_state_npt_equilibration = 500 , nvt_equilibration_temperature_coupling_frequency = 0.1 , nvt_equilibration_timestep_fs = 2 , nvt_equilibration_duration_ns = 20 , reporting_frequency_state_nvt_equilibration = 2000 , nve_production_timestep_fs = 1 , nve_production_duration_ns = 20 , reporting_frequency_coordinates_unwrapped = 2000 , reporting_frequency_coordinates_wrapped = 4000 , reporting_frequency_state_nve_production = 4000 , replica_count = 10 , pme_error_tolerance = 0.000001 , constraint_tolerance = 0.0000001 , cutoff_distance_nm = 1.2 , cutoff_switch_distance_nm = 1.0 ) -> None : \"\"\"The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Args: workdir (str): The path at which the project should be stored. simulation_platform (str, optional): The platform the simulation should run on. Defaults to 'CUDA'. simulation_properties (dict, optional): The platform properties for the simulation. Defaults to {'DeviceIndex': '0', 'Precision': 'double'}. total_number_molecules (list, optional): A list with the number of molecules that should be placed in the simulation box. Defaults to [1000]. init_box_side_length (list, optional): The initial box side lengths that should be used by packmol. Defaults to [30]. chi_water_s (list, optional): A list with all different molar fractions of water that should be simulated. Defaults to [0,0.5,1]. temperature_s (list, optional): A list with all different temperatures in kelvin at which the boxes should be simulated. Defaults to [298.15]. npt_equilibration_pressure_s (list, optional): A list with all pressures in bar at which the boxes should be simulated. Defaults to [1]. npt_equilibration_pressure_coupling_frequency (int, optional): The pressure coupling frequency at which the Monte Carlo barostat should interact with the system and attempt a Monte Carlo move to adjust the volume during the NpT equilibration in simulation steps. Defaults to 25. npt_equilibration_temperature_coupling_frequency (float, optional): The friction coefficient of the Langevin thermostat during the NpT equilibration in inverse picoseconds. Defaults to 0.1. npt_equilibration_timestep_fs (int, optional): The integration time step during the NpT equilibration in femtoseconds. Defaults to 2. npt_equilibration_duration_ns (int, optional): The duration of the NpT equilibration in nanoseconds. Defaults to 10. reporting_frequency_state_npt_equilibration (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NpT equilibration. Defaults to 500. nvt_equilibration_temperature_coupling_frequency (float, optional): The friction coefficient of the Langevin thermostat during the NVT equilibration in inverse picoseconds. Defaults to 0.1. nvt_equilibration_timestep_fs (int, optional): The integration time step during the NVT equilibration in femtoseconds. Defaults to 2. nvt_equilibration_duration_ns (int, optional): The duration of the NVT equilibration in nanoseconds. Defaults to 20. reporting_frequency_state_nvt_equilibration (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NVT equilibration. Defaults to 2000. nve_production_timestep_fs (int, optional): The integration time step during the NVE production in femtoseconds. Defaults to 1. nve_production_duration_ns (int, optional): The duration of the NVE production in nanoseconds. Defaults to 20. reporting_frequency_coordinates_unwrapped (int, optional): The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. Defaults to 2000. reporting_frequency_coordinates_wrapped (int, optional): The reporting frequency of the trajectory with wrapped coordinates in simulation steps during the NVE production. Defaults to 4000. reporting_frequency_state_nve_production (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NVE production. Defaults to 4000. replica_count (int, optional): The number of times the simulation of one system should be replicated. Defaults to 10. pme_error_tolerance (float, optional): Decides how large the grid for PME is together with the cutoff. Defaults to 0.000001. constraint_tolerance (float, optional): The constraint tolerance specifies the distance tolerance within which constraints are maintained, as a fraction of the constrained distance. Defaults to 0.0000001 cutoff_distance_nm (float, optional): The cutoff distance for nonbonded interactions in nanometers. Defaults to 1.2. cutoff_switch_distance_nm (float, optional): Starting point of the switching function that makes the energy go smoothly to 0 at the cutoff distance in nanometers. Defaults to 1.0. \"\"\" self . workdir = m_utils . directory_maker ( workdir ) self . moldir = m_utils . directory_maker ( f ' { self . workdir } /molecules' ) self . boxdir = m_utils . directory_maker ( f ' { self . workdir } /boxes' ) self . resdir = m_utils . directory_maker ( f ' { self . workdir } /results' ) self . submitdir = m_utils . directory_maker ( f ' { self . workdir } /hpc_submission' ) self . forcedir = m_utils . directory_maker ( f ' { self . workdir } /forcefield' ) self . res_rawdir = m_utils . directory_maker ( f ' { self . resdir } /raw_data' ) self . res_partsdir = m_utils . directory_maker ( f ' { self . resdir } /parts' ) self . molecules = [] self . simulation_boxes = [] self . simulationsystems = [] self . replicas = [] self . molecule_names = [] self . molecule_number_of_atoms = [] self . molecule_abbreviations = [] self . mixture_dict = {} self . forcefields = [] self . elements = {} self . chi_water_s = chi_water_s self . total_number_molecules = total_number_molecules self . init_box_side_length = init_box_side_length self . water_name = 'Water' self . water_abbreviation = 'HOH' self . replica_number_dict = None self . simulation_platform = simulation_platform self . simulation_properties = simulation_properties self . temperature_s = temperature_s self . npt_equilibration_pressure_s = npt_equilibration_pressure_s self . npt_equilibration_pressure_coupling_frequency = npt_equilibration_pressure_coupling_frequency self . npt_equilibration_temperature_coupling_frequency = npt_equilibration_temperature_coupling_frequency self . npt_equilibration_timestep_fs = npt_equilibration_timestep_fs self . npt_equilibration_duration_ns = npt_equilibration_duration_ns self . nvt_equilibration_temperature_coupling_frequency = nvt_equilibration_temperature_coupling_frequency self . nvt_equilibration_timestep_fs = nvt_equilibration_timestep_fs self . nvt_equilibration_duration_ns = nvt_equilibration_duration_ns self . nve_production_timestep_fs = nve_production_timestep_fs self . nve_production_duration_ns = nve_production_duration_ns self . reporting_frequency_coordinates_unwrapped = reporting_frequency_coordinates_unwrapped self . reporting_frequency_coordinates_wrapped = reporting_frequency_coordinates_wrapped self . reporting_frequency_state_npt_equilibration = reporting_frequency_state_npt_equilibration self . reporting_frequency_state_nvt_equilibration = reporting_frequency_state_nvt_equilibration self . reporting_frequency_state_nve_production = reporting_frequency_state_nve_production self . replica_count = replica_count self . pme_error_tolerance = pme_error_tolerance self . constraint_tolerance = constraint_tolerance self . cutoff_distance_nm = cutoff_distance_nm self . cutoff_switch_distance_nm = cutoff_switch_distance_nm self . half_npt_equilibration_csv_columns = int (((( self . npt_equilibration_duration_ns / self . npt_equilibration_timestep_fs ) * ( 10 ** 6 )) / reporting_frequency_state_npt_equilibration ) / 2 ) self . create_description () m_utils . add_chainsubmitter_script ( self . submitdir ) def create_description ( self ) -> None : \"\"\"Creates a .json file with all input arguments of the project and info on all added files. \"\"\" json_structure = m_utils . jsonize_project ( self ) if os . path . isfile ( f ' { self . workdir } /project_description.json' ) == False : with open ( f ' { self . workdir } /project_description.json' , 'w' , encoding = 'utf-8' ) as f : json . dump ( json_structure , f , ensure_ascii = False , indent = 4 ) else : m_utils . merge_project_descriptions ( f ' { self . workdir } /project_description.json' , json_structure ) self . description = f ' { self . workdir } /project_description.json' def add_molecule ( self , Molecule ) -> None : \"\"\"Adds a molecule to the project. Args: Molecule (object): Contains information on the molecule that is used for packing with packmol and to identify it. \"\"\" if Molecule . use_as_water : self . water_name = Molecule . name self . water_abbreviation = Molecule . abbreviation else : self . molecules . append ( Molecule ) self . molecule_names . append ( Molecule . name ) self . molecule_number_of_atoms . append ( Molecule . number_of_atoms ) self . molecule_abbreviations . append ( Molecule . abbreviation ) json_structure = m_utils . jsonize_molecule ( Molecule ) m_utils . add_json_entry ( f ' { self . description } ' , json_structure , key = 'molecules' , subkey = f ' { Molecule . name } ' ) def add_forcefield ( self , Forcefield ) -> None : \"\"\"Adds a force field to the project. Args: Forcefield (object): Contains information on the force field. \"\"\" self . forcefields . append ( Forcefield . path ) if Forcefield . elements is not None : self . elements . update ( Forcefield . elements ) json_structure = m_utils . jsonize_forcefield ( Forcefield ) m_utils . add_json_entry ( f ' { self . description } ' , json_structure , key = 'force fields' , subkey = f ' { Forcefield . ff_name } ' ) def add_mixture ( self , Mixture ) -> None : \"\"\"Adds a mixture to the project. Args: Mixture (object): Contains information on the mixture that is simulated. \"\"\" self . mixture_dict = Mixture . mixture_dict def create_simulationboxes ( self ) -> None : \"\"\"Creates and packs the simulation boxes. \"\"\" LINKER = '-' for total_number_molecules , init_box_side_length in zip ( self . total_number_molecules , self . init_box_side_length ): for chi_water in self . chi_water_s : string_total_number_molecules = str ( total_number_molecules ) string_init_box_side_length = str ( init_box_side_length ) string_chi_water = str ( chi_water ) mixture_tuple = ( string_total_number_molecules , string_init_box_side_length , string_chi_water ) mixture_name = LINKER . join ( mixture_tuple ) simulation_box = Simulationbox ( self , total_number_molecules , init_box_side_length , chi_water , self . water_name , mixture_name ) self . simulation_boxes . append ( simulation_box ) for x in self . simulation_boxes : x . pack () x . conect_creator () def create_systems ( self ) -> None : \"\"\"Assigns temperature, pressure and NpT equilibration parameters to the boxes. \"\"\" parameter_list = [ self . simulation_boxes , self . temperature_s , self . npt_equilibration_pressure_s ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : simulationbox , temperature , pressure = combination system = Simulationsystem ( self , simulationbox , temperature , pressure ) self . simulationsystems . append ( system ) def create_replicas ( self , start = 1 ) -> None : \"\"\"Creates replicas of the systems and assigns NVT equilibration and NVE production parameters to them. Args: start (int, optional): The number from which on the replica numbering will start. Defaults to 1. \"\"\" self . replica_start = start replica_count = range ( start , ( self . replica_count + start )) self . replica_number_dict = {} for tot in self . total_number_molecules : self . replica_number_dict [ f ' { tot } ' ] = self . replica_count parameter_list = [ self . simulationsystems , replica_count ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : system , replica_number = combination replica = Replica ( self , system , replica_number ) self . replicas . append ( replica ) m_utils . add_json_entry ( f ' { self . description } ' , start , key = 'project' , subkey = 'simulation_parameters' , subsubkey = 'replica_starting_number' ) def adjust_to_correct_density ( self ) -> None : \"\"\"Runs the NpT equilibration to adjust the system volume and density to the correct value. \"\"\" for system in self . simulationsystems : system . npt_equilibration () def simulate ( self ) -> None : \"\"\"Runs the NVT equilibration and the NVE production. \"\"\" for replica in self . replicas : replica . nvt_equilibration () replica . nve_production () def create_hpc_submission_adjust_to_correct_density ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the NpT equilibration. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'accelerated'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. number_of_gpus (int, optional): The number of GPUs requested on a node. Defaults to 4. chunk_size (int, optional): Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. max_number_of_jobs (int, optional): Maximum number of job submissions allowed on the hpc. Defaults to None. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. chain_submission_number (int, optional): The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. dependency_type (str, optional): Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. checkpoint_frequency (int, optional): The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. \"\"\" forcefields_ = [ re . sub ( r '^.*?/forcefield' , f ' { hpc_folder } /forcefield' , forcefield ) for forcefield in self . forcefields ] forcefields = ',' . join ( forcefields_ ) if self . elements : elements = m_utils . bash_arg_prepper ( self . elements ) else : elements = None if max_number_of_jobs is None : chunked_simulationsystems = [ self . simulationsystems [ i : i + chunk_size ] for i in range ( 0 , len ( self . simulationsystems ), chunk_size )] else : chunked_simulationsystems = [ self . simulationsystems [ i : i + chunk_size ] for i in range ( 0 , len ( self . simulationsystems ), chunk_size )][: max_number_of_jobs ] for chunk in chunked_simulationsystems : GPU_INDEX_COUNTER = 0 m_utils . hpc_submission_header ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , f ' { id ( chunk ) } _adjust_to_correct_density' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) for system in chunk : with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , 'a' , newline = ' \\n ' ) as file : if 'DeviceIndex' and 'Precision' in self . simulation_properties : simulation_properties_ = self . simulation_properties simulation_properties_ [ 'DeviceIndex' ] = f ' { GPU_INDEX_COUNTER } ' simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) else : simulation_properties_ = { 'DeviceIndex' : f ' { GPU_INDEX_COUNTER } ' , 'Precision' : 'double' } simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) if self . simulation_platform == 'CUDA' : simulation_platform = self . simulation_platform else : simulation_platform = 'CUDA' file . write ( f 'python { hpc_scripts_folder } /cluster_adjust_to_correct_density.py { hpc_folder } { simulation_properties } { simulation_platform } { forcefields } { system . pme_error_tolerance } { system . cutoff_distance_nm } { system . cutoff_switch_distance_nm } { system . name } { system . temperature } { system . pressure } { system . simulationbox_name } { system . npt_equilibration_pressure_coupling_frequency } { system . npt_equilibration_temperature_coupling_frequency } { system . npt_equilibration_timestep_fs } { system . npt_equilibration_steps } { system . reporting_frequency_state_npt_equilibration } { system . constraint_tolerance } { checkpoint_frequency } { elements } & \\n ' ) GPU_INDEX_COUNTER += 1 with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( ' \\n wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_adjust_to_correct_density.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for chunk in chunked_simulationsystems : if chain_submission_number > 1 : file . write ( f '''bash chainsubmitter.sh { chain_submission_number } { hpc_folder } /shfiles/chunk { id ( chunk ) } _adjust_to_correct_density.sh { dependency_type } { partition } \\n ''' ) else : file . write ( f '''sbatch chunk { id ( chunk ) } _adjust_to_correct_density.sh \\n ''' ) def create_hpc_submission_simulate ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 containing the NVT equilibration and NVE production. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'accelerated'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. number_of_gpus (int, optional): The number of GPUs requested on a node. Defaults to 4. chunk_size (int, optional): Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. max_number_of_jobs (int, optional): Maximum number of job submissions allowed on the hpc. Defaults to None. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. chain_submission_number (int, optional): The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. dependency_type (str, optional): Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. checkpoint_frequency (int, optional): The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. \"\"\" forcefields_ = [ re . sub ( r '^.*?/forcefield' , f ' { hpc_folder } /forcefield' , forcefield ) for forcefield in self . forcefields ] forcefields = ',' . join ( forcefields_ ) if self . elements : elements = m_utils . bash_arg_prepper ( self . elements ) else : elements = None if max_number_of_jobs is None : chunked_replicas = [ self . replicas [ i : i + chunk_size ] for i in range ( 0 , len ( self . replicas ), chunk_size )] else : chunked_replicas = [ self . replicas [ i : i + chunk_size ] for i in range ( 0 , len ( self . replicas ), chunk_size )][: max_number_of_jobs ] for chunk in chunked_replicas : GPU_INDEX_COUNTER = 0 m_utils . hpc_submission_header ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , f ' { id ( chunk ) } _simulate' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) for replica in chunk : with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , 'a' , newline = ' \\n ' ) as file : if 'DeviceIndex' and 'Precision' in self . simulation_properties : simulation_properties_ = self . simulation_properties simulation_properties_ [ 'DeviceIndex' ] = f ' { GPU_INDEX_COUNTER } ' simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) else : simulation_properties_ = { 'DeviceIndex' : f ' { GPU_INDEX_COUNTER } ' , 'Precision' : 'double' } simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) if self . simulation_platform == 'CUDA' : simulation_platform = self . simulation_platform else : simulation_platform = 'CUDA' file . write ( f 'python { hpc_scripts_folder } /cluster_simulate.py { hpc_folder } { simulation_properties } { simulation_platform } { forcefields } { replica . pme_error_tolerance } { replica . cutoff_distance_nm } { replica . cutoff_switch_distance_nm } { replica . name } { replica . replica_number } { replica . temperature } { replica . half_npt_equilibration_csv_columns } { replica . nvt_equilibration_temperature_coupling_frequency } { replica . nvt_equilibration_steps } { replica . nvt_equilibration_timestep_fs } { replica . reporting_frequency_state_nvt_equilibration } { replica . nve_production_timestep_fs } { replica . nve_production_steps } { replica . reporting_frequency_coordinates_unwrapped } { replica . reporting_frequency_coordinates_wrapped } { replica . reporting_frequency_state_nve_production } { checkpoint_frequency } { replica . constraint_tolerance } { elements } & \\n ' ) GPU_INDEX_COUNTER += 1 with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( ' \\n wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_simulate.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for chunk in chunked_replicas : if chain_submission_number > 1 : file . write ( f '''bash chainsubmitter.sh { chain_submission_number } { hpc_folder } /shfiles/chunk { id ( chunk ) } _simulate.sh { dependency_type } { partition } \\n ''' ) else : file . write ( f '''sbatch chunk { id ( chunk ) } _simulate.sh \\n ''' ) def create_hpc_submission_analyze_density ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , max_runtime_hh_mm_ss = '00:10:00' , conda_module = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 containing the density anlysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '00:10:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) molecule_names , chi_water_s , temperature_s , npt_equilibration_pressure_s , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , [ system . name for system in self . simulationsystems ]) chunked_simulationsystems = [ self . simulationsystems [ i : i + 10 ] for i in range ( 0 , len ( self . simulationsystems ), 10 )] m_utils . hpc_submission_header ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , f 'id { id ( self . simulationsystems ) } _analyze_density' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in chunked_simulationsystems : for system in chunk : with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_density.py { hpc_folder } { system . name } { self . half_npt_equilibration_csv_columns } { system . total_number_molecules } { system . temperature } { system . pressure } { system . chi_water } { molecule_names } & \\n ' ) with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_join_density.py { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { hpc_folder } { name_list } { molecule_names } { self . water_name } { description } & \\n ' ) file . write ( 'wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_density_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n sbatch id { id ( self . simulationsystems ) } _analyze_density.sh \\n ''' ) def create_hpc_submission_analyze_msd ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , fit_starting_percentage = 20 , fit_ending_percentage = 80 , just_conclude = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. parallel_running (int, optional): The number of replica analyses running in parallel. Defaults to 5. submission_split (int, optional): The number of job submissions the analysis is split in. Defaults to 4. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. fit_starting_percentage (int, optional): Start of the linear fit in percent of NVE production duration. Defaults to 20. fit_ending_percentage (int, optional): Ending of the linear fit in percent of NVE production duration. Defaults to 80. just_conclude (bool, optional): If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) fit_starting_frame , fit_ending_frame , time_between_frames = m_utils . msd_opt_prepper ( self . nve_production_timestep_fs , self . nve_production_duration_ns , self . reporting_frequency_coordinates_unwrapped , fit_starting_percentage , fit_ending_percentage ) molecule_names , molecule_abbreviations , number_dict , total_number_molecules , chi_water_s , temperature_s , npt_equilibration_pressure_s , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . molecule_abbreviations , self . replica_number_dict , self . total_number_molecules , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , [ system . name for system in self . simulationsystems ]) chunked_replicas = [ self . replicas [ i : i + parallel_running ] for i in range ( 0 , len ( self . replicas ), parallel_running )] split_fac = int ( len ( chunked_replicas ) / submission_split ) submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if len ( submission_splits ) > submission_split : split_fac = int ( len ( chunked_replicas ) / submission_split ) + 1 submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if not just_conclude : for split in submission_splits : m_utils . hpc_submission_header ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , f 'split { id ( split ) } _analyze_msd' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in split : for replica in chunk : with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_sdc.py { hpc_folder } { replica . name } { replica . replica_number } { replica . chi_water } { self . water_abbreviation } { molecule_abbreviations } { time_between_frames } { fit_starting_frame } { fit_ending_frame } { replica . temperature } { replica . pressure } { replica . total_number_molecules } { molecule_names } { self . water_name } & \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'exit 0' ) with open ( f ' { self . submitdir } /submit_msd_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for split in submission_splits : file . write ( f '''sbatch split { id ( split ) } _analyze_msd.sh \\n ''' ) with open ( f ' { self . submitdir } /conclude_msd.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) file . write ( f 'source { hpc_workspace } /conda/etc/profile.d/conda.sh \\n ' ) file . write ( f 'conda activate { environment_name } \\n ' ) file . write ( f 'python { hpc_scripts_folder } /cluster_join_sdc_and_comp_visc.py { total_number_molecules } { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { hpc_folder } { name_list } { molecule_names } { self . water_name } { number_dict } { molecule_abbreviations } { self . water_abbreviation } { description } { self . replica_start } & \\n ' ) file . write ( 'wait \\n exit 0' ) def create_hpc_submission_analyze_hbonds ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , donors = 'donor_selection_string' , hydrogens = 'hydrogen_selection_string' , acceptors = 'acceptors_selection_string' , just_conclude = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. parallel_running (int, optional): The number of replica analyses running in parallel. Defaults to 5. submission_split (int, optional): The number of job submissions the analysis is split in. Defaults to 4. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. donors (str, optional): Selection of all hydrogen bond donor atoms in MDAnalysis selection syntax. Defaults to 'donor_selection_string'. hydrogens (str, optional): Selection of all hydrogen bond hydrogen atoms in MDAnalysis selection syntax. Defaults to 'hydrogens_selection_string'. acceptors (str, optional): Selection of all hydrogen bond acceptor atoms in MDAnalysis selection syntax. Defaults to 'acceptors_selection_string'. just_conclude (bool, optional): If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) molecule_names , number_dict , chi_water_s , temperature_s , npt_equilibration_pressure_s , molecule_abbreviations , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . replica_number_dict , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , self . molecule_abbreviations , [ system . name for system in self . simulationsystems ]) chunked_replicas = [ self . replicas [ i : i + parallel_running ] for i in range ( 0 , len ( self . replicas ), parallel_running )] split_fac = int ( len ( chunked_replicas ) / submission_split ) submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if len ( submission_splits ) > submission_split : split_fac = int ( len ( chunked_replicas ) / submission_split ) + 1 submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if not just_conclude : for split in submission_splits : m_utils . hpc_submission_header ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , f 'split { id ( split ) } _analyze_hbonds' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in split : for replica in chunk : with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_hbonds.py { hpc_folder } { replica . name } { replica . replica_number } { replica . chi_water } { replica . temperature } { replica . pressure } { replica . total_number_molecules } { molecule_names } \" { donors } \" \" { hydrogens } \" \" { acceptors } \" & \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'exit 0' ) with open ( f ' { self . submitdir } /submit_hbonds_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for split in submission_splits : file . write ( f '''sbatch split { id ( split ) } _analyze_hbonds.sh \\n ''' ) with open ( f ' { self . submitdir } /conclude_hbonds.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) file . write ( f 'source { hpc_workspace } /conda/etc/profile.d/conda.sh \\n ' ) file . write ( f 'conda activate { environment_name } \\n ' ) file . write ( f 'python { hpc_scripts_folder } /cluster_join_hbonds.py { hpc_folder } { name_list } { number_dict } { description } { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { molecule_names } { self . water_name } { molecule_abbreviations } { self . water_abbreviation } { self . replica_start } & \\n ' ) file . write ( 'wait \\n exit 0' ) def hpc_extend_replica_folders ( self , hpc_folder = 'workspace/project_name' ) -> None : \"\"\"Creates newly added replica folders to the system folders on the hpc. Args: hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. \"\"\" folder_list = [] for replica in self . replicas : folder_list . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder } / { replica . name } ' , replica . folder )) with open ( f ' { self . submitdir } /extend_replica_folders.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash ''' ) for folder_string in folder_list : file . write ( f '''mkdir { folder_string } ''' ) def hpc_job_checker ( self , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , hpc_workspace = 'workspace' , environment_name = 'openmm_new' , verbose = True , energy_shift_tolerance_percent = 1 ) -> None : \"\"\"Creates a bash script to check the overall status of the simulations on the hpc. Checked properties are doneness percent, average temperature and total energy shift. Args: hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmm_new'. verbose (bool, optional): If true checks average temperature and total energy shift. Defaults to True. energy_shift_tolerance_percent (int, optional): The tolerated energy shift in percent. If the energy shift of a simulation is greater, a warning is issued. Defaults to 1. \"\"\" system_file_list_ = [] for system in self . simulationsystems : system_file_list_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder } / { system . name } ' , system . folder )) system_file_list = sorted ( system_file_list_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) with open ( f ' { self . submitdir } /system_list.txt' , 'w' , newline = ' \\n ' ) as file : for file_str in system_file_list : file . write ( f ''' { file_str } ''' ) replica_file_list_ = [] for replica in self . replicas : replica_file_list_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder } / { replica . name } ' , replica . folder )) replica_file_list = sorted ( replica_file_list_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) replica_file_list . append ( 'finalize' ) with open ( f ' { self . submitdir } /replica_list.txt' , 'w' , newline = ' \\n ' ) as file : for file_str in replica_file_list : file . write ( f ''' { file_str } ''' ) with open ( f ' { self . submitdir } /job_checker.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash source { hpc_workspace } /conda/etc/profile.d/conda.sh conda activate { environment_name } python { hpc_scripts_folder } /job_checker.py { self . nvt_equilibration_duration_ns } { self . nve_production_duration_ns } { verbose } { energy_shift_tolerance_percent } { self . npt_equilibration_duration_ns } exit 0 ''' ) def remove_done_jobs_from_systems ( self , path_to_job_checks = 'workdir/job_checks.txt' ) -> None : \"\"\"Removes all systems that are done according to the job checker from the project. Args: path_to_job_checks (str, optional): The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. \"\"\" with open ( f ' { path_to_job_checks } ' , 'r' , newline = ' \\n ' ) as file : not_done_job_list_ = [ line . rstrip () for line in file if 'not yet adjusted' in line ] not_done_job_list = [ item [: - 17 ] for item in not_done_job_list_ ] filtered_systems = [] for system in self . simulationsystems : for string in not_done_job_list : if system . name in string : filtered_systems . append ( system ) self . simulationsystems = filtered_systems def remove_done_jobs_from_replicas ( self , path_to_job_checks = 'workdir/job_checks.txt' ) -> None : \"\"\"Removes all replicas that are done according to the job checker from the project. Args: path_to_job_checks (str, optional): The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. \"\"\" with open ( f ' { path_to_job_checks } ' , 'r' , newline = ' \\n ' ) as file : not_done_job_list_ = [ line . rstrip () for line in file if 'not yet finished' in line ] not_done_job_list = [ item [: - 17 ] for item in not_done_job_list_ ] filtered_replicas = [] for replica in self . replicas : for string in not_done_job_list : if replica . name in string and int ( re . search ( r '\\d+$' , string ) . group ()) == replica . replica_number : filtered_replicas . append ( replica ) self . replicas = filtered_replicas def overcharge_replicas ( self , total_number_molecules = 1000 , overcharge_amount = 10 ) -> None : \"\"\"Adds the overcharge amount to the replicas of the systems specified by total number of molecules. Args: total_number_molecules (int, optional): Number of molecules that are placed in the simulation box. Defaults to 1000. overcharge_amount (int, optional): Amount of replicas that should be added. Defaults to 10. \"\"\" filtered_systems = [ system for system in self . simulationsystems if system . total_number_molecules in total_number_molecules ] replica_count = range (( self . replica_count + self . replica_start ), ( self . replica_count + self . replica_start + overcharge_amount )) parameter_list = [ filtered_systems , replica_count ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : system , replica_number = combination replica = Replica ( self , system , replica_number ) self . replicas . append ( replica ) entry = f 'with { overcharge_amount } replicas' m_utils . add_json_entry ( f ' { self . description } ' , entry , key = 'project' , subkey = 'simulation_parameters' , subsubkey = 'overcharged_boxes' , subsubsubkey = f ' { total_number_molecules } molecules' ) self . replica_number_dict [ f ' { total_number_molecules } ' ] = self . replica_count + self . replica_start + overcharge_amount def transfer_project ( self , hpc_folder_old = 'workspace_old/project_name' , hpc_folder_new = 'workspace_new/project_name' ) -> None : \"\"\"Transfers a project between two workspaces. Args: hpc_folder_old (str, optional): The path to the old project folder on the hpc. Defaults to 'workspace_old/project_name'. hpc_folder_new (str, optional): The path to the new project folder on the hpc. Defaults to 'workspace_new/project_name'. \"\"\" system_file_list_old_ = [] system_file_list_new_ = [] for system in self . simulationsystems : system_file_list_old_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder_old } / { system . name } ' , system . folder )) system_file_list_new_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder_new } / { system . name } ' , system . folder )) system_file_list_old = sorted ( system_file_list_old_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) system_file_list_new = sorted ( system_file_list_new_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) with open ( f ' { self . submitdir } /transfer_project.py' , 'w' , newline = ' \\n ' ) as file : file . write ( 'import shutil \\n ' ) for file_str_old , file_str_new in zip ( system_file_list_old , system_file_list_new ): file . write ( f '''shutil.copytree(r\" { file_str_old } /npt_equilibration\", r\" { file_str_new } /npt_equilibration\") ''' ) replica_file_list_old_ = [] replica_file_list_new_ = [] for replica in self . replicas : replica_file_list_old_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder_old } / { replica . name } ' , replica . folder )) replica_file_list_new_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder_new } / { replica . name } ' , replica . folder )) replica_file_list_old = sorted ( replica_file_list_old_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) replica_file_list_new = sorted ( replica_file_list_new_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) with open ( f ' { self . submitdir } /transfer_project.py' , 'a' , newline = ' \\n ' ) as file : for file_str_old , file_str_new in zip ( replica_file_list_old , replica_file_list_new ): file . write ( f '''shutil.copytree(r\" { file_str_old } \", r\" { file_str_new } \") ''' ) with open ( f ' { self . submitdir } /transfer_project.py' , 'a' , newline = ' \\n ' ) as file : file . write ( f '''shutil.copytree(r\" { hpc_folder_old } /boxes\", r\" { hpc_folder_new } /boxes\") shutil.copytree(r\" { hpc_folder_old } /forcefield\", r\" { hpc_folder_new } /forcefield\") shutil.copytree(r\" { hpc_folder_old } /hpc_submission\", r\" { hpc_folder_new } /hpc_submission\") shutil.copytree(r\" { hpc_folder_old } /molecules\", r\" { hpc_folder_new } /molecules\") shutil.copytree(r\" { hpc_folder_old } /results\", r\" { hpc_folder_new } /results\") ''' ) __init__ ( workdir , simulation_platform = 'CUDA' , simulation_properties = { 'DeviceIndex' : '0' , 'Precision' : 'double' }, total_number_molecules = [ 1000 ], init_box_side_length = [ 30 ], chi_water_s = [ 0 , 0.5 , 1 ], temperature_s = [ 298.15 ], npt_equilibration_pressure_s = [ 1 ], npt_equilibration_pressure_coupling_frequency = 25 , npt_equilibration_temperature_coupling_frequency = 0.1 , npt_equilibration_timestep_fs = 2 , npt_equilibration_duration_ns = 10 , reporting_frequency_state_npt_equilibration = 500 , nvt_equilibration_temperature_coupling_frequency = 0.1 , nvt_equilibration_timestep_fs = 2 , nvt_equilibration_duration_ns = 20 , reporting_frequency_state_nvt_equilibration = 2000 , nve_production_timestep_fs = 1 , nve_production_duration_ns = 20 , reporting_frequency_coordinates_unwrapped = 2000 , reporting_frequency_coordinates_wrapped = 4000 , reporting_frequency_state_nve_production = 4000 , replica_count = 10 , pme_error_tolerance = 1e-06 , constraint_tolerance = 1e-07 , cutoff_distance_nm = 1.2 , cutoff_switch_distance_nm = 1.0 ) \u00b6 The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Parameters: Name Type Description Default workdir str The path at which the project should be stored. required simulation_platform str The platform the simulation should run on. Defaults to 'CUDA'. 'CUDA' simulation_properties dict The platform properties for the simulation. Defaults to {'DeviceIndex': '0', 'Precision': 'double'}. {'DeviceIndex': '0', 'Precision': 'double'} total_number_molecules list A list with the number of molecules that should be placed in the simulation box. Defaults to [1000]. [1000] init_box_side_length list The initial box side lengths that should be used by packmol. Defaults to [30]. [30] chi_water_s list A list with all different molar fractions of water that should be simulated. Defaults to [0,0.5,1]. [0, 0.5, 1] temperature_s list A list with all different temperatures in kelvin at which the boxes should be simulated. Defaults to [298.15]. [298.15] npt_equilibration_pressure_s list A list with all pressures in bar at which the boxes should be simulated. Defaults to [1]. [1] npt_equilibration_pressure_coupling_frequency int The pressure coupling frequency at which the Monte Carlo barostat should interact with the system and attempt a Monte Carlo move to adjust the volume during the NpT equilibration in simulation steps. Defaults to 25. 25 npt_equilibration_temperature_coupling_frequency float The friction coefficient of the Langevin thermostat during the NpT equilibration in inverse picoseconds. Defaults to 0.1. 0.1 npt_equilibration_timestep_fs int The integration time step during the NpT equilibration in femtoseconds. Defaults to 2. 2 npt_equilibration_duration_ns int The duration of the NpT equilibration in nanoseconds. Defaults to 10. 10 reporting_frequency_state_npt_equilibration int The reporting frequency of the openMM StateDataReporter in simulation steps during the NpT equilibration. Defaults to 500. 500 nvt_equilibration_temperature_coupling_frequency float The friction coefficient of the Langevin thermostat during the NVT equilibration in inverse picoseconds. Defaults to 0.1. 0.1 nvt_equilibration_timestep_fs int The integration time step during the NVT equilibration in femtoseconds. Defaults to 2. 2 nvt_equilibration_duration_ns int The duration of the NVT equilibration in nanoseconds. Defaults to 20. 20 reporting_frequency_state_nvt_equilibration int The reporting frequency of the openMM StateDataReporter in simulation steps during the NVT equilibration. Defaults to 2000. 2000 nve_production_timestep_fs int The integration time step during the NVE production in femtoseconds. Defaults to 1. 1 nve_production_duration_ns int The duration of the NVE production in nanoseconds. Defaults to 20. 20 reporting_frequency_coordinates_unwrapped int The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. Defaults to 2000. 2000 reporting_frequency_coordinates_wrapped int The reporting frequency of the trajectory with wrapped coordinates in simulation steps during the NVE production. Defaults to 4000. 4000 reporting_frequency_state_nve_production int The reporting frequency of the openMM StateDataReporter in simulation steps during the NVE production. Defaults to 4000. 4000 replica_count int The number of times the simulation of one system should be replicated. Defaults to 10. 10 pme_error_tolerance float Decides how large the grid for PME is together with the cutoff. Defaults to 0.000001. 1e-06 constraint_tolerance float The constraint tolerance specifies the distance tolerance within which constraints are maintained, as a fraction of the constrained distance. Defaults to 0.0000001 1e-07 cutoff_distance_nm float The cutoff distance for nonbonded interactions in nanometers. Defaults to 1.2. 1.2 cutoff_switch_distance_nm float Starting point of the switching function that makes the energy go smoothly to 0 at the cutoff distance in nanometers. Defaults to 1.0. 1.0 Source code in mixturemm/mixturemm.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def __init__ ( self , workdir , simulation_platform = 'CUDA' , simulation_properties = { 'DeviceIndex' : '0' , 'Precision' : 'double' }, total_number_molecules = [ 1000 ], init_box_side_length = [ 30 ], chi_water_s = [ 0 , 0.5 , 1 ], temperature_s = [ 298.15 ], npt_equilibration_pressure_s = [ 1 ], npt_equilibration_pressure_coupling_frequency = 25 , npt_equilibration_temperature_coupling_frequency = 0.1 , npt_equilibration_timestep_fs = 2 , npt_equilibration_duration_ns = 10 , reporting_frequency_state_npt_equilibration = 500 , nvt_equilibration_temperature_coupling_frequency = 0.1 , nvt_equilibration_timestep_fs = 2 , nvt_equilibration_duration_ns = 20 , reporting_frequency_state_nvt_equilibration = 2000 , nve_production_timestep_fs = 1 , nve_production_duration_ns = 20 , reporting_frequency_coordinates_unwrapped = 2000 , reporting_frequency_coordinates_wrapped = 4000 , reporting_frequency_state_nve_production = 4000 , replica_count = 10 , pme_error_tolerance = 0.000001 , constraint_tolerance = 0.0000001 , cutoff_distance_nm = 1.2 , cutoff_switch_distance_nm = 1.0 ) -> None : \"\"\"The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Args: workdir (str): The path at which the project should be stored. simulation_platform (str, optional): The platform the simulation should run on. Defaults to 'CUDA'. simulation_properties (dict, optional): The platform properties for the simulation. Defaults to {'DeviceIndex': '0', 'Precision': 'double'}. total_number_molecules (list, optional): A list with the number of molecules that should be placed in the simulation box. Defaults to [1000]. init_box_side_length (list, optional): The initial box side lengths that should be used by packmol. Defaults to [30]. chi_water_s (list, optional): A list with all different molar fractions of water that should be simulated. Defaults to [0,0.5,1]. temperature_s (list, optional): A list with all different temperatures in kelvin at which the boxes should be simulated. Defaults to [298.15]. npt_equilibration_pressure_s (list, optional): A list with all pressures in bar at which the boxes should be simulated. Defaults to [1]. npt_equilibration_pressure_coupling_frequency (int, optional): The pressure coupling frequency at which the Monte Carlo barostat should interact with the system and attempt a Monte Carlo move to adjust the volume during the NpT equilibration in simulation steps. Defaults to 25. npt_equilibration_temperature_coupling_frequency (float, optional): The friction coefficient of the Langevin thermostat during the NpT equilibration in inverse picoseconds. Defaults to 0.1. npt_equilibration_timestep_fs (int, optional): The integration time step during the NpT equilibration in femtoseconds. Defaults to 2. npt_equilibration_duration_ns (int, optional): The duration of the NpT equilibration in nanoseconds. Defaults to 10. reporting_frequency_state_npt_equilibration (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NpT equilibration. Defaults to 500. nvt_equilibration_temperature_coupling_frequency (float, optional): The friction coefficient of the Langevin thermostat during the NVT equilibration in inverse picoseconds. Defaults to 0.1. nvt_equilibration_timestep_fs (int, optional): The integration time step during the NVT equilibration in femtoseconds. Defaults to 2. nvt_equilibration_duration_ns (int, optional): The duration of the NVT equilibration in nanoseconds. Defaults to 20. reporting_frequency_state_nvt_equilibration (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NVT equilibration. Defaults to 2000. nve_production_timestep_fs (int, optional): The integration time step during the NVE production in femtoseconds. Defaults to 1. nve_production_duration_ns (int, optional): The duration of the NVE production in nanoseconds. Defaults to 20. reporting_frequency_coordinates_unwrapped (int, optional): The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. Defaults to 2000. reporting_frequency_coordinates_wrapped (int, optional): The reporting frequency of the trajectory with wrapped coordinates in simulation steps during the NVE production. Defaults to 4000. reporting_frequency_state_nve_production (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NVE production. Defaults to 4000. replica_count (int, optional): The number of times the simulation of one system should be replicated. Defaults to 10. pme_error_tolerance (float, optional): Decides how large the grid for PME is together with the cutoff. Defaults to 0.000001. constraint_tolerance (float, optional): The constraint tolerance specifies the distance tolerance within which constraints are maintained, as a fraction of the constrained distance. Defaults to 0.0000001 cutoff_distance_nm (float, optional): The cutoff distance for nonbonded interactions in nanometers. Defaults to 1.2. cutoff_switch_distance_nm (float, optional): Starting point of the switching function that makes the energy go smoothly to 0 at the cutoff distance in nanometers. Defaults to 1.0. \"\"\" self . workdir = m_utils . directory_maker ( workdir ) self . moldir = m_utils . directory_maker ( f ' { self . workdir } /molecules' ) self . boxdir = m_utils . directory_maker ( f ' { self . workdir } /boxes' ) self . resdir = m_utils . directory_maker ( f ' { self . workdir } /results' ) self . submitdir = m_utils . directory_maker ( f ' { self . workdir } /hpc_submission' ) self . forcedir = m_utils . directory_maker ( f ' { self . workdir } /forcefield' ) self . res_rawdir = m_utils . directory_maker ( f ' { self . resdir } /raw_data' ) self . res_partsdir = m_utils . directory_maker ( f ' { self . resdir } /parts' ) self . molecules = [] self . simulation_boxes = [] self . simulationsystems = [] self . replicas = [] self . molecule_names = [] self . molecule_number_of_atoms = [] self . molecule_abbreviations = [] self . mixture_dict = {} self . forcefields = [] self . elements = {} self . chi_water_s = chi_water_s self . total_number_molecules = total_number_molecules self . init_box_side_length = init_box_side_length self . water_name = 'Water' self . water_abbreviation = 'HOH' self . replica_number_dict = None self . simulation_platform = simulation_platform self . simulation_properties = simulation_properties self . temperature_s = temperature_s self . npt_equilibration_pressure_s = npt_equilibration_pressure_s self . npt_equilibration_pressure_coupling_frequency = npt_equilibration_pressure_coupling_frequency self . npt_equilibration_temperature_coupling_frequency = npt_equilibration_temperature_coupling_frequency self . npt_equilibration_timestep_fs = npt_equilibration_timestep_fs self . npt_equilibration_duration_ns = npt_equilibration_duration_ns self . nvt_equilibration_temperature_coupling_frequency = nvt_equilibration_temperature_coupling_frequency self . nvt_equilibration_timestep_fs = nvt_equilibration_timestep_fs self . nvt_equilibration_duration_ns = nvt_equilibration_duration_ns self . nve_production_timestep_fs = nve_production_timestep_fs self . nve_production_duration_ns = nve_production_duration_ns self . reporting_frequency_coordinates_unwrapped = reporting_frequency_coordinates_unwrapped self . reporting_frequency_coordinates_wrapped = reporting_frequency_coordinates_wrapped self . reporting_frequency_state_npt_equilibration = reporting_frequency_state_npt_equilibration self . reporting_frequency_state_nvt_equilibration = reporting_frequency_state_nvt_equilibration self . reporting_frequency_state_nve_production = reporting_frequency_state_nve_production self . replica_count = replica_count self . pme_error_tolerance = pme_error_tolerance self . constraint_tolerance = constraint_tolerance self . cutoff_distance_nm = cutoff_distance_nm self . cutoff_switch_distance_nm = cutoff_switch_distance_nm self . half_npt_equilibration_csv_columns = int (((( self . npt_equilibration_duration_ns / self . npt_equilibration_timestep_fs ) * ( 10 ** 6 )) / reporting_frequency_state_npt_equilibration ) / 2 ) self . create_description () m_utils . add_chainsubmitter_script ( self . submitdir ) add_forcefield ( Forcefield ) \u00b6 Adds a force field to the project. Parameters: Name Type Description Default Forcefield object Contains information on the force field. required Source code in mixturemm/mixturemm.py 180 181 182 183 184 185 186 187 188 189 190 191 def add_forcefield ( self , Forcefield ) -> None : \"\"\"Adds a force field to the project. Args: Forcefield (object): Contains information on the force field. \"\"\" self . forcefields . append ( Forcefield . path ) if Forcefield . elements is not None : self . elements . update ( Forcefield . elements ) json_structure = m_utils . jsonize_forcefield ( Forcefield ) m_utils . add_json_entry ( f ' { self . description } ' , json_structure , key = 'force fields' , subkey = f ' { Forcefield . ff_name } ' ) add_mixture ( Mixture ) \u00b6 Adds a mixture to the project. Parameters: Name Type Description Default Mixture object Contains information on the mixture that is simulated. required Source code in mixturemm/mixturemm.py 193 194 195 196 197 198 199 200 def add_mixture ( self , Mixture ) -> None : \"\"\"Adds a mixture to the project. Args: Mixture (object): Contains information on the mixture that is simulated. \"\"\" self . mixture_dict = Mixture . mixture_dict add_molecule ( Molecule ) \u00b6 Adds a molecule to the project. Parameters: Name Type Description Default Molecule object Contains information on the molecule that is used for packing with packmol and to identify it. required Source code in mixturemm/mixturemm.py 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def add_molecule ( self , Molecule ) -> None : \"\"\"Adds a molecule to the project. Args: Molecule (object): Contains information on the molecule that is used for packing with packmol and to identify it. \"\"\" if Molecule . use_as_water : self . water_name = Molecule . name self . water_abbreviation = Molecule . abbreviation else : self . molecules . append ( Molecule ) self . molecule_names . append ( Molecule . name ) self . molecule_number_of_atoms . append ( Molecule . number_of_atoms ) self . molecule_abbreviations . append ( Molecule . abbreviation ) json_structure = m_utils . jsonize_molecule ( Molecule ) m_utils . add_json_entry ( f ' { self . description } ' , json_structure , key = 'molecules' , subkey = f ' { Molecule . name } ' ) adjust_to_correct_density () \u00b6 Runs the NpT equilibration to adjust the system volume and density to the correct value. Source code in mixturemm/mixturemm.py 253 254 255 256 257 258 def adjust_to_correct_density ( self ) -> None : \"\"\"Runs the NpT equilibration to adjust the system volume and density to the correct value. \"\"\" for system in self . simulationsystems : system . npt_equilibration () create_description () \u00b6 Creates a .json file with all input arguments of the project and info on all added files. Source code in mixturemm/mixturemm.py 150 151 152 153 154 155 156 157 158 159 160 def create_description ( self ) -> None : \"\"\"Creates a .json file with all input arguments of the project and info on all added files. \"\"\" json_structure = m_utils . jsonize_project ( self ) if os . path . isfile ( f ' { self . workdir } /project_description.json' ) == False : with open ( f ' { self . workdir } /project_description.json' , 'w' , encoding = 'utf-8' ) as f : json . dump ( json_structure , f , ensure_ascii = False , indent = 4 ) else : m_utils . merge_project_descriptions ( f ' { self . workdir } /project_description.json' , json_structure ) self . description = f ' { self . workdir } /project_description.json' create_hpc_submission_adjust_to_correct_density ( hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) \u00b6 Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the NpT equilibration. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. 'openmm_new' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'accelerated'. 'accelerated' number_of_threads int The number of requested threads. Defaults to 152. 152 number_of_gpus int The number of GPUs requested on a node. Defaults to 4. 4 chunk_size int Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. 4 max_number_of_jobs int Maximum number of job submissions allowed on the hpc. Defaults to None. None max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '24:00:00'. '24:00:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False chain_submission_number int The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. 1 dependency_type str Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. 'afternotok' checkpoint_frequency int The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. 10000 Source code in mixturemm/mixturemm.py 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 def create_hpc_submission_adjust_to_correct_density ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the NpT equilibration. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'accelerated'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. number_of_gpus (int, optional): The number of GPUs requested on a node. Defaults to 4. chunk_size (int, optional): Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. max_number_of_jobs (int, optional): Maximum number of job submissions allowed on the hpc. Defaults to None. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. chain_submission_number (int, optional): The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. dependency_type (str, optional): Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. checkpoint_frequency (int, optional): The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. \"\"\" forcefields_ = [ re . sub ( r '^.*?/forcefield' , f ' { hpc_folder } /forcefield' , forcefield ) for forcefield in self . forcefields ] forcefields = ',' . join ( forcefields_ ) if self . elements : elements = m_utils . bash_arg_prepper ( self . elements ) else : elements = None if max_number_of_jobs is None : chunked_simulationsystems = [ self . simulationsystems [ i : i + chunk_size ] for i in range ( 0 , len ( self . simulationsystems ), chunk_size )] else : chunked_simulationsystems = [ self . simulationsystems [ i : i + chunk_size ] for i in range ( 0 , len ( self . simulationsystems ), chunk_size )][: max_number_of_jobs ] for chunk in chunked_simulationsystems : GPU_INDEX_COUNTER = 0 m_utils . hpc_submission_header ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , f ' { id ( chunk ) } _adjust_to_correct_density' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) for system in chunk : with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , 'a' , newline = ' \\n ' ) as file : if 'DeviceIndex' and 'Precision' in self . simulation_properties : simulation_properties_ = self . simulation_properties simulation_properties_ [ 'DeviceIndex' ] = f ' { GPU_INDEX_COUNTER } ' simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) else : simulation_properties_ = { 'DeviceIndex' : f ' { GPU_INDEX_COUNTER } ' , 'Precision' : 'double' } simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) if self . simulation_platform == 'CUDA' : simulation_platform = self . simulation_platform else : simulation_platform = 'CUDA' file . write ( f 'python { hpc_scripts_folder } /cluster_adjust_to_correct_density.py { hpc_folder } { simulation_properties } { simulation_platform } { forcefields } { system . pme_error_tolerance } { system . cutoff_distance_nm } { system . cutoff_switch_distance_nm } { system . name } { system . temperature } { system . pressure } { system . simulationbox_name } { system . npt_equilibration_pressure_coupling_frequency } { system . npt_equilibration_temperature_coupling_frequency } { system . npt_equilibration_timestep_fs } { system . npt_equilibration_steps } { system . reporting_frequency_state_npt_equilibration } { system . constraint_tolerance } { checkpoint_frequency } { elements } & \\n ' ) GPU_INDEX_COUNTER += 1 with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( ' \\n wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_adjust_to_correct_density.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for chunk in chunked_simulationsystems : if chain_submission_number > 1 : file . write ( f '''bash chainsubmitter.sh { chain_submission_number } { hpc_folder } /shfiles/chunk { id ( chunk ) } _adjust_to_correct_density.sh { dependency_type } { partition } \\n ''' ) else : file . write ( f '''sbatch chunk { id ( chunk ) } _adjust_to_correct_density.sh \\n ''' ) create_hpc_submission_analyze_density ( hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , max_runtime_hh_mm_ss = '00:10:00' , conda_module = False ) \u00b6 Creates job submission scripts for bwUniCluster 2.0 containing the density anlysis. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. 'analysis' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'cpuonly'. 'cpuonly' number_of_threads int The number of requested threads. Defaults to 152. 152 max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '00:10:00'. '00:10:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False Source code in mixturemm/mixturemm.py 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 def create_hpc_submission_analyze_density ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , max_runtime_hh_mm_ss = '00:10:00' , conda_module = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 containing the density anlysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '00:10:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) molecule_names , chi_water_s , temperature_s , npt_equilibration_pressure_s , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , [ system . name for system in self . simulationsystems ]) chunked_simulationsystems = [ self . simulationsystems [ i : i + 10 ] for i in range ( 0 , len ( self . simulationsystems ), 10 )] m_utils . hpc_submission_header ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , f 'id { id ( self . simulationsystems ) } _analyze_density' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in chunked_simulationsystems : for system in chunk : with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_density.py { hpc_folder } { system . name } { self . half_npt_equilibration_csv_columns } { system . total_number_molecules } { system . temperature } { system . pressure } { system . chi_water } { molecule_names } & \\n ' ) with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_join_density.py { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { hpc_folder } { name_list } { molecule_names } { self . water_name } { description } & \\n ' ) file . write ( 'wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_density_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n sbatch id { id ( self . simulationsystems ) } _analyze_density.sh \\n ''' ) create_hpc_submission_analyze_hbonds ( hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , donors = 'donor_selection_string' , hydrogens = 'hydrogen_selection_string' , acceptors = 'acceptors_selection_string' , just_conclude = False ) \u00b6 Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. 'analysis' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'cpuonly'. 'cpuonly' number_of_threads int The number of requested threads. Defaults to 152. 152 parallel_running int The number of replica analyses running in parallel. Defaults to 5. 5 submission_split int The number of job submissions the analysis is split in. Defaults to 4. 4 max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '24:00:00'. '24:00:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False donors str Selection of all hydrogen bond donor atoms in MDAnalysis selection syntax. Defaults to 'donor_selection_string'. 'donor_selection_string' hydrogens str Selection of all hydrogen bond hydrogen atoms in MDAnalysis selection syntax. Defaults to 'hydrogens_selection_string'. 'hydrogen_selection_string' acceptors str Selection of all hydrogen bond acceptor atoms in MDAnalysis selection syntax. Defaults to 'acceptors_selection_string'. 'acceptors_selection_string' just_conclude bool If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. False Source code in mixturemm/mixturemm.py 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 def create_hpc_submission_analyze_hbonds ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , donors = 'donor_selection_string' , hydrogens = 'hydrogen_selection_string' , acceptors = 'acceptors_selection_string' , just_conclude = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. parallel_running (int, optional): The number of replica analyses running in parallel. Defaults to 5. submission_split (int, optional): The number of job submissions the analysis is split in. Defaults to 4. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. donors (str, optional): Selection of all hydrogen bond donor atoms in MDAnalysis selection syntax. Defaults to 'donor_selection_string'. hydrogens (str, optional): Selection of all hydrogen bond hydrogen atoms in MDAnalysis selection syntax. Defaults to 'hydrogens_selection_string'. acceptors (str, optional): Selection of all hydrogen bond acceptor atoms in MDAnalysis selection syntax. Defaults to 'acceptors_selection_string'. just_conclude (bool, optional): If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) molecule_names , number_dict , chi_water_s , temperature_s , npt_equilibration_pressure_s , molecule_abbreviations , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . replica_number_dict , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , self . molecule_abbreviations , [ system . name for system in self . simulationsystems ]) chunked_replicas = [ self . replicas [ i : i + parallel_running ] for i in range ( 0 , len ( self . replicas ), parallel_running )] split_fac = int ( len ( chunked_replicas ) / submission_split ) submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if len ( submission_splits ) > submission_split : split_fac = int ( len ( chunked_replicas ) / submission_split ) + 1 submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if not just_conclude : for split in submission_splits : m_utils . hpc_submission_header ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , f 'split { id ( split ) } _analyze_hbonds' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in split : for replica in chunk : with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_hbonds.py { hpc_folder } { replica . name } { replica . replica_number } { replica . chi_water } { replica . temperature } { replica . pressure } { replica . total_number_molecules } { molecule_names } \" { donors } \" \" { hydrogens } \" \" { acceptors } \" & \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'exit 0' ) with open ( f ' { self . submitdir } /submit_hbonds_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for split in submission_splits : file . write ( f '''sbatch split { id ( split ) } _analyze_hbonds.sh \\n ''' ) with open ( f ' { self . submitdir } /conclude_hbonds.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) file . write ( f 'source { hpc_workspace } /conda/etc/profile.d/conda.sh \\n ' ) file . write ( f 'conda activate { environment_name } \\n ' ) file . write ( f 'python { hpc_scripts_folder } /cluster_join_hbonds.py { hpc_folder } { name_list } { number_dict } { description } { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { molecule_names } { self . water_name } { molecule_abbreviations } { self . water_abbreviation } { self . replica_start } & \\n ' ) file . write ( 'wait \\n exit 0' ) create_hpc_submission_analyze_msd ( hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , fit_starting_percentage = 20 , fit_ending_percentage = 80 , just_conclude = False ) \u00b6 Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. 'analysis' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'cpuonly'. 'cpuonly' number_of_threads int The number of requested threads. Defaults to 152. 152 parallel_running int The number of replica analyses running in parallel. Defaults to 5. 5 submission_split int The number of job submissions the analysis is split in. Defaults to 4. 4 max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '24:00:00'. '24:00:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False fit_starting_percentage int Start of the linear fit in percent of NVE production duration. Defaults to 20. 20 fit_ending_percentage int Ending of the linear fit in percent of NVE production duration. Defaults to 80. 80 just_conclude bool If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. False Source code in mixturemm/mixturemm.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 def create_hpc_submission_analyze_msd ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , fit_starting_percentage = 20 , fit_ending_percentage = 80 , just_conclude = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. parallel_running (int, optional): The number of replica analyses running in parallel. Defaults to 5. submission_split (int, optional): The number of job submissions the analysis is split in. Defaults to 4. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. fit_starting_percentage (int, optional): Start of the linear fit in percent of NVE production duration. Defaults to 20. fit_ending_percentage (int, optional): Ending of the linear fit in percent of NVE production duration. Defaults to 80. just_conclude (bool, optional): If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) fit_starting_frame , fit_ending_frame , time_between_frames = m_utils . msd_opt_prepper ( self . nve_production_timestep_fs , self . nve_production_duration_ns , self . reporting_frequency_coordinates_unwrapped , fit_starting_percentage , fit_ending_percentage ) molecule_names , molecule_abbreviations , number_dict , total_number_molecules , chi_water_s , temperature_s , npt_equilibration_pressure_s , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . molecule_abbreviations , self . replica_number_dict , self . total_number_molecules , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , [ system . name for system in self . simulationsystems ]) chunked_replicas = [ self . replicas [ i : i + parallel_running ] for i in range ( 0 , len ( self . replicas ), parallel_running )] split_fac = int ( len ( chunked_replicas ) / submission_split ) submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if len ( submission_splits ) > submission_split : split_fac = int ( len ( chunked_replicas ) / submission_split ) + 1 submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if not just_conclude : for split in submission_splits : m_utils . hpc_submission_header ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , f 'split { id ( split ) } _analyze_msd' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in split : for replica in chunk : with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_sdc.py { hpc_folder } { replica . name } { replica . replica_number } { replica . chi_water } { self . water_abbreviation } { molecule_abbreviations } { time_between_frames } { fit_starting_frame } { fit_ending_frame } { replica . temperature } { replica . pressure } { replica . total_number_molecules } { molecule_names } { self . water_name } & \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'exit 0' ) with open ( f ' { self . submitdir } /submit_msd_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for split in submission_splits : file . write ( f '''sbatch split { id ( split ) } _analyze_msd.sh \\n ''' ) with open ( f ' { self . submitdir } /conclude_msd.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) file . write ( f 'source { hpc_workspace } /conda/etc/profile.d/conda.sh \\n ' ) file . write ( f 'conda activate { environment_name } \\n ' ) file . write ( f 'python { hpc_scripts_folder } /cluster_join_sdc_and_comp_visc.py { total_number_molecules } { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { hpc_folder } { name_list } { molecule_names } { self . water_name } { number_dict } { molecule_abbreviations } { self . water_abbreviation } { description } { self . replica_start } & \\n ' ) file . write ( 'wait \\n exit 0' ) create_hpc_submission_simulate ( hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) \u00b6 Creates job submission scripts for bwUniCluster 2.0 containing the NVT equilibration and NVE production. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. 'openmm_new' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'accelerated'. 'accelerated' number_of_threads int The number of requested threads. Defaults to 152. 152 number_of_gpus int The number of GPUs requested on a node. Defaults to 4. 4 chunk_size int Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. 4 max_number_of_jobs int Maximum number of job submissions allowed on the hpc. Defaults to None. None max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '24:00:00'. '24:00:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False chain_submission_number int The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. 1 dependency_type str Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. 'afternotok' checkpoint_frequency int The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. 10000 Source code in mixturemm/mixturemm.py 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 def create_hpc_submission_simulate ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 containing the NVT equilibration and NVE production. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'accelerated'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. number_of_gpus (int, optional): The number of GPUs requested on a node. Defaults to 4. chunk_size (int, optional): Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. max_number_of_jobs (int, optional): Maximum number of job submissions allowed on the hpc. Defaults to None. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. chain_submission_number (int, optional): The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. dependency_type (str, optional): Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. checkpoint_frequency (int, optional): The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. \"\"\" forcefields_ = [ re . sub ( r '^.*?/forcefield' , f ' { hpc_folder } /forcefield' , forcefield ) for forcefield in self . forcefields ] forcefields = ',' . join ( forcefields_ ) if self . elements : elements = m_utils . bash_arg_prepper ( self . elements ) else : elements = None if max_number_of_jobs is None : chunked_replicas = [ self . replicas [ i : i + chunk_size ] for i in range ( 0 , len ( self . replicas ), chunk_size )] else : chunked_replicas = [ self . replicas [ i : i + chunk_size ] for i in range ( 0 , len ( self . replicas ), chunk_size )][: max_number_of_jobs ] for chunk in chunked_replicas : GPU_INDEX_COUNTER = 0 m_utils . hpc_submission_header ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , f ' { id ( chunk ) } _simulate' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) for replica in chunk : with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , 'a' , newline = ' \\n ' ) as file : if 'DeviceIndex' and 'Precision' in self . simulation_properties : simulation_properties_ = self . simulation_properties simulation_properties_ [ 'DeviceIndex' ] = f ' { GPU_INDEX_COUNTER } ' simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) else : simulation_properties_ = { 'DeviceIndex' : f ' { GPU_INDEX_COUNTER } ' , 'Precision' : 'double' } simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) if self . simulation_platform == 'CUDA' : simulation_platform = self . simulation_platform else : simulation_platform = 'CUDA' file . write ( f 'python { hpc_scripts_folder } /cluster_simulate.py { hpc_folder } { simulation_properties } { simulation_platform } { forcefields } { replica . pme_error_tolerance } { replica . cutoff_distance_nm } { replica . cutoff_switch_distance_nm } { replica . name } { replica . replica_number } { replica . temperature } { replica . half_npt_equilibration_csv_columns } { replica . nvt_equilibration_temperature_coupling_frequency } { replica . nvt_equilibration_steps } { replica . nvt_equilibration_timestep_fs } { replica . reporting_frequency_state_nvt_equilibration } { replica . nve_production_timestep_fs } { replica . nve_production_steps } { replica . reporting_frequency_coordinates_unwrapped } { replica . reporting_frequency_coordinates_wrapped } { replica . reporting_frequency_state_nve_production } { checkpoint_frequency } { replica . constraint_tolerance } { elements } & \\n ' ) GPU_INDEX_COUNTER += 1 with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( ' \\n wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_simulate.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for chunk in chunked_replicas : if chain_submission_number > 1 : file . write ( f '''bash chainsubmitter.sh { chain_submission_number } { hpc_folder } /shfiles/chunk { id ( chunk ) } _simulate.sh { dependency_type } { partition } \\n ''' ) else : file . write ( f '''sbatch chunk { id ( chunk ) } _simulate.sh \\n ''' ) create_replicas ( start = 1 ) \u00b6 Creates replicas of the systems and assigns NVT equilibration and NVE production parameters to them. Parameters: Name Type Description Default start int The number from which on the replica numbering will start. Defaults to 1. 1 Source code in mixturemm/mixturemm.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 def create_replicas ( self , start = 1 ) -> None : \"\"\"Creates replicas of the systems and assigns NVT equilibration and NVE production parameters to them. Args: start (int, optional): The number from which on the replica numbering will start. Defaults to 1. \"\"\" self . replica_start = start replica_count = range ( start , ( self . replica_count + start )) self . replica_number_dict = {} for tot in self . total_number_molecules : self . replica_number_dict [ f ' { tot } ' ] = self . replica_count parameter_list = [ self . simulationsystems , replica_count ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : system , replica_number = combination replica = Replica ( self , system , replica_number ) self . replicas . append ( replica ) m_utils . add_json_entry ( f ' { self . description } ' , start , key = 'project' , subkey = 'simulation_parameters' , subsubkey = 'replica_starting_number' ) create_simulationboxes () \u00b6 Creates and packs the simulation boxes. Source code in mixturemm/mixturemm.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 def create_simulationboxes ( self ) -> None : \"\"\"Creates and packs the simulation boxes. \"\"\" LINKER = '-' for total_number_molecules , init_box_side_length in zip ( self . total_number_molecules , self . init_box_side_length ): for chi_water in self . chi_water_s : string_total_number_molecules = str ( total_number_molecules ) string_init_box_side_length = str ( init_box_side_length ) string_chi_water = str ( chi_water ) mixture_tuple = ( string_total_number_molecules , string_init_box_side_length , string_chi_water ) mixture_name = LINKER . join ( mixture_tuple ) simulation_box = Simulationbox ( self , total_number_molecules , init_box_side_length , chi_water , self . water_name , mixture_name ) self . simulation_boxes . append ( simulation_box ) for x in self . simulation_boxes : x . pack () x . conect_creator () create_systems () \u00b6 Assigns temperature, pressure and NpT equilibration parameters to the boxes. Source code in mixturemm/mixturemm.py 221 222 223 224 225 226 227 228 229 230 def create_systems ( self ) -> None : \"\"\"Assigns temperature, pressure and NpT equilibration parameters to the boxes. \"\"\" parameter_list = [ self . simulation_boxes , self . temperature_s , self . npt_equilibration_pressure_s ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : simulationbox , temperature , pressure = combination system = Simulationsystem ( self , simulationbox , temperature , pressure ) self . simulationsystems . append ( system ) hpc_extend_replica_folders ( hpc_folder = 'workspace/project_name' ) \u00b6 Creates newly added replica folders to the system folders on the hpc. Parameters: Name Type Description Default hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' Source code in mixturemm/mixturemm.py 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 def hpc_extend_replica_folders ( self , hpc_folder = 'workspace/project_name' ) -> None : \"\"\"Creates newly added replica folders to the system folders on the hpc. Args: hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. \"\"\" folder_list = [] for replica in self . replicas : folder_list . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder } / { replica . name } ' , replica . folder )) with open ( f ' { self . submitdir } /extend_replica_folders.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash ''' ) for folder_string in folder_list : file . write ( f '''mkdir { folder_string } ''' ) hpc_job_checker ( hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , hpc_workspace = 'workspace' , environment_name = 'openmm_new' , verbose = True , energy_shift_tolerance_percent = 1 ) \u00b6 Creates a bash script to check the overall status of the simulations on the hpc. Checked properties are doneness percent, average temperature and total energy shift. Parameters: Name Type Description Default hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'openmm_new'. 'openmm_new' verbose bool If true checks average temperature and total energy shift. Defaults to True. True energy_shift_tolerance_percent int The tolerated energy shift in percent. If the energy shift of a simulation is greater, a warning is issued. Defaults to 1. 1 Source code in mixturemm/mixturemm.py 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 def hpc_job_checker ( self , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , hpc_workspace = 'workspace' , environment_name = 'openmm_new' , verbose = True , energy_shift_tolerance_percent = 1 ) -> None : \"\"\"Creates a bash script to check the overall status of the simulations on the hpc. Checked properties are doneness percent, average temperature and total energy shift. Args: hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmm_new'. verbose (bool, optional): If true checks average temperature and total energy shift. Defaults to True. energy_shift_tolerance_percent (int, optional): The tolerated energy shift in percent. If the energy shift of a simulation is greater, a warning is issued. Defaults to 1. \"\"\" system_file_list_ = [] for system in self . simulationsystems : system_file_list_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder } / { system . name } ' , system . folder )) system_file_list = sorted ( system_file_list_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) with open ( f ' { self . submitdir } /system_list.txt' , 'w' , newline = ' \\n ' ) as file : for file_str in system_file_list : file . write ( f ''' { file_str } ''' ) replica_file_list_ = [] for replica in self . replicas : replica_file_list_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder } / { replica . name } ' , replica . folder )) replica_file_list = sorted ( replica_file_list_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) replica_file_list . append ( 'finalize' ) with open ( f ' { self . submitdir } /replica_list.txt' , 'w' , newline = ' \\n ' ) as file : for file_str in replica_file_list : file . write ( f ''' { file_str } ''' ) with open ( f ' { self . submitdir } /job_checker.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash source { hpc_workspace } /conda/etc/profile.d/conda.sh conda activate { environment_name } python { hpc_scripts_folder } /job_checker.py { self . nvt_equilibration_duration_ns } { self . nve_production_duration_ns } { verbose } { energy_shift_tolerance_percent } { self . npt_equilibration_duration_ns } exit 0 ''' ) overcharge_replicas ( total_number_molecules = 1000 , overcharge_amount = 10 ) \u00b6 Adds the overcharge amount to the replicas of the systems specified by total number of molecules. Parameters: Name Type Description Default total_number_molecules int Number of molecules that are placed in the simulation box. Defaults to 1000. 1000 overcharge_amount int Amount of replicas that should be added. Defaults to 10. 10 Source code in mixturemm/mixturemm.py 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 def overcharge_replicas ( self , total_number_molecules = 1000 , overcharge_amount = 10 ) -> None : \"\"\"Adds the overcharge amount to the replicas of the systems specified by total number of molecules. Args: total_number_molecules (int, optional): Number of molecules that are placed in the simulation box. Defaults to 1000. overcharge_amount (int, optional): Amount of replicas that should be added. Defaults to 10. \"\"\" filtered_systems = [ system for system in self . simulationsystems if system . total_number_molecules in total_number_molecules ] replica_count = range (( self . replica_count + self . replica_start ), ( self . replica_count + self . replica_start + overcharge_amount )) parameter_list = [ filtered_systems , replica_count ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : system , replica_number = combination replica = Replica ( self , system , replica_number ) self . replicas . append ( replica ) entry = f 'with { overcharge_amount } replicas' m_utils . add_json_entry ( f ' { self . description } ' , entry , key = 'project' , subkey = 'simulation_parameters' , subsubkey = 'overcharged_boxes' , subsubsubkey = f ' { total_number_molecules } molecules' ) self . replica_number_dict [ f ' { total_number_molecules } ' ] = self . replica_count + self . replica_start + overcharge_amount remove_done_jobs_from_replicas ( path_to_job_checks = 'workdir/job_checks.txt' ) \u00b6 Removes all replicas that are done according to the job checker from the project. Parameters: Name Type Description Default path_to_job_checks str The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. 'workdir/job_checks.txt' Source code in mixturemm/mixturemm.py 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 def remove_done_jobs_from_replicas ( self , path_to_job_checks = 'workdir/job_checks.txt' ) -> None : \"\"\"Removes all replicas that are done according to the job checker from the project. Args: path_to_job_checks (str, optional): The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. \"\"\" with open ( f ' { path_to_job_checks } ' , 'r' , newline = ' \\n ' ) as file : not_done_job_list_ = [ line . rstrip () for line in file if 'not yet finished' in line ] not_done_job_list = [ item [: - 17 ] for item in not_done_job_list_ ] filtered_replicas = [] for replica in self . replicas : for string in not_done_job_list : if replica . name in string and int ( re . search ( r '\\d+$' , string ) . group ()) == replica . replica_number : filtered_replicas . append ( replica ) self . replicas = filtered_replicas remove_done_jobs_from_systems ( path_to_job_checks = 'workdir/job_checks.txt' ) \u00b6 Removes all systems that are done according to the job checker from the project. Parameters: Name Type Description Default path_to_job_checks str The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. 'workdir/job_checks.txt' Source code in mixturemm/mixturemm.py 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 def remove_done_jobs_from_systems ( self , path_to_job_checks = 'workdir/job_checks.txt' ) -> None : \"\"\"Removes all systems that are done according to the job checker from the project. Args: path_to_job_checks (str, optional): The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. \"\"\" with open ( f ' { path_to_job_checks } ' , 'r' , newline = ' \\n ' ) as file : not_done_job_list_ = [ line . rstrip () for line in file if 'not yet adjusted' in line ] not_done_job_list = [ item [: - 17 ] for item in not_done_job_list_ ] filtered_systems = [] for system in self . simulationsystems : for string in not_done_job_list : if system . name in string : filtered_systems . append ( system ) self . simulationsystems = filtered_systems simulate () \u00b6 Runs the NVT equilibration and the NVE production. Source code in mixturemm/mixturemm.py 260 261 262 263 264 265 266 def simulate ( self ) -> None : \"\"\"Runs the NVT equilibration and the NVE production. \"\"\" for replica in self . replicas : replica . nvt_equilibration () replica . nve_production () transfer_project ( hpc_folder_old = 'workspace_old/project_name' , hpc_folder_new = 'workspace_new/project_name' ) \u00b6 Transfers a project between two workspaces. Parameters: Name Type Description Default hpc_folder_old str The path to the old project folder on the hpc. Defaults to 'workspace_old/project_name'. 'workspace_old/project_name' hpc_folder_new str The path to the new project folder on the hpc. Defaults to 'workspace_new/project_name'. 'workspace_new/project_name' Source code in mixturemm/mixturemm.py 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 def transfer_project ( self , hpc_folder_old = 'workspace_old/project_name' , hpc_folder_new = 'workspace_new/project_name' ) -> None : \"\"\"Transfers a project between two workspaces. Args: hpc_folder_old (str, optional): The path to the old project folder on the hpc. Defaults to 'workspace_old/project_name'. hpc_folder_new (str, optional): The path to the new project folder on the hpc. Defaults to 'workspace_new/project_name'. \"\"\" system_file_list_old_ = [] system_file_list_new_ = [] for system in self . simulationsystems : system_file_list_old_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder_old } / { system . name } ' , system . folder )) system_file_list_new_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder_new } / { system . name } ' , system . folder )) system_file_list_old = sorted ( system_file_list_old_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) system_file_list_new = sorted ( system_file_list_new_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) with open ( f ' { self . submitdir } /transfer_project.py' , 'w' , newline = ' \\n ' ) as file : file . write ( 'import shutil \\n ' ) for file_str_old , file_str_new in zip ( system_file_list_old , system_file_list_new ): file . write ( f '''shutil.copytree(r\" { file_str_old } /npt_equilibration\", r\" { file_str_new } /npt_equilibration\") ''' ) replica_file_list_old_ = [] replica_file_list_new_ = [] for replica in self . replicas : replica_file_list_old_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder_old } / { replica . name } ' , replica . folder )) replica_file_list_new_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder_new } / { replica . name } ' , replica . folder )) replica_file_list_old = sorted ( replica_file_list_old_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) replica_file_list_new = sorted ( replica_file_list_new_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) with open ( f ' { self . submitdir } /transfer_project.py' , 'a' , newline = ' \\n ' ) as file : for file_str_old , file_str_new in zip ( replica_file_list_old , replica_file_list_new ): file . write ( f '''shutil.copytree(r\" { file_str_old } \", r\" { file_str_new } \") ''' ) with open ( f ' { self . submitdir } /transfer_project.py' , 'a' , newline = ' \\n ' ) as file : file . write ( f '''shutil.copytree(r\" { hpc_folder_old } /boxes\", r\" { hpc_folder_new } /boxes\") shutil.copytree(r\" { hpc_folder_old } /forcefield\", r\" { hpc_folder_new } /forcefield\") shutil.copytree(r\" { hpc_folder_old } /hpc_submission\", r\" { hpc_folder_new } /hpc_submission\") shutil.copytree(r\" { hpc_folder_old } /molecules\", r\" { hpc_folder_new } /molecules\") shutil.copytree(r\" { hpc_folder_old } /results\", r\" { hpc_folder_new } /results\") ''' )","title":"mixturemm module"},{"location":"mixturemm/#mixturemm","text":"Main module. MIT License Copyright (c) 2021, Benjamin Schmitz Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"mixturemm"},{"location":"mixturemm/#mixturemm.mixturemm.Forcefield","text":"Source code in mixturemm/mixturemm.py 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 class Forcefield : def __init__ ( self , workdir , path_to_XML , ff_name , built_in = True , elements = None ) -> None : \"\"\"Contains information on the force field. Args: workdir (str): The path at which the project is stored. path_to_XML (str): The path to the force field XML file. ff_name (str): The name under which the force field should be stored. built_in (bool, optional): Decides whether the fore field is part of openMM or from an external source. If true, declares that a built in forcefield of openmm will be used. Defaults to True. elements (dict, optional): OpenMM uses Elements to match molecules to the force field. If atomtypes in the force field are unknown to OpenMM, they are registered by giving their name and mass in the form {'name' : mass}. Defaults to None. \"\"\" self . forcedir = f ' { workdir } /forcefield' self . ff_name = ff_name self . built_in = built_in self . elements = elements if built_in == False : shutil . copy ( path_to_XML , f ' { self . forcedir } / { ff_name } .xml' ) self . path = f ' { self . forcedir } / { ff_name } .xml' else : self . path = path_to_XML if elements is not None : for name , mass in elements . items (): _ = elem . Element ( number = 0 , name = name , symbol = name , mass = mass * amu )","title":"Forcefield"},{"location":"mixturemm/#mixturemm.mixturemm.Forcefield.__init__","text":"Contains information on the force field. Parameters: Name Type Description Default workdir str The path at which the project is stored. required path_to_XML str The path to the force field XML file. required ff_name str The name under which the force field should be stored. required built_in bool Decides whether the fore field is part of openMM or from an external source. If true, declares that a built in forcefield of openmm will be used. Defaults to True. True elements dict OpenMM uses Elements to match molecules to the force field. If atomtypes in the force field are unknown to OpenMM, they are registered by giving their name and mass in the form {'name' : mass}. Defaults to None. None Source code in mixturemm/mixturemm.py 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 def __init__ ( self , workdir , path_to_XML , ff_name , built_in = True , elements = None ) -> None : \"\"\"Contains information on the force field. Args: workdir (str): The path at which the project is stored. path_to_XML (str): The path to the force field XML file. ff_name (str): The name under which the force field should be stored. built_in (bool, optional): Decides whether the fore field is part of openMM or from an external source. If true, declares that a built in forcefield of openmm will be used. Defaults to True. elements (dict, optional): OpenMM uses Elements to match molecules to the force field. If atomtypes in the force field are unknown to OpenMM, they are registered by giving their name and mass in the form {'name' : mass}. Defaults to None. \"\"\" self . forcedir = f ' { workdir } /forcefield' self . ff_name = ff_name self . built_in = built_in self . elements = elements if built_in == False : shutil . copy ( path_to_XML , f ' { self . forcedir } / { ff_name } .xml' ) self . path = f ' { self . forcedir } / { ff_name } .xml' else : self . path = path_to_XML if elements is not None : for name , mass in elements . items (): _ = elem . Element ( number = 0 , name = name , symbol = name , mass = mass * amu )","title":"__init__()"},{"location":"mixturemm/#mixturemm.mixturemm.Mixture","text":"Source code in mixturemm/mixturemm.py 863 864 865 866 867 868 869 870 871 872 873 874 class Mixture : def __init__ ( self , mixture_dict ) -> None : \"\"\"Contains information on the mixture that is simulated. Args: mixture_dict (dict): Dictionary with molecule names and their corresponding mole fraction in the mixture. \"\"\" self . mixture_dict = mixture_dict","title":"Mixture"},{"location":"mixturemm/#mixturemm.mixturemm.Mixture.__init__","text":"Contains information on the mixture that is simulated. Parameters: Name Type Description Default mixture_dict dict Dictionary with molecule names and their corresponding mole fraction in the mixture. required Source code in mixturemm/mixturemm.py 865 866 867 868 869 870 871 872 873 874 def __init__ ( self , mixture_dict ) -> None : \"\"\"Contains information on the mixture that is simulated. Args: mixture_dict (dict): Dictionary with molecule names and their corresponding mole fraction in the mixture. \"\"\" self . mixture_dict = mixture_dict","title":"__init__()"},{"location":"mixturemm/#mixturemm.mixturemm.Molecule","text":"Source code in mixturemm/mixturemm.py 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 class Molecule : def __init__ ( self , workdir , name , number_of_atoms , path_to_pdb , abbreviation , smiles , inchi , molar_mass , use_as_water = False ) -> None : \"\"\"Contains information on the molecule that is used for packing with packmol and to identify it. Args: workdir (str): The path at which the project is stored. name (str): Name of the molecule. number_of_atoms (int): The number of atoms that the molecule consists of. path_to_pdb (str): The path to the molecule PDB file. abbreviation (str): The abbreviation of the molecule that is used inside the PDB file. smiles (str): The SMILES code of the molecule. inchi (str): The InChI code of the molecule. molar_mass (str): The molar mass of the molecule. use_as_water (bool, optional): Decides whether the molecule is used as water or not. If used as water, the water molar fraction is applied to it while packing boxes. Defaults to False. \"\"\" self . moldir = f ' { workdir } /molecules' self . name = name self . number_of_atoms = number_of_atoms self . abbreviation = abbreviation self . smiles = smiles self . inchi = inchi self . molar_mass = molar_mass self . use_as_water = False if use_as_water : self . use_as_water = True shutil . copy ( path_to_pdb , f ' { self . moldir } / { self . name } .pdb' ) self . path = f ' { self . moldir } / { self . name } .pdb'","title":"Molecule"},{"location":"mixturemm/#mixturemm.mixturemm.Molecule.__init__","text":"Contains information on the molecule that is used for packing with packmol and to identify it. Parameters: Name Type Description Default workdir str The path at which the project is stored. required name str Name of the molecule. required number_of_atoms int The number of atoms that the molecule consists of. required path_to_pdb str The path to the molecule PDB file. required abbreviation str The abbreviation of the molecule that is used inside the PDB file. required smiles str The SMILES code of the molecule. required inchi str The InChI code of the molecule. required molar_mass str The molar mass of the molecule. required use_as_water bool Decides whether the molecule is used as water or not. If used as water, the water molar fraction is applied to it while packing boxes. Defaults to False. False Source code in mixturemm/mixturemm.py 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 def __init__ ( self , workdir , name , number_of_atoms , path_to_pdb , abbreviation , smiles , inchi , molar_mass , use_as_water = False ) -> None : \"\"\"Contains information on the molecule that is used for packing with packmol and to identify it. Args: workdir (str): The path at which the project is stored. name (str): Name of the molecule. number_of_atoms (int): The number of atoms that the molecule consists of. path_to_pdb (str): The path to the molecule PDB file. abbreviation (str): The abbreviation of the molecule that is used inside the PDB file. smiles (str): The SMILES code of the molecule. inchi (str): The InChI code of the molecule. molar_mass (str): The molar mass of the molecule. use_as_water (bool, optional): Decides whether the molecule is used as water or not. If used as water, the water molar fraction is applied to it while packing boxes. Defaults to False. \"\"\" self . moldir = f ' { workdir } /molecules' self . name = name self . number_of_atoms = number_of_atoms self . abbreviation = abbreviation self . smiles = smiles self . inchi = inchi self . molar_mass = molar_mass self . use_as_water = False if use_as_water : self . use_as_water = True shutil . copy ( path_to_pdb , f ' { self . moldir } / { self . name } .pdb' ) self . path = f ' { self . moldir } / { self . name } .pdb'","title":"__init__()"},{"location":"mixturemm/#mixturemm.mixturemm.Project","text":"Source code in mixturemm/mixturemm.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 class Project : def __init__ ( self , workdir , simulation_platform = 'CUDA' , simulation_properties = { 'DeviceIndex' : '0' , 'Precision' : 'double' }, total_number_molecules = [ 1000 ], init_box_side_length = [ 30 ], chi_water_s = [ 0 , 0.5 , 1 ], temperature_s = [ 298.15 ], npt_equilibration_pressure_s = [ 1 ], npt_equilibration_pressure_coupling_frequency = 25 , npt_equilibration_temperature_coupling_frequency = 0.1 , npt_equilibration_timestep_fs = 2 , npt_equilibration_duration_ns = 10 , reporting_frequency_state_npt_equilibration = 500 , nvt_equilibration_temperature_coupling_frequency = 0.1 , nvt_equilibration_timestep_fs = 2 , nvt_equilibration_duration_ns = 20 , reporting_frequency_state_nvt_equilibration = 2000 , nve_production_timestep_fs = 1 , nve_production_duration_ns = 20 , reporting_frequency_coordinates_unwrapped = 2000 , reporting_frequency_coordinates_wrapped = 4000 , reporting_frequency_state_nve_production = 4000 , replica_count = 10 , pme_error_tolerance = 0.000001 , constraint_tolerance = 0.0000001 , cutoff_distance_nm = 1.2 , cutoff_switch_distance_nm = 1.0 ) -> None : \"\"\"The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Args: workdir (str): The path at which the project should be stored. simulation_platform (str, optional): The platform the simulation should run on. Defaults to 'CUDA'. simulation_properties (dict, optional): The platform properties for the simulation. Defaults to {'DeviceIndex': '0', 'Precision': 'double'}. total_number_molecules (list, optional): A list with the number of molecules that should be placed in the simulation box. Defaults to [1000]. init_box_side_length (list, optional): The initial box side lengths that should be used by packmol. Defaults to [30]. chi_water_s (list, optional): A list with all different molar fractions of water that should be simulated. Defaults to [0,0.5,1]. temperature_s (list, optional): A list with all different temperatures in kelvin at which the boxes should be simulated. Defaults to [298.15]. npt_equilibration_pressure_s (list, optional): A list with all pressures in bar at which the boxes should be simulated. Defaults to [1]. npt_equilibration_pressure_coupling_frequency (int, optional): The pressure coupling frequency at which the Monte Carlo barostat should interact with the system and attempt a Monte Carlo move to adjust the volume during the NpT equilibration in simulation steps. Defaults to 25. npt_equilibration_temperature_coupling_frequency (float, optional): The friction coefficient of the Langevin thermostat during the NpT equilibration in inverse picoseconds. Defaults to 0.1. npt_equilibration_timestep_fs (int, optional): The integration time step during the NpT equilibration in femtoseconds. Defaults to 2. npt_equilibration_duration_ns (int, optional): The duration of the NpT equilibration in nanoseconds. Defaults to 10. reporting_frequency_state_npt_equilibration (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NpT equilibration. Defaults to 500. nvt_equilibration_temperature_coupling_frequency (float, optional): The friction coefficient of the Langevin thermostat during the NVT equilibration in inverse picoseconds. Defaults to 0.1. nvt_equilibration_timestep_fs (int, optional): The integration time step during the NVT equilibration in femtoseconds. Defaults to 2. nvt_equilibration_duration_ns (int, optional): The duration of the NVT equilibration in nanoseconds. Defaults to 20. reporting_frequency_state_nvt_equilibration (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NVT equilibration. Defaults to 2000. nve_production_timestep_fs (int, optional): The integration time step during the NVE production in femtoseconds. Defaults to 1. nve_production_duration_ns (int, optional): The duration of the NVE production in nanoseconds. Defaults to 20. reporting_frequency_coordinates_unwrapped (int, optional): The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. Defaults to 2000. reporting_frequency_coordinates_wrapped (int, optional): The reporting frequency of the trajectory with wrapped coordinates in simulation steps during the NVE production. Defaults to 4000. reporting_frequency_state_nve_production (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NVE production. Defaults to 4000. replica_count (int, optional): The number of times the simulation of one system should be replicated. Defaults to 10. pme_error_tolerance (float, optional): Decides how large the grid for PME is together with the cutoff. Defaults to 0.000001. constraint_tolerance (float, optional): The constraint tolerance specifies the distance tolerance within which constraints are maintained, as a fraction of the constrained distance. Defaults to 0.0000001 cutoff_distance_nm (float, optional): The cutoff distance for nonbonded interactions in nanometers. Defaults to 1.2. cutoff_switch_distance_nm (float, optional): Starting point of the switching function that makes the energy go smoothly to 0 at the cutoff distance in nanometers. Defaults to 1.0. \"\"\" self . workdir = m_utils . directory_maker ( workdir ) self . moldir = m_utils . directory_maker ( f ' { self . workdir } /molecules' ) self . boxdir = m_utils . directory_maker ( f ' { self . workdir } /boxes' ) self . resdir = m_utils . directory_maker ( f ' { self . workdir } /results' ) self . submitdir = m_utils . directory_maker ( f ' { self . workdir } /hpc_submission' ) self . forcedir = m_utils . directory_maker ( f ' { self . workdir } /forcefield' ) self . res_rawdir = m_utils . directory_maker ( f ' { self . resdir } /raw_data' ) self . res_partsdir = m_utils . directory_maker ( f ' { self . resdir } /parts' ) self . molecules = [] self . simulation_boxes = [] self . simulationsystems = [] self . replicas = [] self . molecule_names = [] self . molecule_number_of_atoms = [] self . molecule_abbreviations = [] self . mixture_dict = {} self . forcefields = [] self . elements = {} self . chi_water_s = chi_water_s self . total_number_molecules = total_number_molecules self . init_box_side_length = init_box_side_length self . water_name = 'Water' self . water_abbreviation = 'HOH' self . replica_number_dict = None self . simulation_platform = simulation_platform self . simulation_properties = simulation_properties self . temperature_s = temperature_s self . npt_equilibration_pressure_s = npt_equilibration_pressure_s self . npt_equilibration_pressure_coupling_frequency = npt_equilibration_pressure_coupling_frequency self . npt_equilibration_temperature_coupling_frequency = npt_equilibration_temperature_coupling_frequency self . npt_equilibration_timestep_fs = npt_equilibration_timestep_fs self . npt_equilibration_duration_ns = npt_equilibration_duration_ns self . nvt_equilibration_temperature_coupling_frequency = nvt_equilibration_temperature_coupling_frequency self . nvt_equilibration_timestep_fs = nvt_equilibration_timestep_fs self . nvt_equilibration_duration_ns = nvt_equilibration_duration_ns self . nve_production_timestep_fs = nve_production_timestep_fs self . nve_production_duration_ns = nve_production_duration_ns self . reporting_frequency_coordinates_unwrapped = reporting_frequency_coordinates_unwrapped self . reporting_frequency_coordinates_wrapped = reporting_frequency_coordinates_wrapped self . reporting_frequency_state_npt_equilibration = reporting_frequency_state_npt_equilibration self . reporting_frequency_state_nvt_equilibration = reporting_frequency_state_nvt_equilibration self . reporting_frequency_state_nve_production = reporting_frequency_state_nve_production self . replica_count = replica_count self . pme_error_tolerance = pme_error_tolerance self . constraint_tolerance = constraint_tolerance self . cutoff_distance_nm = cutoff_distance_nm self . cutoff_switch_distance_nm = cutoff_switch_distance_nm self . half_npt_equilibration_csv_columns = int (((( self . npt_equilibration_duration_ns / self . npt_equilibration_timestep_fs ) * ( 10 ** 6 )) / reporting_frequency_state_npt_equilibration ) / 2 ) self . create_description () m_utils . add_chainsubmitter_script ( self . submitdir ) def create_description ( self ) -> None : \"\"\"Creates a .json file with all input arguments of the project and info on all added files. \"\"\" json_structure = m_utils . jsonize_project ( self ) if os . path . isfile ( f ' { self . workdir } /project_description.json' ) == False : with open ( f ' { self . workdir } /project_description.json' , 'w' , encoding = 'utf-8' ) as f : json . dump ( json_structure , f , ensure_ascii = False , indent = 4 ) else : m_utils . merge_project_descriptions ( f ' { self . workdir } /project_description.json' , json_structure ) self . description = f ' { self . workdir } /project_description.json' def add_molecule ( self , Molecule ) -> None : \"\"\"Adds a molecule to the project. Args: Molecule (object): Contains information on the molecule that is used for packing with packmol and to identify it. \"\"\" if Molecule . use_as_water : self . water_name = Molecule . name self . water_abbreviation = Molecule . abbreviation else : self . molecules . append ( Molecule ) self . molecule_names . append ( Molecule . name ) self . molecule_number_of_atoms . append ( Molecule . number_of_atoms ) self . molecule_abbreviations . append ( Molecule . abbreviation ) json_structure = m_utils . jsonize_molecule ( Molecule ) m_utils . add_json_entry ( f ' { self . description } ' , json_structure , key = 'molecules' , subkey = f ' { Molecule . name } ' ) def add_forcefield ( self , Forcefield ) -> None : \"\"\"Adds a force field to the project. Args: Forcefield (object): Contains information on the force field. \"\"\" self . forcefields . append ( Forcefield . path ) if Forcefield . elements is not None : self . elements . update ( Forcefield . elements ) json_structure = m_utils . jsonize_forcefield ( Forcefield ) m_utils . add_json_entry ( f ' { self . description } ' , json_structure , key = 'force fields' , subkey = f ' { Forcefield . ff_name } ' ) def add_mixture ( self , Mixture ) -> None : \"\"\"Adds a mixture to the project. Args: Mixture (object): Contains information on the mixture that is simulated. \"\"\" self . mixture_dict = Mixture . mixture_dict def create_simulationboxes ( self ) -> None : \"\"\"Creates and packs the simulation boxes. \"\"\" LINKER = '-' for total_number_molecules , init_box_side_length in zip ( self . total_number_molecules , self . init_box_side_length ): for chi_water in self . chi_water_s : string_total_number_molecules = str ( total_number_molecules ) string_init_box_side_length = str ( init_box_side_length ) string_chi_water = str ( chi_water ) mixture_tuple = ( string_total_number_molecules , string_init_box_side_length , string_chi_water ) mixture_name = LINKER . join ( mixture_tuple ) simulation_box = Simulationbox ( self , total_number_molecules , init_box_side_length , chi_water , self . water_name , mixture_name ) self . simulation_boxes . append ( simulation_box ) for x in self . simulation_boxes : x . pack () x . conect_creator () def create_systems ( self ) -> None : \"\"\"Assigns temperature, pressure and NpT equilibration parameters to the boxes. \"\"\" parameter_list = [ self . simulation_boxes , self . temperature_s , self . npt_equilibration_pressure_s ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : simulationbox , temperature , pressure = combination system = Simulationsystem ( self , simulationbox , temperature , pressure ) self . simulationsystems . append ( system ) def create_replicas ( self , start = 1 ) -> None : \"\"\"Creates replicas of the systems and assigns NVT equilibration and NVE production parameters to them. Args: start (int, optional): The number from which on the replica numbering will start. Defaults to 1. \"\"\" self . replica_start = start replica_count = range ( start , ( self . replica_count + start )) self . replica_number_dict = {} for tot in self . total_number_molecules : self . replica_number_dict [ f ' { tot } ' ] = self . replica_count parameter_list = [ self . simulationsystems , replica_count ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : system , replica_number = combination replica = Replica ( self , system , replica_number ) self . replicas . append ( replica ) m_utils . add_json_entry ( f ' { self . description } ' , start , key = 'project' , subkey = 'simulation_parameters' , subsubkey = 'replica_starting_number' ) def adjust_to_correct_density ( self ) -> None : \"\"\"Runs the NpT equilibration to adjust the system volume and density to the correct value. \"\"\" for system in self . simulationsystems : system . npt_equilibration () def simulate ( self ) -> None : \"\"\"Runs the NVT equilibration and the NVE production. \"\"\" for replica in self . replicas : replica . nvt_equilibration () replica . nve_production () def create_hpc_submission_adjust_to_correct_density ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the NpT equilibration. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'accelerated'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. number_of_gpus (int, optional): The number of GPUs requested on a node. Defaults to 4. chunk_size (int, optional): Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. max_number_of_jobs (int, optional): Maximum number of job submissions allowed on the hpc. Defaults to None. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. chain_submission_number (int, optional): The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. dependency_type (str, optional): Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. checkpoint_frequency (int, optional): The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. \"\"\" forcefields_ = [ re . sub ( r '^.*?/forcefield' , f ' { hpc_folder } /forcefield' , forcefield ) for forcefield in self . forcefields ] forcefields = ',' . join ( forcefields_ ) if self . elements : elements = m_utils . bash_arg_prepper ( self . elements ) else : elements = None if max_number_of_jobs is None : chunked_simulationsystems = [ self . simulationsystems [ i : i + chunk_size ] for i in range ( 0 , len ( self . simulationsystems ), chunk_size )] else : chunked_simulationsystems = [ self . simulationsystems [ i : i + chunk_size ] for i in range ( 0 , len ( self . simulationsystems ), chunk_size )][: max_number_of_jobs ] for chunk in chunked_simulationsystems : GPU_INDEX_COUNTER = 0 m_utils . hpc_submission_header ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , f ' { id ( chunk ) } _adjust_to_correct_density' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) for system in chunk : with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , 'a' , newline = ' \\n ' ) as file : if 'DeviceIndex' and 'Precision' in self . simulation_properties : simulation_properties_ = self . simulation_properties simulation_properties_ [ 'DeviceIndex' ] = f ' { GPU_INDEX_COUNTER } ' simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) else : simulation_properties_ = { 'DeviceIndex' : f ' { GPU_INDEX_COUNTER } ' , 'Precision' : 'double' } simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) if self . simulation_platform == 'CUDA' : simulation_platform = self . simulation_platform else : simulation_platform = 'CUDA' file . write ( f 'python { hpc_scripts_folder } /cluster_adjust_to_correct_density.py { hpc_folder } { simulation_properties } { simulation_platform } { forcefields } { system . pme_error_tolerance } { system . cutoff_distance_nm } { system . cutoff_switch_distance_nm } { system . name } { system . temperature } { system . pressure } { system . simulationbox_name } { system . npt_equilibration_pressure_coupling_frequency } { system . npt_equilibration_temperature_coupling_frequency } { system . npt_equilibration_timestep_fs } { system . npt_equilibration_steps } { system . reporting_frequency_state_npt_equilibration } { system . constraint_tolerance } { checkpoint_frequency } { elements } & \\n ' ) GPU_INDEX_COUNTER += 1 with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( ' \\n wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_adjust_to_correct_density.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for chunk in chunked_simulationsystems : if chain_submission_number > 1 : file . write ( f '''bash chainsubmitter.sh { chain_submission_number } { hpc_folder } /shfiles/chunk { id ( chunk ) } _adjust_to_correct_density.sh { dependency_type } { partition } \\n ''' ) else : file . write ( f '''sbatch chunk { id ( chunk ) } _adjust_to_correct_density.sh \\n ''' ) def create_hpc_submission_simulate ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 containing the NVT equilibration and NVE production. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'accelerated'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. number_of_gpus (int, optional): The number of GPUs requested on a node. Defaults to 4. chunk_size (int, optional): Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. max_number_of_jobs (int, optional): Maximum number of job submissions allowed on the hpc. Defaults to None. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. chain_submission_number (int, optional): The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. dependency_type (str, optional): Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. checkpoint_frequency (int, optional): The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. \"\"\" forcefields_ = [ re . sub ( r '^.*?/forcefield' , f ' { hpc_folder } /forcefield' , forcefield ) for forcefield in self . forcefields ] forcefields = ',' . join ( forcefields_ ) if self . elements : elements = m_utils . bash_arg_prepper ( self . elements ) else : elements = None if max_number_of_jobs is None : chunked_replicas = [ self . replicas [ i : i + chunk_size ] for i in range ( 0 , len ( self . replicas ), chunk_size )] else : chunked_replicas = [ self . replicas [ i : i + chunk_size ] for i in range ( 0 , len ( self . replicas ), chunk_size )][: max_number_of_jobs ] for chunk in chunked_replicas : GPU_INDEX_COUNTER = 0 m_utils . hpc_submission_header ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , f ' { id ( chunk ) } _simulate' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) for replica in chunk : with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , 'a' , newline = ' \\n ' ) as file : if 'DeviceIndex' and 'Precision' in self . simulation_properties : simulation_properties_ = self . simulation_properties simulation_properties_ [ 'DeviceIndex' ] = f ' { GPU_INDEX_COUNTER } ' simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) else : simulation_properties_ = { 'DeviceIndex' : f ' { GPU_INDEX_COUNTER } ' , 'Precision' : 'double' } simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) if self . simulation_platform == 'CUDA' : simulation_platform = self . simulation_platform else : simulation_platform = 'CUDA' file . write ( f 'python { hpc_scripts_folder } /cluster_simulate.py { hpc_folder } { simulation_properties } { simulation_platform } { forcefields } { replica . pme_error_tolerance } { replica . cutoff_distance_nm } { replica . cutoff_switch_distance_nm } { replica . name } { replica . replica_number } { replica . temperature } { replica . half_npt_equilibration_csv_columns } { replica . nvt_equilibration_temperature_coupling_frequency } { replica . nvt_equilibration_steps } { replica . nvt_equilibration_timestep_fs } { replica . reporting_frequency_state_nvt_equilibration } { replica . nve_production_timestep_fs } { replica . nve_production_steps } { replica . reporting_frequency_coordinates_unwrapped } { replica . reporting_frequency_coordinates_wrapped } { replica . reporting_frequency_state_nve_production } { checkpoint_frequency } { replica . constraint_tolerance } { elements } & \\n ' ) GPU_INDEX_COUNTER += 1 with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( ' \\n wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_simulate.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for chunk in chunked_replicas : if chain_submission_number > 1 : file . write ( f '''bash chainsubmitter.sh { chain_submission_number } { hpc_folder } /shfiles/chunk { id ( chunk ) } _simulate.sh { dependency_type } { partition } \\n ''' ) else : file . write ( f '''sbatch chunk { id ( chunk ) } _simulate.sh \\n ''' ) def create_hpc_submission_analyze_density ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , max_runtime_hh_mm_ss = '00:10:00' , conda_module = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 containing the density anlysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '00:10:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) molecule_names , chi_water_s , temperature_s , npt_equilibration_pressure_s , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , [ system . name for system in self . simulationsystems ]) chunked_simulationsystems = [ self . simulationsystems [ i : i + 10 ] for i in range ( 0 , len ( self . simulationsystems ), 10 )] m_utils . hpc_submission_header ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , f 'id { id ( self . simulationsystems ) } _analyze_density' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in chunked_simulationsystems : for system in chunk : with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_density.py { hpc_folder } { system . name } { self . half_npt_equilibration_csv_columns } { system . total_number_molecules } { system . temperature } { system . pressure } { system . chi_water } { molecule_names } & \\n ' ) with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_join_density.py { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { hpc_folder } { name_list } { molecule_names } { self . water_name } { description } & \\n ' ) file . write ( 'wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_density_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n sbatch id { id ( self . simulationsystems ) } _analyze_density.sh \\n ''' ) def create_hpc_submission_analyze_msd ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , fit_starting_percentage = 20 , fit_ending_percentage = 80 , just_conclude = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. parallel_running (int, optional): The number of replica analyses running in parallel. Defaults to 5. submission_split (int, optional): The number of job submissions the analysis is split in. Defaults to 4. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. fit_starting_percentage (int, optional): Start of the linear fit in percent of NVE production duration. Defaults to 20. fit_ending_percentage (int, optional): Ending of the linear fit in percent of NVE production duration. Defaults to 80. just_conclude (bool, optional): If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) fit_starting_frame , fit_ending_frame , time_between_frames = m_utils . msd_opt_prepper ( self . nve_production_timestep_fs , self . nve_production_duration_ns , self . reporting_frequency_coordinates_unwrapped , fit_starting_percentage , fit_ending_percentage ) molecule_names , molecule_abbreviations , number_dict , total_number_molecules , chi_water_s , temperature_s , npt_equilibration_pressure_s , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . molecule_abbreviations , self . replica_number_dict , self . total_number_molecules , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , [ system . name for system in self . simulationsystems ]) chunked_replicas = [ self . replicas [ i : i + parallel_running ] for i in range ( 0 , len ( self . replicas ), parallel_running )] split_fac = int ( len ( chunked_replicas ) / submission_split ) submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if len ( submission_splits ) > submission_split : split_fac = int ( len ( chunked_replicas ) / submission_split ) + 1 submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if not just_conclude : for split in submission_splits : m_utils . hpc_submission_header ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , f 'split { id ( split ) } _analyze_msd' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in split : for replica in chunk : with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_sdc.py { hpc_folder } { replica . name } { replica . replica_number } { replica . chi_water } { self . water_abbreviation } { molecule_abbreviations } { time_between_frames } { fit_starting_frame } { fit_ending_frame } { replica . temperature } { replica . pressure } { replica . total_number_molecules } { molecule_names } { self . water_name } & \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'exit 0' ) with open ( f ' { self . submitdir } /submit_msd_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for split in submission_splits : file . write ( f '''sbatch split { id ( split ) } _analyze_msd.sh \\n ''' ) with open ( f ' { self . submitdir } /conclude_msd.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) file . write ( f 'source { hpc_workspace } /conda/etc/profile.d/conda.sh \\n ' ) file . write ( f 'conda activate { environment_name } \\n ' ) file . write ( f 'python { hpc_scripts_folder } /cluster_join_sdc_and_comp_visc.py { total_number_molecules } { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { hpc_folder } { name_list } { molecule_names } { self . water_name } { number_dict } { molecule_abbreviations } { self . water_abbreviation } { description } { self . replica_start } & \\n ' ) file . write ( 'wait \\n exit 0' ) def create_hpc_submission_analyze_hbonds ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , donors = 'donor_selection_string' , hydrogens = 'hydrogen_selection_string' , acceptors = 'acceptors_selection_string' , just_conclude = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. parallel_running (int, optional): The number of replica analyses running in parallel. Defaults to 5. submission_split (int, optional): The number of job submissions the analysis is split in. Defaults to 4. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. donors (str, optional): Selection of all hydrogen bond donor atoms in MDAnalysis selection syntax. Defaults to 'donor_selection_string'. hydrogens (str, optional): Selection of all hydrogen bond hydrogen atoms in MDAnalysis selection syntax. Defaults to 'hydrogens_selection_string'. acceptors (str, optional): Selection of all hydrogen bond acceptor atoms in MDAnalysis selection syntax. Defaults to 'acceptors_selection_string'. just_conclude (bool, optional): If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) molecule_names , number_dict , chi_water_s , temperature_s , npt_equilibration_pressure_s , molecule_abbreviations , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . replica_number_dict , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , self . molecule_abbreviations , [ system . name for system in self . simulationsystems ]) chunked_replicas = [ self . replicas [ i : i + parallel_running ] for i in range ( 0 , len ( self . replicas ), parallel_running )] split_fac = int ( len ( chunked_replicas ) / submission_split ) submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if len ( submission_splits ) > submission_split : split_fac = int ( len ( chunked_replicas ) / submission_split ) + 1 submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if not just_conclude : for split in submission_splits : m_utils . hpc_submission_header ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , f 'split { id ( split ) } _analyze_hbonds' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in split : for replica in chunk : with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_hbonds.py { hpc_folder } { replica . name } { replica . replica_number } { replica . chi_water } { replica . temperature } { replica . pressure } { replica . total_number_molecules } { molecule_names } \" { donors } \" \" { hydrogens } \" \" { acceptors } \" & \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'exit 0' ) with open ( f ' { self . submitdir } /submit_hbonds_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for split in submission_splits : file . write ( f '''sbatch split { id ( split ) } _analyze_hbonds.sh \\n ''' ) with open ( f ' { self . submitdir } /conclude_hbonds.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) file . write ( f 'source { hpc_workspace } /conda/etc/profile.d/conda.sh \\n ' ) file . write ( f 'conda activate { environment_name } \\n ' ) file . write ( f 'python { hpc_scripts_folder } /cluster_join_hbonds.py { hpc_folder } { name_list } { number_dict } { description } { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { molecule_names } { self . water_name } { molecule_abbreviations } { self . water_abbreviation } { self . replica_start } & \\n ' ) file . write ( 'wait \\n exit 0' ) def hpc_extend_replica_folders ( self , hpc_folder = 'workspace/project_name' ) -> None : \"\"\"Creates newly added replica folders to the system folders on the hpc. Args: hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. \"\"\" folder_list = [] for replica in self . replicas : folder_list . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder } / { replica . name } ' , replica . folder )) with open ( f ' { self . submitdir } /extend_replica_folders.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash ''' ) for folder_string in folder_list : file . write ( f '''mkdir { folder_string } ''' ) def hpc_job_checker ( self , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , hpc_workspace = 'workspace' , environment_name = 'openmm_new' , verbose = True , energy_shift_tolerance_percent = 1 ) -> None : \"\"\"Creates a bash script to check the overall status of the simulations on the hpc. Checked properties are doneness percent, average temperature and total energy shift. Args: hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmm_new'. verbose (bool, optional): If true checks average temperature and total energy shift. Defaults to True. energy_shift_tolerance_percent (int, optional): The tolerated energy shift in percent. If the energy shift of a simulation is greater, a warning is issued. Defaults to 1. \"\"\" system_file_list_ = [] for system in self . simulationsystems : system_file_list_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder } / { system . name } ' , system . folder )) system_file_list = sorted ( system_file_list_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) with open ( f ' { self . submitdir } /system_list.txt' , 'w' , newline = ' \\n ' ) as file : for file_str in system_file_list : file . write ( f ''' { file_str } ''' ) replica_file_list_ = [] for replica in self . replicas : replica_file_list_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder } / { replica . name } ' , replica . folder )) replica_file_list = sorted ( replica_file_list_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) replica_file_list . append ( 'finalize' ) with open ( f ' { self . submitdir } /replica_list.txt' , 'w' , newline = ' \\n ' ) as file : for file_str in replica_file_list : file . write ( f ''' { file_str } ''' ) with open ( f ' { self . submitdir } /job_checker.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash source { hpc_workspace } /conda/etc/profile.d/conda.sh conda activate { environment_name } python { hpc_scripts_folder } /job_checker.py { self . nvt_equilibration_duration_ns } { self . nve_production_duration_ns } { verbose } { energy_shift_tolerance_percent } { self . npt_equilibration_duration_ns } exit 0 ''' ) def remove_done_jobs_from_systems ( self , path_to_job_checks = 'workdir/job_checks.txt' ) -> None : \"\"\"Removes all systems that are done according to the job checker from the project. Args: path_to_job_checks (str, optional): The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. \"\"\" with open ( f ' { path_to_job_checks } ' , 'r' , newline = ' \\n ' ) as file : not_done_job_list_ = [ line . rstrip () for line in file if 'not yet adjusted' in line ] not_done_job_list = [ item [: - 17 ] for item in not_done_job_list_ ] filtered_systems = [] for system in self . simulationsystems : for string in not_done_job_list : if system . name in string : filtered_systems . append ( system ) self . simulationsystems = filtered_systems def remove_done_jobs_from_replicas ( self , path_to_job_checks = 'workdir/job_checks.txt' ) -> None : \"\"\"Removes all replicas that are done according to the job checker from the project. Args: path_to_job_checks (str, optional): The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. \"\"\" with open ( f ' { path_to_job_checks } ' , 'r' , newline = ' \\n ' ) as file : not_done_job_list_ = [ line . rstrip () for line in file if 'not yet finished' in line ] not_done_job_list = [ item [: - 17 ] for item in not_done_job_list_ ] filtered_replicas = [] for replica in self . replicas : for string in not_done_job_list : if replica . name in string and int ( re . search ( r '\\d+$' , string ) . group ()) == replica . replica_number : filtered_replicas . append ( replica ) self . replicas = filtered_replicas def overcharge_replicas ( self , total_number_molecules = 1000 , overcharge_amount = 10 ) -> None : \"\"\"Adds the overcharge amount to the replicas of the systems specified by total number of molecules. Args: total_number_molecules (int, optional): Number of molecules that are placed in the simulation box. Defaults to 1000. overcharge_amount (int, optional): Amount of replicas that should be added. Defaults to 10. \"\"\" filtered_systems = [ system for system in self . simulationsystems if system . total_number_molecules in total_number_molecules ] replica_count = range (( self . replica_count + self . replica_start ), ( self . replica_count + self . replica_start + overcharge_amount )) parameter_list = [ filtered_systems , replica_count ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : system , replica_number = combination replica = Replica ( self , system , replica_number ) self . replicas . append ( replica ) entry = f 'with { overcharge_amount } replicas' m_utils . add_json_entry ( f ' { self . description } ' , entry , key = 'project' , subkey = 'simulation_parameters' , subsubkey = 'overcharged_boxes' , subsubsubkey = f ' { total_number_molecules } molecules' ) self . replica_number_dict [ f ' { total_number_molecules } ' ] = self . replica_count + self . replica_start + overcharge_amount def transfer_project ( self , hpc_folder_old = 'workspace_old/project_name' , hpc_folder_new = 'workspace_new/project_name' ) -> None : \"\"\"Transfers a project between two workspaces. Args: hpc_folder_old (str, optional): The path to the old project folder on the hpc. Defaults to 'workspace_old/project_name'. hpc_folder_new (str, optional): The path to the new project folder on the hpc. Defaults to 'workspace_new/project_name'. \"\"\" system_file_list_old_ = [] system_file_list_new_ = [] for system in self . simulationsystems : system_file_list_old_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder_old } / { system . name } ' , system . folder )) system_file_list_new_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder_new } / { system . name } ' , system . folder )) system_file_list_old = sorted ( system_file_list_old_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) system_file_list_new = sorted ( system_file_list_new_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) with open ( f ' { self . submitdir } /transfer_project.py' , 'w' , newline = ' \\n ' ) as file : file . write ( 'import shutil \\n ' ) for file_str_old , file_str_new in zip ( system_file_list_old , system_file_list_new ): file . write ( f '''shutil.copytree(r\" { file_str_old } /npt_equilibration\", r\" { file_str_new } /npt_equilibration\") ''' ) replica_file_list_old_ = [] replica_file_list_new_ = [] for replica in self . replicas : replica_file_list_old_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder_old } / { replica . name } ' , replica . folder )) replica_file_list_new_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder_new } / { replica . name } ' , replica . folder )) replica_file_list_old = sorted ( replica_file_list_old_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) replica_file_list_new = sorted ( replica_file_list_new_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) with open ( f ' { self . submitdir } /transfer_project.py' , 'a' , newline = ' \\n ' ) as file : for file_str_old , file_str_new in zip ( replica_file_list_old , replica_file_list_new ): file . write ( f '''shutil.copytree(r\" { file_str_old } \", r\" { file_str_new } \") ''' ) with open ( f ' { self . submitdir } /transfer_project.py' , 'a' , newline = ' \\n ' ) as file : file . write ( f '''shutil.copytree(r\" { hpc_folder_old } /boxes\", r\" { hpc_folder_new } /boxes\") shutil.copytree(r\" { hpc_folder_old } /forcefield\", r\" { hpc_folder_new } /forcefield\") shutil.copytree(r\" { hpc_folder_old } /hpc_submission\", r\" { hpc_folder_new } /hpc_submission\") shutil.copytree(r\" { hpc_folder_old } /molecules\", r\" { hpc_folder_new } /molecules\") shutil.copytree(r\" { hpc_folder_old } /results\", r\" { hpc_folder_new } /results\") ''' )","title":"Project"},{"location":"mixturemm/#mixturemm.mixturemm.Project.__init__","text":"The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Parameters: Name Type Description Default workdir str The path at which the project should be stored. required simulation_platform str The platform the simulation should run on. Defaults to 'CUDA'. 'CUDA' simulation_properties dict The platform properties for the simulation. Defaults to {'DeviceIndex': '0', 'Precision': 'double'}. {'DeviceIndex': '0', 'Precision': 'double'} total_number_molecules list A list with the number of molecules that should be placed in the simulation box. Defaults to [1000]. [1000] init_box_side_length list The initial box side lengths that should be used by packmol. Defaults to [30]. [30] chi_water_s list A list with all different molar fractions of water that should be simulated. Defaults to [0,0.5,1]. [0, 0.5, 1] temperature_s list A list with all different temperatures in kelvin at which the boxes should be simulated. Defaults to [298.15]. [298.15] npt_equilibration_pressure_s list A list with all pressures in bar at which the boxes should be simulated. Defaults to [1]. [1] npt_equilibration_pressure_coupling_frequency int The pressure coupling frequency at which the Monte Carlo barostat should interact with the system and attempt a Monte Carlo move to adjust the volume during the NpT equilibration in simulation steps. Defaults to 25. 25 npt_equilibration_temperature_coupling_frequency float The friction coefficient of the Langevin thermostat during the NpT equilibration in inverse picoseconds. Defaults to 0.1. 0.1 npt_equilibration_timestep_fs int The integration time step during the NpT equilibration in femtoseconds. Defaults to 2. 2 npt_equilibration_duration_ns int The duration of the NpT equilibration in nanoseconds. Defaults to 10. 10 reporting_frequency_state_npt_equilibration int The reporting frequency of the openMM StateDataReporter in simulation steps during the NpT equilibration. Defaults to 500. 500 nvt_equilibration_temperature_coupling_frequency float The friction coefficient of the Langevin thermostat during the NVT equilibration in inverse picoseconds. Defaults to 0.1. 0.1 nvt_equilibration_timestep_fs int The integration time step during the NVT equilibration in femtoseconds. Defaults to 2. 2 nvt_equilibration_duration_ns int The duration of the NVT equilibration in nanoseconds. Defaults to 20. 20 reporting_frequency_state_nvt_equilibration int The reporting frequency of the openMM StateDataReporter in simulation steps during the NVT equilibration. Defaults to 2000. 2000 nve_production_timestep_fs int The integration time step during the NVE production in femtoseconds. Defaults to 1. 1 nve_production_duration_ns int The duration of the NVE production in nanoseconds. Defaults to 20. 20 reporting_frequency_coordinates_unwrapped int The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. Defaults to 2000. 2000 reporting_frequency_coordinates_wrapped int The reporting frequency of the trajectory with wrapped coordinates in simulation steps during the NVE production. Defaults to 4000. 4000 reporting_frequency_state_nve_production int The reporting frequency of the openMM StateDataReporter in simulation steps during the NVE production. Defaults to 4000. 4000 replica_count int The number of times the simulation of one system should be replicated. Defaults to 10. 10 pme_error_tolerance float Decides how large the grid for PME is together with the cutoff. Defaults to 0.000001. 1e-06 constraint_tolerance float The constraint tolerance specifies the distance tolerance within which constraints are maintained, as a fraction of the constrained distance. Defaults to 0.0000001 1e-07 cutoff_distance_nm float The cutoff distance for nonbonded interactions in nanometers. Defaults to 1.2. 1.2 cutoff_switch_distance_nm float Starting point of the switching function that makes the energy go smoothly to 0 at the cutoff distance in nanometers. Defaults to 1.0. 1.0 Source code in mixturemm/mixturemm.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def __init__ ( self , workdir , simulation_platform = 'CUDA' , simulation_properties = { 'DeviceIndex' : '0' , 'Precision' : 'double' }, total_number_molecules = [ 1000 ], init_box_side_length = [ 30 ], chi_water_s = [ 0 , 0.5 , 1 ], temperature_s = [ 298.15 ], npt_equilibration_pressure_s = [ 1 ], npt_equilibration_pressure_coupling_frequency = 25 , npt_equilibration_temperature_coupling_frequency = 0.1 , npt_equilibration_timestep_fs = 2 , npt_equilibration_duration_ns = 10 , reporting_frequency_state_npt_equilibration = 500 , nvt_equilibration_temperature_coupling_frequency = 0.1 , nvt_equilibration_timestep_fs = 2 , nvt_equilibration_duration_ns = 20 , reporting_frequency_state_nvt_equilibration = 2000 , nve_production_timestep_fs = 1 , nve_production_duration_ns = 20 , reporting_frequency_coordinates_unwrapped = 2000 , reporting_frequency_coordinates_wrapped = 4000 , reporting_frequency_state_nve_production = 4000 , replica_count = 10 , pme_error_tolerance = 0.000001 , constraint_tolerance = 0.0000001 , cutoff_distance_nm = 1.2 , cutoff_switch_distance_nm = 1.0 ) -> None : \"\"\"The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Args: workdir (str): The path at which the project should be stored. simulation_platform (str, optional): The platform the simulation should run on. Defaults to 'CUDA'. simulation_properties (dict, optional): The platform properties for the simulation. Defaults to {'DeviceIndex': '0', 'Precision': 'double'}. total_number_molecules (list, optional): A list with the number of molecules that should be placed in the simulation box. Defaults to [1000]. init_box_side_length (list, optional): The initial box side lengths that should be used by packmol. Defaults to [30]. chi_water_s (list, optional): A list with all different molar fractions of water that should be simulated. Defaults to [0,0.5,1]. temperature_s (list, optional): A list with all different temperatures in kelvin at which the boxes should be simulated. Defaults to [298.15]. npt_equilibration_pressure_s (list, optional): A list with all pressures in bar at which the boxes should be simulated. Defaults to [1]. npt_equilibration_pressure_coupling_frequency (int, optional): The pressure coupling frequency at which the Monte Carlo barostat should interact with the system and attempt a Monte Carlo move to adjust the volume during the NpT equilibration in simulation steps. Defaults to 25. npt_equilibration_temperature_coupling_frequency (float, optional): The friction coefficient of the Langevin thermostat during the NpT equilibration in inverse picoseconds. Defaults to 0.1. npt_equilibration_timestep_fs (int, optional): The integration time step during the NpT equilibration in femtoseconds. Defaults to 2. npt_equilibration_duration_ns (int, optional): The duration of the NpT equilibration in nanoseconds. Defaults to 10. reporting_frequency_state_npt_equilibration (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NpT equilibration. Defaults to 500. nvt_equilibration_temperature_coupling_frequency (float, optional): The friction coefficient of the Langevin thermostat during the NVT equilibration in inverse picoseconds. Defaults to 0.1. nvt_equilibration_timestep_fs (int, optional): The integration time step during the NVT equilibration in femtoseconds. Defaults to 2. nvt_equilibration_duration_ns (int, optional): The duration of the NVT equilibration in nanoseconds. Defaults to 20. reporting_frequency_state_nvt_equilibration (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NVT equilibration. Defaults to 2000. nve_production_timestep_fs (int, optional): The integration time step during the NVE production in femtoseconds. Defaults to 1. nve_production_duration_ns (int, optional): The duration of the NVE production in nanoseconds. Defaults to 20. reporting_frequency_coordinates_unwrapped (int, optional): The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. Defaults to 2000. reporting_frequency_coordinates_wrapped (int, optional): The reporting frequency of the trajectory with wrapped coordinates in simulation steps during the NVE production. Defaults to 4000. reporting_frequency_state_nve_production (int, optional): The reporting frequency of the openMM StateDataReporter in simulation steps during the NVE production. Defaults to 4000. replica_count (int, optional): The number of times the simulation of one system should be replicated. Defaults to 10. pme_error_tolerance (float, optional): Decides how large the grid for PME is together with the cutoff. Defaults to 0.000001. constraint_tolerance (float, optional): The constraint tolerance specifies the distance tolerance within which constraints are maintained, as a fraction of the constrained distance. Defaults to 0.0000001 cutoff_distance_nm (float, optional): The cutoff distance for nonbonded interactions in nanometers. Defaults to 1.2. cutoff_switch_distance_nm (float, optional): Starting point of the switching function that makes the energy go smoothly to 0 at the cutoff distance in nanometers. Defaults to 1.0. \"\"\" self . workdir = m_utils . directory_maker ( workdir ) self . moldir = m_utils . directory_maker ( f ' { self . workdir } /molecules' ) self . boxdir = m_utils . directory_maker ( f ' { self . workdir } /boxes' ) self . resdir = m_utils . directory_maker ( f ' { self . workdir } /results' ) self . submitdir = m_utils . directory_maker ( f ' { self . workdir } /hpc_submission' ) self . forcedir = m_utils . directory_maker ( f ' { self . workdir } /forcefield' ) self . res_rawdir = m_utils . directory_maker ( f ' { self . resdir } /raw_data' ) self . res_partsdir = m_utils . directory_maker ( f ' { self . resdir } /parts' ) self . molecules = [] self . simulation_boxes = [] self . simulationsystems = [] self . replicas = [] self . molecule_names = [] self . molecule_number_of_atoms = [] self . molecule_abbreviations = [] self . mixture_dict = {} self . forcefields = [] self . elements = {} self . chi_water_s = chi_water_s self . total_number_molecules = total_number_molecules self . init_box_side_length = init_box_side_length self . water_name = 'Water' self . water_abbreviation = 'HOH' self . replica_number_dict = None self . simulation_platform = simulation_platform self . simulation_properties = simulation_properties self . temperature_s = temperature_s self . npt_equilibration_pressure_s = npt_equilibration_pressure_s self . npt_equilibration_pressure_coupling_frequency = npt_equilibration_pressure_coupling_frequency self . npt_equilibration_temperature_coupling_frequency = npt_equilibration_temperature_coupling_frequency self . npt_equilibration_timestep_fs = npt_equilibration_timestep_fs self . npt_equilibration_duration_ns = npt_equilibration_duration_ns self . nvt_equilibration_temperature_coupling_frequency = nvt_equilibration_temperature_coupling_frequency self . nvt_equilibration_timestep_fs = nvt_equilibration_timestep_fs self . nvt_equilibration_duration_ns = nvt_equilibration_duration_ns self . nve_production_timestep_fs = nve_production_timestep_fs self . nve_production_duration_ns = nve_production_duration_ns self . reporting_frequency_coordinates_unwrapped = reporting_frequency_coordinates_unwrapped self . reporting_frequency_coordinates_wrapped = reporting_frequency_coordinates_wrapped self . reporting_frequency_state_npt_equilibration = reporting_frequency_state_npt_equilibration self . reporting_frequency_state_nvt_equilibration = reporting_frequency_state_nvt_equilibration self . reporting_frequency_state_nve_production = reporting_frequency_state_nve_production self . replica_count = replica_count self . pme_error_tolerance = pme_error_tolerance self . constraint_tolerance = constraint_tolerance self . cutoff_distance_nm = cutoff_distance_nm self . cutoff_switch_distance_nm = cutoff_switch_distance_nm self . half_npt_equilibration_csv_columns = int (((( self . npt_equilibration_duration_ns / self . npt_equilibration_timestep_fs ) * ( 10 ** 6 )) / reporting_frequency_state_npt_equilibration ) / 2 ) self . create_description () m_utils . add_chainsubmitter_script ( self . submitdir )","title":"__init__()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.add_forcefield","text":"Adds a force field to the project. Parameters: Name Type Description Default Forcefield object Contains information on the force field. required Source code in mixturemm/mixturemm.py 180 181 182 183 184 185 186 187 188 189 190 191 def add_forcefield ( self , Forcefield ) -> None : \"\"\"Adds a force field to the project. Args: Forcefield (object): Contains information on the force field. \"\"\" self . forcefields . append ( Forcefield . path ) if Forcefield . elements is not None : self . elements . update ( Forcefield . elements ) json_structure = m_utils . jsonize_forcefield ( Forcefield ) m_utils . add_json_entry ( f ' { self . description } ' , json_structure , key = 'force fields' , subkey = f ' { Forcefield . ff_name } ' )","title":"add_forcefield()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.add_mixture","text":"Adds a mixture to the project. Parameters: Name Type Description Default Mixture object Contains information on the mixture that is simulated. required Source code in mixturemm/mixturemm.py 193 194 195 196 197 198 199 200 def add_mixture ( self , Mixture ) -> None : \"\"\"Adds a mixture to the project. Args: Mixture (object): Contains information on the mixture that is simulated. \"\"\" self . mixture_dict = Mixture . mixture_dict","title":"add_mixture()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.add_molecule","text":"Adds a molecule to the project. Parameters: Name Type Description Default Molecule object Contains information on the molecule that is used for packing with packmol and to identify it. required Source code in mixturemm/mixturemm.py 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def add_molecule ( self , Molecule ) -> None : \"\"\"Adds a molecule to the project. Args: Molecule (object): Contains information on the molecule that is used for packing with packmol and to identify it. \"\"\" if Molecule . use_as_water : self . water_name = Molecule . name self . water_abbreviation = Molecule . abbreviation else : self . molecules . append ( Molecule ) self . molecule_names . append ( Molecule . name ) self . molecule_number_of_atoms . append ( Molecule . number_of_atoms ) self . molecule_abbreviations . append ( Molecule . abbreviation ) json_structure = m_utils . jsonize_molecule ( Molecule ) m_utils . add_json_entry ( f ' { self . description } ' , json_structure , key = 'molecules' , subkey = f ' { Molecule . name } ' )","title":"add_molecule()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.adjust_to_correct_density","text":"Runs the NpT equilibration to adjust the system volume and density to the correct value. Source code in mixturemm/mixturemm.py 253 254 255 256 257 258 def adjust_to_correct_density ( self ) -> None : \"\"\"Runs the NpT equilibration to adjust the system volume and density to the correct value. \"\"\" for system in self . simulationsystems : system . npt_equilibration ()","title":"adjust_to_correct_density()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.create_description","text":"Creates a .json file with all input arguments of the project and info on all added files. Source code in mixturemm/mixturemm.py 150 151 152 153 154 155 156 157 158 159 160 def create_description ( self ) -> None : \"\"\"Creates a .json file with all input arguments of the project and info on all added files. \"\"\" json_structure = m_utils . jsonize_project ( self ) if os . path . isfile ( f ' { self . workdir } /project_description.json' ) == False : with open ( f ' { self . workdir } /project_description.json' , 'w' , encoding = 'utf-8' ) as f : json . dump ( json_structure , f , ensure_ascii = False , indent = 4 ) else : m_utils . merge_project_descriptions ( f ' { self . workdir } /project_description.json' , json_structure ) self . description = f ' { self . workdir } /project_description.json'","title":"create_description()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.create_hpc_submission_adjust_to_correct_density","text":"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the NpT equilibration. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. 'openmm_new' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'accelerated'. 'accelerated' number_of_threads int The number of requested threads. Defaults to 152. 152 number_of_gpus int The number of GPUs requested on a node. Defaults to 4. 4 chunk_size int Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. 4 max_number_of_jobs int Maximum number of job submissions allowed on the hpc. Defaults to None. None max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '24:00:00'. '24:00:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False chain_submission_number int The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. 1 dependency_type str Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. 'afternotok' checkpoint_frequency int The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. 10000 Source code in mixturemm/mixturemm.py 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 def create_hpc_submission_adjust_to_correct_density ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the NpT equilibration. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'accelerated'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. number_of_gpus (int, optional): The number of GPUs requested on a node. Defaults to 4. chunk_size (int, optional): Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. max_number_of_jobs (int, optional): Maximum number of job submissions allowed on the hpc. Defaults to None. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. chain_submission_number (int, optional): The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. dependency_type (str, optional): Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. checkpoint_frequency (int, optional): The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. \"\"\" forcefields_ = [ re . sub ( r '^.*?/forcefield' , f ' { hpc_folder } /forcefield' , forcefield ) for forcefield in self . forcefields ] forcefields = ',' . join ( forcefields_ ) if self . elements : elements = m_utils . bash_arg_prepper ( self . elements ) else : elements = None if max_number_of_jobs is None : chunked_simulationsystems = [ self . simulationsystems [ i : i + chunk_size ] for i in range ( 0 , len ( self . simulationsystems ), chunk_size )] else : chunked_simulationsystems = [ self . simulationsystems [ i : i + chunk_size ] for i in range ( 0 , len ( self . simulationsystems ), chunk_size )][: max_number_of_jobs ] for chunk in chunked_simulationsystems : GPU_INDEX_COUNTER = 0 m_utils . hpc_submission_header ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , f ' { id ( chunk ) } _adjust_to_correct_density' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) for system in chunk : with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , 'a' , newline = ' \\n ' ) as file : if 'DeviceIndex' and 'Precision' in self . simulation_properties : simulation_properties_ = self . simulation_properties simulation_properties_ [ 'DeviceIndex' ] = f ' { GPU_INDEX_COUNTER } ' simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) else : simulation_properties_ = { 'DeviceIndex' : f ' { GPU_INDEX_COUNTER } ' , 'Precision' : 'double' } simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) if self . simulation_platform == 'CUDA' : simulation_platform = self . simulation_platform else : simulation_platform = 'CUDA' file . write ( f 'python { hpc_scripts_folder } /cluster_adjust_to_correct_density.py { hpc_folder } { simulation_properties } { simulation_platform } { forcefields } { system . pme_error_tolerance } { system . cutoff_distance_nm } { system . cutoff_switch_distance_nm } { system . name } { system . temperature } { system . pressure } { system . simulationbox_name } { system . npt_equilibration_pressure_coupling_frequency } { system . npt_equilibration_temperature_coupling_frequency } { system . npt_equilibration_timestep_fs } { system . npt_equilibration_steps } { system . reporting_frequency_state_npt_equilibration } { system . constraint_tolerance } { checkpoint_frequency } { elements } & \\n ' ) GPU_INDEX_COUNTER += 1 with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _adjust_to_correct_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( ' \\n wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_adjust_to_correct_density.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for chunk in chunked_simulationsystems : if chain_submission_number > 1 : file . write ( f '''bash chainsubmitter.sh { chain_submission_number } { hpc_folder } /shfiles/chunk { id ( chunk ) } _adjust_to_correct_density.sh { dependency_type } { partition } \\n ''' ) else : file . write ( f '''sbatch chunk { id ( chunk ) } _adjust_to_correct_density.sh \\n ''' )","title":"create_hpc_submission_adjust_to_correct_density()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.create_hpc_submission_analyze_density","text":"Creates job submission scripts for bwUniCluster 2.0 containing the density anlysis. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. 'analysis' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'cpuonly'. 'cpuonly' number_of_threads int The number of requested threads. Defaults to 152. 152 max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '00:10:00'. '00:10:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False Source code in mixturemm/mixturemm.py 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 def create_hpc_submission_analyze_density ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , max_runtime_hh_mm_ss = '00:10:00' , conda_module = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 containing the density anlysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '00:10:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) molecule_names , chi_water_s , temperature_s , npt_equilibration_pressure_s , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , [ system . name for system in self . simulationsystems ]) chunked_simulationsystems = [ self . simulationsystems [ i : i + 10 ] for i in range ( 0 , len ( self . simulationsystems ), 10 )] m_utils . hpc_submission_header ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , f 'id { id ( self . simulationsystems ) } _analyze_density' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in chunked_simulationsystems : for system in chunk : with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_density.py { hpc_folder } { system . name } { self . half_npt_equilibration_csv_columns } { system . total_number_molecules } { system . temperature } { system . pressure } { system . chi_water } { molecule_names } & \\n ' ) with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /id { id ( self . simulationsystems ) } _analyze_density.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_join_density.py { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { hpc_folder } { name_list } { molecule_names } { self . water_name } { description } & \\n ' ) file . write ( 'wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_density_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n sbatch id { id ( self . simulationsystems ) } _analyze_density.sh \\n ''' )","title":"create_hpc_submission_analyze_density()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.create_hpc_submission_analyze_hbonds","text":"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. 'analysis' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'cpuonly'. 'cpuonly' number_of_threads int The number of requested threads. Defaults to 152. 152 parallel_running int The number of replica analyses running in parallel. Defaults to 5. 5 submission_split int The number of job submissions the analysis is split in. Defaults to 4. 4 max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '24:00:00'. '24:00:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False donors str Selection of all hydrogen bond donor atoms in MDAnalysis selection syntax. Defaults to 'donor_selection_string'. 'donor_selection_string' hydrogens str Selection of all hydrogen bond hydrogen atoms in MDAnalysis selection syntax. Defaults to 'hydrogens_selection_string'. 'hydrogen_selection_string' acceptors str Selection of all hydrogen bond acceptor atoms in MDAnalysis selection syntax. Defaults to 'acceptors_selection_string'. 'acceptors_selection_string' just_conclude bool If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. False Source code in mixturemm/mixturemm.py 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 def create_hpc_submission_analyze_hbonds ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , donors = 'donor_selection_string' , hydrogens = 'hydrogen_selection_string' , acceptors = 'acceptors_selection_string' , just_conclude = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. parallel_running (int, optional): The number of replica analyses running in parallel. Defaults to 5. submission_split (int, optional): The number of job submissions the analysis is split in. Defaults to 4. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. donors (str, optional): Selection of all hydrogen bond donor atoms in MDAnalysis selection syntax. Defaults to 'donor_selection_string'. hydrogens (str, optional): Selection of all hydrogen bond hydrogen atoms in MDAnalysis selection syntax. Defaults to 'hydrogens_selection_string'. acceptors (str, optional): Selection of all hydrogen bond acceptor atoms in MDAnalysis selection syntax. Defaults to 'acceptors_selection_string'. just_conclude (bool, optional): If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) molecule_names , number_dict , chi_water_s , temperature_s , npt_equilibration_pressure_s , molecule_abbreviations , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . replica_number_dict , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , self . molecule_abbreviations , [ system . name for system in self . simulationsystems ]) chunked_replicas = [ self . replicas [ i : i + parallel_running ] for i in range ( 0 , len ( self . replicas ), parallel_running )] split_fac = int ( len ( chunked_replicas ) / submission_split ) submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if len ( submission_splits ) > submission_split : split_fac = int ( len ( chunked_replicas ) / submission_split ) + 1 submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if not just_conclude : for split in submission_splits : m_utils . hpc_submission_header ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , f 'split { id ( split ) } _analyze_hbonds' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in split : for replica in chunk : with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_hbonds.py { hpc_folder } { replica . name } { replica . replica_number } { replica . chi_water } { replica . temperature } { replica . pressure } { replica . total_number_molecules } { molecule_names } \" { donors } \" \" { hydrogens } \" \" { acceptors } \" & \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_hbonds.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'exit 0' ) with open ( f ' { self . submitdir } /submit_hbonds_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for split in submission_splits : file . write ( f '''sbatch split { id ( split ) } _analyze_hbonds.sh \\n ''' ) with open ( f ' { self . submitdir } /conclude_hbonds.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) file . write ( f 'source { hpc_workspace } /conda/etc/profile.d/conda.sh \\n ' ) file . write ( f 'conda activate { environment_name } \\n ' ) file . write ( f 'python { hpc_scripts_folder } /cluster_join_hbonds.py { hpc_folder } { name_list } { number_dict } { description } { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { molecule_names } { self . water_name } { molecule_abbreviations } { self . water_abbreviation } { self . replica_start } & \\n ' ) file . write ( 'wait \\n exit 0' )","title":"create_hpc_submission_analyze_hbonds()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.create_hpc_submission_analyze_msd","text":"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. 'analysis' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'cpuonly'. 'cpuonly' number_of_threads int The number of requested threads. Defaults to 152. 152 parallel_running int The number of replica analyses running in parallel. Defaults to 5. 5 submission_split int The number of job submissions the analysis is split in. Defaults to 4. 4 max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '24:00:00'. '24:00:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False fit_starting_percentage int Start of the linear fit in percent of NVE production duration. Defaults to 20. 20 fit_ending_percentage int Ending of the linear fit in percent of NVE production duration. Defaults to 80. 80 just_conclude bool If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. False Source code in mixturemm/mixturemm.py 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 def create_hpc_submission_analyze_msd ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 5 , submission_split = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , fit_starting_percentage = 20 , fit_ending_percentage = 80 , just_conclude = False ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 or HoreKa containing the mean squared displacement, self-diffusion coefficient and viscosity analysis. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'analysis'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'cpuonly'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. parallel_running (int, optional): The number of replica analyses running in parallel. Defaults to 5. submission_split (int, optional): The number of job submissions the analysis is split in. Defaults to 4. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. fit_starting_percentage (int, optional): Start of the linear fit in percent of NVE production duration. Defaults to 20. fit_ending_percentage (int, optional): Ending of the linear fit in percent of NVE production duration. Defaults to 80. just_conclude (bool, optional): If true, skips the generation of job submissions scripts and just generates the conclude script. Defaults to True. \"\"\" description = re . sub ( r '^.*?/project_description.json' , f ' { hpc_folder } /project_description.json' , self . description ) fit_starting_frame , fit_ending_frame , time_between_frames = m_utils . msd_opt_prepper ( self . nve_production_timestep_fs , self . nve_production_duration_ns , self . reporting_frequency_coordinates_unwrapped , fit_starting_percentage , fit_ending_percentage ) molecule_names , molecule_abbreviations , number_dict , total_number_molecules , chi_water_s , temperature_s , npt_equilibration_pressure_s , name_list = m_utils . bash_arg_prepper ( self . molecule_names , self . molecule_abbreviations , self . replica_number_dict , self . total_number_molecules , self . chi_water_s , self . temperature_s , self . npt_equilibration_pressure_s , [ system . name for system in self . simulationsystems ]) chunked_replicas = [ self . replicas [ i : i + parallel_running ] for i in range ( 0 , len ( self . replicas ), parallel_running )] split_fac = int ( len ( chunked_replicas ) / submission_split ) submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if len ( submission_splits ) > submission_split : split_fac = int ( len ( chunked_replicas ) / submission_split ) + 1 submission_splits = [ chunked_replicas [ i : i + split_fac ] for i in range ( 0 , len ( chunked_replicas ), split_fac )] if not just_conclude : for split in submission_splits : m_utils . hpc_submission_header ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , f 'split { id ( split ) } _analyze_msd' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , None , max_runtime_hh_mm_ss , conda_module ) for chunk in split : for replica in chunk : with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( f 'python { hpc_scripts_folder } /cluster_get_sdc.py { hpc_folder } { replica . name } { replica . replica_number } { replica . chi_water } { self . water_abbreviation } { molecule_abbreviations } { time_between_frames } { fit_starting_frame } { fit_ending_frame } { replica . temperature } { replica . pressure } { replica . total_number_molecules } { molecule_names } { self . water_name } & \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'wait \\n ' ) with open ( f ' { self . submitdir } /split { id ( split ) } _analyze_msd.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( 'exit 0' ) with open ( f ' { self . submitdir } /submit_msd_analysis.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for split in submission_splits : file . write ( f '''sbatch split { id ( split ) } _analyze_msd.sh \\n ''' ) with open ( f ' { self . submitdir } /conclude_msd.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) file . write ( f 'source { hpc_workspace } /conda/etc/profile.d/conda.sh \\n ' ) file . write ( f 'conda activate { environment_name } \\n ' ) file . write ( f 'python { hpc_scripts_folder } /cluster_join_sdc_and_comp_visc.py { total_number_molecules } { chi_water_s } { temperature_s } { npt_equilibration_pressure_s } { hpc_folder } { name_list } { molecule_names } { self . water_name } { number_dict } { molecule_abbreviations } { self . water_abbreviation } { description } { self . replica_start } & \\n ' ) file . write ( 'wait \\n exit 0' )","title":"create_hpc_submission_analyze_msd()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.create_hpc_submission_simulate","text":"Creates job submission scripts for bwUniCluster 2.0 containing the NVT equilibration and NVE production. Parameters: Name Type Description Default hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. 'openmm_new' scheduler str The queue scheduler. Defaults to 'SBATCH'. 'SBATCH' partition str The partition the job should be submitted to. Defaults to 'accelerated'. 'accelerated' number_of_threads int The number of requested threads. Defaults to 152. 152 number_of_gpus int The number of GPUs requested on a node. Defaults to 4. 4 chunk_size int Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. 4 max_number_of_jobs int Maximum number of job submissions allowed on the hpc. Defaults to None. None max_runtime_hh_mm_ss str Maximum runtime for a job. Defaults to '24:00:00'. '24:00:00' conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. False chain_submission_number int The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. 1 dependency_type str Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. 'afternotok' checkpoint_frequency int The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. 10000 Source code in mixturemm/mixturemm.py 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 def create_hpc_submission_simulate ( self , hpc_workspace = 'workspace' , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , environment_name = 'openmm_new' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = None , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 10000 ) -> None : \"\"\"Creates job submission scripts for bwUniCluster 2.0 containing the NVT equilibration and NVE production. Args: hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmmfin'. scheduler (str, optional): The queue scheduler. Defaults to 'SBATCH'. partition (str, optional): The partition the job should be submitted to. Defaults to 'accelerated'. number_of_threads (int, optional): The number of requested threads. Defaults to 152. number_of_gpus (int, optional): The number of GPUs requested on a node. Defaults to 4. chunk_size (int, optional): Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. Defaults to 4. max_number_of_jobs (int, optional): Maximum number of job submissions allowed on the hpc. Defaults to None. max_runtime_hh_mm_ss (str, optional): Maximum runtime for a job. Defaults to '24:00:00'. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. Defaults to False. chain_submission_number (int, optional): The number of job submissions that should be submitted as a sequential chain job. Defaults to 1. dependency_type (str, optional): Dependency keyword of the SLURM workload manager for chain jobs. Defaults to 'afternotok'. checkpoint_frequency (int, optional): The frequency at which checkpoints are saved to restart from once a job continues. Defaults to 10000. \"\"\" forcefields_ = [ re . sub ( r '^.*?/forcefield' , f ' { hpc_folder } /forcefield' , forcefield ) for forcefield in self . forcefields ] forcefields = ',' . join ( forcefields_ ) if self . elements : elements = m_utils . bash_arg_prepper ( self . elements ) else : elements = None if max_number_of_jobs is None : chunked_replicas = [ self . replicas [ i : i + chunk_size ] for i in range ( 0 , len ( self . replicas ), chunk_size )] else : chunked_replicas = [ self . replicas [ i : i + chunk_size ] for i in range ( 0 , len ( self . replicas ), chunk_size )][: max_number_of_jobs ] for chunk in chunked_replicas : GPU_INDEX_COUNTER = 0 m_utils . hpc_submission_header ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , f ' { id ( chunk ) } _simulate' , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) for replica in chunk : with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , 'a' , newline = ' \\n ' ) as file : if 'DeviceIndex' and 'Precision' in self . simulation_properties : simulation_properties_ = self . simulation_properties simulation_properties_ [ 'DeviceIndex' ] = f ' { GPU_INDEX_COUNTER } ' simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) else : simulation_properties_ = { 'DeviceIndex' : f ' { GPU_INDEX_COUNTER } ' , 'Precision' : 'double' } simulation_properties = m_utils . bash_arg_prepper ( simulation_properties_ ) if self . simulation_platform == 'CUDA' : simulation_platform = self . simulation_platform else : simulation_platform = 'CUDA' file . write ( f 'python { hpc_scripts_folder } /cluster_simulate.py { hpc_folder } { simulation_properties } { simulation_platform } { forcefields } { replica . pme_error_tolerance } { replica . cutoff_distance_nm } { replica . cutoff_switch_distance_nm } { replica . name } { replica . replica_number } { replica . temperature } { replica . half_npt_equilibration_csv_columns } { replica . nvt_equilibration_temperature_coupling_frequency } { replica . nvt_equilibration_steps } { replica . nvt_equilibration_timestep_fs } { replica . reporting_frequency_state_nvt_equilibration } { replica . nve_production_timestep_fs } { replica . nve_production_steps } { replica . reporting_frequency_coordinates_unwrapped } { replica . reporting_frequency_coordinates_wrapped } { replica . reporting_frequency_state_nve_production } { checkpoint_frequency } { replica . constraint_tolerance } { elements } & \\n ' ) GPU_INDEX_COUNTER += 1 with open ( f ' { self . submitdir } /chunk { id ( chunk ) } _simulate.sh' , 'a' , newline = ' \\n ' ) as file : file . write ( ' \\n wait \\n exit 0' ) with open ( f ' { self . submitdir } /submit_simulate.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash \\n ''' ) for chunk in chunked_replicas : if chain_submission_number > 1 : file . write ( f '''bash chainsubmitter.sh { chain_submission_number } { hpc_folder } /shfiles/chunk { id ( chunk ) } _simulate.sh { dependency_type } { partition } \\n ''' ) else : file . write ( f '''sbatch chunk { id ( chunk ) } _simulate.sh \\n ''' )","title":"create_hpc_submission_simulate()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.create_replicas","text":"Creates replicas of the systems and assigns NVT equilibration and NVE production parameters to them. Parameters: Name Type Description Default start int The number from which on the replica numbering will start. Defaults to 1. 1 Source code in mixturemm/mixturemm.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 def create_replicas ( self , start = 1 ) -> None : \"\"\"Creates replicas of the systems and assigns NVT equilibration and NVE production parameters to them. Args: start (int, optional): The number from which on the replica numbering will start. Defaults to 1. \"\"\" self . replica_start = start replica_count = range ( start , ( self . replica_count + start )) self . replica_number_dict = {} for tot in self . total_number_molecules : self . replica_number_dict [ f ' { tot } ' ] = self . replica_count parameter_list = [ self . simulationsystems , replica_count ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : system , replica_number = combination replica = Replica ( self , system , replica_number ) self . replicas . append ( replica ) m_utils . add_json_entry ( f ' { self . description } ' , start , key = 'project' , subkey = 'simulation_parameters' , subsubkey = 'replica_starting_number' )","title":"create_replicas()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.create_simulationboxes","text":"Creates and packs the simulation boxes. Source code in mixturemm/mixturemm.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 def create_simulationboxes ( self ) -> None : \"\"\"Creates and packs the simulation boxes. \"\"\" LINKER = '-' for total_number_molecules , init_box_side_length in zip ( self . total_number_molecules , self . init_box_side_length ): for chi_water in self . chi_water_s : string_total_number_molecules = str ( total_number_molecules ) string_init_box_side_length = str ( init_box_side_length ) string_chi_water = str ( chi_water ) mixture_tuple = ( string_total_number_molecules , string_init_box_side_length , string_chi_water ) mixture_name = LINKER . join ( mixture_tuple ) simulation_box = Simulationbox ( self , total_number_molecules , init_box_side_length , chi_water , self . water_name , mixture_name ) self . simulation_boxes . append ( simulation_box ) for x in self . simulation_boxes : x . pack () x . conect_creator ()","title":"create_simulationboxes()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.create_systems","text":"Assigns temperature, pressure and NpT equilibration parameters to the boxes. Source code in mixturemm/mixturemm.py 221 222 223 224 225 226 227 228 229 230 def create_systems ( self ) -> None : \"\"\"Assigns temperature, pressure and NpT equilibration parameters to the boxes. \"\"\" parameter_list = [ self . simulation_boxes , self . temperature_s , self . npt_equilibration_pressure_s ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : simulationbox , temperature , pressure = combination system = Simulationsystem ( self , simulationbox , temperature , pressure ) self . simulationsystems . append ( system )","title":"create_systems()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.hpc_extend_replica_folders","text":"Creates newly added replica folders to the system folders on the hpc. Parameters: Name Type Description Default hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' Source code in mixturemm/mixturemm.py 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 def hpc_extend_replica_folders ( self , hpc_folder = 'workspace/project_name' ) -> None : \"\"\"Creates newly added replica folders to the system folders on the hpc. Args: hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. \"\"\" folder_list = [] for replica in self . replicas : folder_list . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder } / { replica . name } ' , replica . folder )) with open ( f ' { self . submitdir } /extend_replica_folders.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash ''' ) for folder_string in folder_list : file . write ( f '''mkdir { folder_string } ''' )","title":"hpc_extend_replica_folders()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.hpc_job_checker","text":"Creates a bash script to check the overall status of the simulations on the hpc. Checked properties are doneness percent, average temperature and total energy shift. Parameters: Name Type Description Default hpc_folder str The path to the project folder on the hpc. Defaults to 'workspace/project_name'. 'workspace/project_name' hpc_scripts_folder str The path to the python scripts folder. Defaults to 'workspace/HPC'. 'workspace/HPC' hpc_workspace str The path to the hpc workspace. Defaults to 'workspace'. 'workspace' environment_name str The name of the anaconda environment containing the dependencies. Defaults to 'openmm_new'. 'openmm_new' verbose bool If true checks average temperature and total energy shift. Defaults to True. True energy_shift_tolerance_percent int The tolerated energy shift in percent. If the energy shift of a simulation is greater, a warning is issued. Defaults to 1. 1 Source code in mixturemm/mixturemm.py 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 def hpc_job_checker ( self , hpc_folder = 'workspace/project_name' , hpc_scripts_folder = 'workspace/HPC' , hpc_workspace = 'workspace' , environment_name = 'openmm_new' , verbose = True , energy_shift_tolerance_percent = 1 ) -> None : \"\"\"Creates a bash script to check the overall status of the simulations on the hpc. Checked properties are doneness percent, average temperature and total energy shift. Args: hpc_folder (str, optional): The path to the project folder on the hpc. Defaults to 'workspace/project_name'. hpc_scripts_folder (str, optional): The path to the python scripts folder. Defaults to 'workspace/HPC'. hpc_workspace (str, optional): The path to the hpc workspace. Defaults to 'workspace'. environment_name (str, optional): The name of the anaconda environment containing the dependencies. Defaults to 'openmm_new'. verbose (bool, optional): If true checks average temperature and total energy shift. Defaults to True. energy_shift_tolerance_percent (int, optional): The tolerated energy shift in percent. If the energy shift of a simulation is greater, a warning is issued. Defaults to 1. \"\"\" system_file_list_ = [] for system in self . simulationsystems : system_file_list_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder } / { system . name } ' , system . folder )) system_file_list = sorted ( system_file_list_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) with open ( f ' { self . submitdir } /system_list.txt' , 'w' , newline = ' \\n ' ) as file : for file_str in system_file_list : file . write ( f ''' { file_str } ''' ) replica_file_list_ = [] for replica in self . replicas : replica_file_list_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder } / { replica . name } ' , replica . folder )) replica_file_list = sorted ( replica_file_list_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) replica_file_list . append ( 'finalize' ) with open ( f ' { self . submitdir } /replica_list.txt' , 'w' , newline = ' \\n ' ) as file : for file_str in replica_file_list : file . write ( f ''' { file_str } ''' ) with open ( f ' { self . submitdir } /job_checker.sh' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash source { hpc_workspace } /conda/etc/profile.d/conda.sh conda activate { environment_name } python { hpc_scripts_folder } /job_checker.py { self . nvt_equilibration_duration_ns } { self . nve_production_duration_ns } { verbose } { energy_shift_tolerance_percent } { self . npt_equilibration_duration_ns } exit 0 ''' )","title":"hpc_job_checker()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.overcharge_replicas","text":"Adds the overcharge amount to the replicas of the systems specified by total number of molecules. Parameters: Name Type Description Default total_number_molecules int Number of molecules that are placed in the simulation box. Defaults to 1000. 1000 overcharge_amount int Amount of replicas that should be added. Defaults to 10. 10 Source code in mixturemm/mixturemm.py 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 def overcharge_replicas ( self , total_number_molecules = 1000 , overcharge_amount = 10 ) -> None : \"\"\"Adds the overcharge amount to the replicas of the systems specified by total number of molecules. Args: total_number_molecules (int, optional): Number of molecules that are placed in the simulation box. Defaults to 1000. overcharge_amount (int, optional): Amount of replicas that should be added. Defaults to 10. \"\"\" filtered_systems = [ system for system in self . simulationsystems if system . total_number_molecules in total_number_molecules ] replica_count = range (( self . replica_count + self . replica_start ), ( self . replica_count + self . replica_start + overcharge_amount )) parameter_list = [ filtered_systems , replica_count ] combination_list = list ( itertools . product ( * parameter_list )) for combination in combination_list : system , replica_number = combination replica = Replica ( self , system , replica_number ) self . replicas . append ( replica ) entry = f 'with { overcharge_amount } replicas' m_utils . add_json_entry ( f ' { self . description } ' , entry , key = 'project' , subkey = 'simulation_parameters' , subsubkey = 'overcharged_boxes' , subsubsubkey = f ' { total_number_molecules } molecules' ) self . replica_number_dict [ f ' { total_number_molecules } ' ] = self . replica_count + self . replica_start + overcharge_amount","title":"overcharge_replicas()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.remove_done_jobs_from_replicas","text":"Removes all replicas that are done according to the job checker from the project. Parameters: Name Type Description Default path_to_job_checks str The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. 'workdir/job_checks.txt' Source code in mixturemm/mixturemm.py 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 def remove_done_jobs_from_replicas ( self , path_to_job_checks = 'workdir/job_checks.txt' ) -> None : \"\"\"Removes all replicas that are done according to the job checker from the project. Args: path_to_job_checks (str, optional): The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. \"\"\" with open ( f ' { path_to_job_checks } ' , 'r' , newline = ' \\n ' ) as file : not_done_job_list_ = [ line . rstrip () for line in file if 'not yet finished' in line ] not_done_job_list = [ item [: - 17 ] for item in not_done_job_list_ ] filtered_replicas = [] for replica in self . replicas : for string in not_done_job_list : if replica . name in string and int ( re . search ( r '\\d+$' , string ) . group ()) == replica . replica_number : filtered_replicas . append ( replica ) self . replicas = filtered_replicas","title":"remove_done_jobs_from_replicas()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.remove_done_jobs_from_systems","text":"Removes all systems that are done according to the job checker from the project. Parameters: Name Type Description Default path_to_job_checks str The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. 'workdir/job_checks.txt' Source code in mixturemm/mixturemm.py 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 def remove_done_jobs_from_systems ( self , path_to_job_checks = 'workdir/job_checks.txt' ) -> None : \"\"\"Removes all systems that are done according to the job checker from the project. Args: path_to_job_checks (str, optional): The path to the job checker output file. Defaults to 'workdir/job_checks.txt'. \"\"\" with open ( f ' { path_to_job_checks } ' , 'r' , newline = ' \\n ' ) as file : not_done_job_list_ = [ line . rstrip () for line in file if 'not yet adjusted' in line ] not_done_job_list = [ item [: - 17 ] for item in not_done_job_list_ ] filtered_systems = [] for system in self . simulationsystems : for string in not_done_job_list : if system . name in string : filtered_systems . append ( system ) self . simulationsystems = filtered_systems","title":"remove_done_jobs_from_systems()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.simulate","text":"Runs the NVT equilibration and the NVE production. Source code in mixturemm/mixturemm.py 260 261 262 263 264 265 266 def simulate ( self ) -> None : \"\"\"Runs the NVT equilibration and the NVE production. \"\"\" for replica in self . replicas : replica . nvt_equilibration () replica . nve_production ()","title":"simulate()"},{"location":"mixturemm/#mixturemm.mixturemm.Project.transfer_project","text":"Transfers a project between two workspaces. Parameters: Name Type Description Default hpc_folder_old str The path to the old project folder on the hpc. Defaults to 'workspace_old/project_name'. 'workspace_old/project_name' hpc_folder_new str The path to the new project folder on the hpc. Defaults to 'workspace_new/project_name'. 'workspace_new/project_name' Source code in mixturemm/mixturemm.py 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 def transfer_project ( self , hpc_folder_old = 'workspace_old/project_name' , hpc_folder_new = 'workspace_new/project_name' ) -> None : \"\"\"Transfers a project between two workspaces. Args: hpc_folder_old (str, optional): The path to the old project folder on the hpc. Defaults to 'workspace_old/project_name'. hpc_folder_new (str, optional): The path to the new project folder on the hpc. Defaults to 'workspace_new/project_name'. \"\"\" system_file_list_old_ = [] system_file_list_new_ = [] for system in self . simulationsystems : system_file_list_old_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder_old } / { system . name } ' , system . folder )) system_file_list_new_ . append ( re . sub ( fr '^.*?/ { system . name } ' , f ' { hpc_folder_new } / { system . name } ' , system . folder )) system_file_list_old = sorted ( system_file_list_old_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) system_file_list_new = sorted ( system_file_list_new_ , key = lambda x : ( float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 1 ] . split ( '-' )[ 4 ]))) with open ( f ' { self . submitdir } /transfer_project.py' , 'w' , newline = ' \\n ' ) as file : file . write ( 'import shutil \\n ' ) for file_str_old , file_str_new in zip ( system_file_list_old , system_file_list_new ): file . write ( f '''shutil.copytree(r\" { file_str_old } /npt_equilibration\", r\" { file_str_new } /npt_equilibration\") ''' ) replica_file_list_old_ = [] replica_file_list_new_ = [] for replica in self . replicas : replica_file_list_old_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder_old } / { replica . name } ' , replica . folder )) replica_file_list_new_ . append ( re . sub ( fr '^.*?/ { replica . name } ' , f ' { hpc_folder_new } / { replica . name } ' , replica . folder )) replica_file_list_old = sorted ( replica_file_list_old_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) replica_file_list_new = sorted ( replica_file_list_new_ , key = lambda x : ( float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 0 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 2 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 3 ]), float ( x . split ( '/' )[ - 2 ] . split ( '-' )[ 4 ]), float ( x . split ( '/' )[ - 1 ] . split ( '_' )[ 1 ]))) with open ( f ' { self . submitdir } /transfer_project.py' , 'a' , newline = ' \\n ' ) as file : for file_str_old , file_str_new in zip ( replica_file_list_old , replica_file_list_new ): file . write ( f '''shutil.copytree(r\" { file_str_old } \", r\" { file_str_new } \") ''' ) with open ( f ' { self . submitdir } /transfer_project.py' , 'a' , newline = ' \\n ' ) as file : file . write ( f '''shutil.copytree(r\" { hpc_folder_old } /boxes\", r\" { hpc_folder_new } /boxes\") shutil.copytree(r\" { hpc_folder_old } /forcefield\", r\" { hpc_folder_new } /forcefield\") shutil.copytree(r\" { hpc_folder_old } /hpc_submission\", r\" { hpc_folder_new } /hpc_submission\") shutil.copytree(r\" { hpc_folder_old } /molecules\", r\" { hpc_folder_new } /molecules\") shutil.copytree(r\" { hpc_folder_old } /results\", r\" { hpc_folder_new } /results\") ''' )","title":"transfer_project()"},{"location":"scientific/","text":"Scientific background \u00b6 Box packing \u00b6 The boxes to be simulated are packed with the python package packmol . This package needs as starting point the PDB files of all occurring molecules and their desired number as well as the initial side length of the box in which the molecules should be packed. For each individual box there is an input file with this information, which is automatically generated during the workflow based on the existing information of the project object. With the given total number of molecules, their proportion in the mixture and the water mole fractions, the respective molecule number is calculated, assigned to the path to the PDB file of the molecule and the box is packed with the resulting input file. The resulting PDB file of the box does not contain any CONECT entries, however OpenMM needs this topology information to assign the molecules their respective force field. Therefore, in a further step, the CONECT entries of the box are created based on the indices of the CONECT entries of the individual molecules and added to the PDB file. CONECT entry indices generation CONECT entries of methanol CONECT entries of three molecules methanol 1 2 3 4 CONECT 1 2 3 CONECT 2 1 CONECT 2 CONECT 3 1 1 2 3 4 5 6 7 8 9 10 11 12 CONECT 1 2 3 CONECT 2 1 CONECT 2 CONECT 3 1 CONECT 4 5 6 all indices +3 CONECT 5 4 CONECT 5 CONECT 6 4 CONECT 7 8 9 all indices +6 CONECT 8 7 CONECT 8 CONECT 9 7 Methanol/Water with 2000, 6000 and 15000 molecules and \\(\\chi_{water}\\) of 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 and 1 \\(\\chi_{water}\\) 2000 molecules 6000 molecules 15000 molecules 0 2000 methanol, 0 water 6000 methanol, 0 water 15000 methanol, 0 water 0.1 1800 methanol, 200 water 5400 methanol, 600 water 13500 methanol, 1500 water 0.2 1600 methanol, 400 water 4800 methanol, 1200 water 12000 methanol, 3000 water 0.3 1400 methanol, 600 water 4200 methanol, 1800 water 10500 methanol, 4500 water 0.4 1200 methanol, 800 water 3600 methanol, 2400 water 9000 methanol, 6000 water 0.5 1000 methanol, 1000 water 3000 methanol, 3000 water 7500 methanol, 7500 water 0.6 800 methanol, 1200 water 2400 methanol, 3600 water 6000 methanol, 9000 water 0.7 600 methanol, 1400 water 1800 methanol, 4200 water 4500 methanol, 10500 water 0.8 400 methanol, 1600 water 1200 methanol, 4800 water 3000 methanol, 12000 water 0.9 200 methanol, 1800 water 600 methanol, 5400 water 1500 methanol, 13500 water 1 0 methanol, 2000 water 0 methanol, 6000 water 0 methanol, 15000 water Simulation \u00b6 All simulations are performed with the OpenMM simulation engine . To simulate viscosity and self-diffusion coefficients of molecular mixtures the NVE ensemble is recommended, this is because in both NVT and NpT ensemble temperature or pressure and temperature are controlled and this affects the transport properties of the system. Therefore, the production of the trajectories takes place in the NVE ensemble. This is preceded by an equilibration phase in the NpT and NVT ensemble to adjust the temperature and pressure and to simulate the correct density of the molecular mixtures. The NpT ensemble starts from the packed boxes and begins with a slow warming phase, temperature is raised by 0.1 K every picosecond. This allows the Monte Carlo barostat , which regulates the pressure, to start with the temperature already equilibrated; if this is not the case, it can lead to artifacts in the resulting density. From the last half of the NpT equilibration, in which the density is equilibrated, the average box size for the starting point of the NVT equilibration is determined. The box size is rescaled to this and velocities are assigned to the molecules according to the temperature. Each replica receives individual velocities from the Boltzmann distribution. In OpenMM the temperature control is technically coupled to the integrator, in both equilibrium phases, Npt and NVT, the temperature is controlled by the LangevinMiddleIntegrator , which is equivalent to a Langevin thermostat with leapfrog integrator. For the NVE production phase, energy conservation in the system is crucial. This is particularly dependent on integration precision. Important here are a small particle mesh ewald and constraint error tolerance while maintaining high simulation speed, since the lowering of the former also results in a lowering of the latter. The cutoff for Lennard-Jones and electostatic interactions also has a non-negligible influence; here, too, a balance must be found between precision and simulation speed. However, the contribution of all particles beyond the cutoff is included with a correction factor. In addition, the energy at the cutoff can smoothly transition to 0 with a switching function. The integration itself is handled by a simple Verlet integrator . During all ensembles the energy of the system is stored, as well as the temperature, density and volume. During the NVE production, trajectories, once with unwrapped coordinates and once with wrapped coordinates, are also stored. Analysis \u00b6 The density \\(\\rho\\) can be read out continously during the simulation via the built-in StateDataReporter of OpenMM. It is calculated by dividing the total mass of the simulated box by its volume. To determine the density of a system, the second half of the simulated NpT ensemble is taken, in which the density is equilibrated. All density outputs of this period are averaged. These are then in turn averaged over all box sizes to give the final density value. MDAnalysis , a python package for trajectory analysis of simulations, is used to compute the mean squared displacement (MSD) of the individual molecule types of the mixture. The Eintein formula is used for this purpose: \\[ MSD(r_d) = \\left \\langle \\frac{1}{N} \\sum_{i=1}^{N} | r_d - r_d ( t_0) |^2 \\right \\rangle_{t_0} \\] \\(N\\) is the number of equivalent particles the MSD is calculated over, \\(r\\) are their coordinates and \\(d\\) the dimensionality. Trajectories with unwrapped coordinates are used for the MSD calculation because it is reliant on the distance travelled by the molecules, which is distorted by rewrapping. The self-diffusion coefficient of a molecule type is then obtained by fitting the linear part of the MSD. The recommended fitting range is between 20% and 80% of the simulation time due to nonlinearity at the beginning and poor averaging at the end. Self-diffusion coefficients are then calculated by dividing the resulting slope by six because of the three-dimensionality of the MSD. The self-diffusion coefficients are averaged over all replicates and finite-size corrected. To achieve this, the self-diffusion coefficients of at least three different sized simulation boxes are fitted linearly over their inverse box side lengths, the intersection with the y-axis is the corrected self-diffusion coefficient at infinite box size. Finite-size effects When simulating small, finite systems, systemic finite-size effects must be taken into account. This is usually achieved by extrapolating several systems of different sizes. Viscosity \\(\\eta\\) is determined using the relationship between self-diffusion coefficient and finite-size corrected self-diffusion coefficient described by Yeh and Hummer. \\[ D = \\left (-\\frac{k_BT\\xi}{6\\pi\\eta}\\right)\\left(\\frac{1}{L}\\right)+D_\\infty \\] \\(D\\) is the self-diffusion coefficient at box size \\(L\\) , \\(k_{B}\\) is the Boltzmann constant, \\(T\\) is the temperature in K, \\(\\eta\\) is the viscosity, \\(\\xi\\) is a dimensionless constant with a value of 2.837297 for cubic boxes and \\(D_{\\infty}\\) is the self-diffusion coefficient at infinite box size. From the linear fit over the inverse box size used to determine the finite-size corrected self-diffusion coefficient, the viscosity can be determined by the slope \\(a\\) . To obtain reliable viscosity values, a simulation length in which linear diffusion takes place is necessary, and good averaging by many replicates is essential; note that the smaller the box, the more replicates are needed, since the number of molecules that can be averaged over is smaller. \\[ \\eta = \\left(-\\frac{k_BT\\xi}{a6\\pi} \\right) \\] The hydrogen bonds analysis is done by MDAnalysis as well. All atoms that participate in hydrogen bond formation must be given in MDAnalysis selection syntax. The hydrogen bonds are then detected by two geometric criteria, the maximum donor-acceptor distance and the minimum angle between donor, hydrogen and acceptor. The maximum donor-acceptor distance is set to 3.5 \u00c5 and the minimal angle between donor, hydrogen and acceptor to 150 \u00b0. Hydrogen bonds types are counted and averaged over simulation time. Additionally, they are averaged per molecule type. Here, wrapped coordinates are analyzed.","title":"Scientific background"},{"location":"scientific/#scientific-background","text":"","title":"Scientific background"},{"location":"scientific/#box-packing","text":"The boxes to be simulated are packed with the python package packmol . This package needs as starting point the PDB files of all occurring molecules and their desired number as well as the initial side length of the box in which the molecules should be packed. For each individual box there is an input file with this information, which is automatically generated during the workflow based on the existing information of the project object. With the given total number of molecules, their proportion in the mixture and the water mole fractions, the respective molecule number is calculated, assigned to the path to the PDB file of the molecule and the box is packed with the resulting input file. The resulting PDB file of the box does not contain any CONECT entries, however OpenMM needs this topology information to assign the molecules their respective force field. Therefore, in a further step, the CONECT entries of the box are created based on the indices of the CONECT entries of the individual molecules and added to the PDB file. CONECT entry indices generation CONECT entries of methanol CONECT entries of three molecules methanol 1 2 3 4 CONECT 1 2 3 CONECT 2 1 CONECT 2 CONECT 3 1 1 2 3 4 5 6 7 8 9 10 11 12 CONECT 1 2 3 CONECT 2 1 CONECT 2 CONECT 3 1 CONECT 4 5 6 all indices +3 CONECT 5 4 CONECT 5 CONECT 6 4 CONECT 7 8 9 all indices +6 CONECT 8 7 CONECT 8 CONECT 9 7 Methanol/Water with 2000, 6000 and 15000 molecules and \\(\\chi_{water}\\) of 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9 and 1 \\(\\chi_{water}\\) 2000 molecules 6000 molecules 15000 molecules 0 2000 methanol, 0 water 6000 methanol, 0 water 15000 methanol, 0 water 0.1 1800 methanol, 200 water 5400 methanol, 600 water 13500 methanol, 1500 water 0.2 1600 methanol, 400 water 4800 methanol, 1200 water 12000 methanol, 3000 water 0.3 1400 methanol, 600 water 4200 methanol, 1800 water 10500 methanol, 4500 water 0.4 1200 methanol, 800 water 3600 methanol, 2400 water 9000 methanol, 6000 water 0.5 1000 methanol, 1000 water 3000 methanol, 3000 water 7500 methanol, 7500 water 0.6 800 methanol, 1200 water 2400 methanol, 3600 water 6000 methanol, 9000 water 0.7 600 methanol, 1400 water 1800 methanol, 4200 water 4500 methanol, 10500 water 0.8 400 methanol, 1600 water 1200 methanol, 4800 water 3000 methanol, 12000 water 0.9 200 methanol, 1800 water 600 methanol, 5400 water 1500 methanol, 13500 water 1 0 methanol, 2000 water 0 methanol, 6000 water 0 methanol, 15000 water","title":"Box packing"},{"location":"scientific/#simulation","text":"All simulations are performed with the OpenMM simulation engine . To simulate viscosity and self-diffusion coefficients of molecular mixtures the NVE ensemble is recommended, this is because in both NVT and NpT ensemble temperature or pressure and temperature are controlled and this affects the transport properties of the system. Therefore, the production of the trajectories takes place in the NVE ensemble. This is preceded by an equilibration phase in the NpT and NVT ensemble to adjust the temperature and pressure and to simulate the correct density of the molecular mixtures. The NpT ensemble starts from the packed boxes and begins with a slow warming phase, temperature is raised by 0.1 K every picosecond. This allows the Monte Carlo barostat , which regulates the pressure, to start with the temperature already equilibrated; if this is not the case, it can lead to artifacts in the resulting density. From the last half of the NpT equilibration, in which the density is equilibrated, the average box size for the starting point of the NVT equilibration is determined. The box size is rescaled to this and velocities are assigned to the molecules according to the temperature. Each replica receives individual velocities from the Boltzmann distribution. In OpenMM the temperature control is technically coupled to the integrator, in both equilibrium phases, Npt and NVT, the temperature is controlled by the LangevinMiddleIntegrator , which is equivalent to a Langevin thermostat with leapfrog integrator. For the NVE production phase, energy conservation in the system is crucial. This is particularly dependent on integration precision. Important here are a small particle mesh ewald and constraint error tolerance while maintaining high simulation speed, since the lowering of the former also results in a lowering of the latter. The cutoff for Lennard-Jones and electostatic interactions also has a non-negligible influence; here, too, a balance must be found between precision and simulation speed. However, the contribution of all particles beyond the cutoff is included with a correction factor. In addition, the energy at the cutoff can smoothly transition to 0 with a switching function. The integration itself is handled by a simple Verlet integrator . During all ensembles the energy of the system is stored, as well as the temperature, density and volume. During the NVE production, trajectories, once with unwrapped coordinates and once with wrapped coordinates, are also stored.","title":"Simulation"},{"location":"scientific/#analysis","text":"The density \\(\\rho\\) can be read out continously during the simulation via the built-in StateDataReporter of OpenMM. It is calculated by dividing the total mass of the simulated box by its volume. To determine the density of a system, the second half of the simulated NpT ensemble is taken, in which the density is equilibrated. All density outputs of this period are averaged. These are then in turn averaged over all box sizes to give the final density value. MDAnalysis , a python package for trajectory analysis of simulations, is used to compute the mean squared displacement (MSD) of the individual molecule types of the mixture. The Eintein formula is used for this purpose: \\[ MSD(r_d) = \\left \\langle \\frac{1}{N} \\sum_{i=1}^{N} | r_d - r_d ( t_0) |^2 \\right \\rangle_{t_0} \\] \\(N\\) is the number of equivalent particles the MSD is calculated over, \\(r\\) are their coordinates and \\(d\\) the dimensionality. Trajectories with unwrapped coordinates are used for the MSD calculation because it is reliant on the distance travelled by the molecules, which is distorted by rewrapping. The self-diffusion coefficient of a molecule type is then obtained by fitting the linear part of the MSD. The recommended fitting range is between 20% and 80% of the simulation time due to nonlinearity at the beginning and poor averaging at the end. Self-diffusion coefficients are then calculated by dividing the resulting slope by six because of the three-dimensionality of the MSD. The self-diffusion coefficients are averaged over all replicates and finite-size corrected. To achieve this, the self-diffusion coefficients of at least three different sized simulation boxes are fitted linearly over their inverse box side lengths, the intersection with the y-axis is the corrected self-diffusion coefficient at infinite box size. Finite-size effects When simulating small, finite systems, systemic finite-size effects must be taken into account. This is usually achieved by extrapolating several systems of different sizes. Viscosity \\(\\eta\\) is determined using the relationship between self-diffusion coefficient and finite-size corrected self-diffusion coefficient described by Yeh and Hummer. \\[ D = \\left (-\\frac{k_BT\\xi}{6\\pi\\eta}\\right)\\left(\\frac{1}{L}\\right)+D_\\infty \\] \\(D\\) is the self-diffusion coefficient at box size \\(L\\) , \\(k_{B}\\) is the Boltzmann constant, \\(T\\) is the temperature in K, \\(\\eta\\) is the viscosity, \\(\\xi\\) is a dimensionless constant with a value of 2.837297 for cubic boxes and \\(D_{\\infty}\\) is the self-diffusion coefficient at infinite box size. From the linear fit over the inverse box size used to determine the finite-size corrected self-diffusion coefficient, the viscosity can be determined by the slope \\(a\\) . To obtain reliable viscosity values, a simulation length in which linear diffusion takes place is necessary, and good averaging by many replicates is essential; note that the smaller the box, the more replicates are needed, since the number of molecules that can be averaged over is smaller. \\[ \\eta = \\left(-\\frac{k_BT\\xi}{a6\\pi} \\right) \\] The hydrogen bonds analysis is done by MDAnalysis as well. All atoms that participate in hydrogen bond formation must be given in MDAnalysis selection syntax. The hydrogen bonds are then detected by two geometric criteria, the maximum donor-acceptor distance and the minimum angle between donor, hydrogen and acceptor. The maximum donor-acceptor distance is set to 3.5 \u00c5 and the minimal angle between donor, hydrogen and acceptor to 150 \u00b0. Hydrogen bonds types are counted and averaged over simulation time. Additionally, they are averaged per molecule type. Here, wrapped coordinates are analyzed.","title":"Analysis"},{"location":"tools/","text":"tools \u00b6 Module with useful functions for preparing a project. MIT License Copyright (c) 2021, Benjamin Schmitz Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. estimate_init_box_side_length ( total_number_molecules , molecule_molar_mass , density_kg_m3 ) \u00b6 Estimates the initial box size for a molecule type. Parameters: Name Type Description Default total_number_molecules int Number of molecules in the planned box. required molecule_molar_mass float Molecular mass of the molecule type in mol per gram. required density_kg_m3 int Density of the molecule type in kilogram per cubic meter. required Returns: Name Type Description float Initial box size for a molecule type. Source code in mixturemm/tools.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def estimate_init_box_side_length ( total_number_molecules , molecule_molar_mass , density_kg_m3 ): \"\"\"Estimates the initial box size for a molecule type. Args: total_number_molecules (int): Number of molecules in the planned box. molecule_molar_mass (float): Molecular mass of the molecule type in mol per gram. density_kg_m3 (int): Density of the molecule type in kilogram per cubic meter. Returns: float: Initial box size for a molecule type. \"\"\" AVOGADRO_NUMBER = 6.022 * ( 10 ** 23 ) mass_kg = ( molecule_molar_mass / AVOGADRO_NUMBER ) * total_number_molecules * ( 10 ** ( - 3 )) volume_m3 = mass_kg / density_kg_m3 side_lenght_m = volume_m3 ** ( 1 / 3 ) side_lenght_angstrom = side_lenght_m * ( 10 ** 10 ) return side_lenght_angstrom max_permitted_number_of_molecules ( molecule_atom_numbers = [], molecule_molar_ratios = []) \u00b6 Calculates the maximum number of molecules that can fit inside a PDB file with the given parameters. Parameters: Name Type Description Default molecule_atom_numbers list The number of atoms that the molecule consists of. Defaults to []. [] molecule_molar_ratios list The proportion of the respective molecule type in the mixture. Defaults to []. [] Returns: Name Type Description int The maximum number of molecules that can fit inside a PDB file with the given parameters. Source code in mixturemm/tools.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def max_permitted_number_of_molecules ( molecule_atom_numbers = [], molecule_molar_ratios = []): \"\"\"Calculates the maximum number of molecules that can fit inside a PDB file with the given parameters. Args: molecule_atom_numbers (list, optional): The number of atoms that the molecule consists of. Defaults to []. molecule_molar_ratios (list, optional): The proportion of the respective molecule type in the mixture. Defaults to []. Returns: int: The maximum number of molecules that can fit inside a PDB file with the given parameters. \"\"\" PDB_MAX_ATOMS = 99999 smallest_package_number_atoms = sum ([ n * r for n , r in zip ( molecule_atom_numbers , molecule_molar_ratios )]) max_smallest_package = PDB_MAX_ATOMS / smallest_package_number_atoms max_permitted_number = max_smallest_package * sum ( molecule_molar_ratios ) return int ( max_permitted_number )","title":"tools module"},{"location":"tools/#tools","text":"Module with useful functions for preparing a project. MIT License Copyright (c) 2021, Benjamin Schmitz Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"tools"},{"location":"tools/#mixturemm.tools.estimate_init_box_side_length","text":"Estimates the initial box size for a molecule type. Parameters: Name Type Description Default total_number_molecules int Number of molecules in the planned box. required molecule_molar_mass float Molecular mass of the molecule type in mol per gram. required density_kg_m3 int Density of the molecule type in kilogram per cubic meter. required Returns: Name Type Description float Initial box size for a molecule type. Source code in mixturemm/tools.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def estimate_init_box_side_length ( total_number_molecules , molecule_molar_mass , density_kg_m3 ): \"\"\"Estimates the initial box size for a molecule type. Args: total_number_molecules (int): Number of molecules in the planned box. molecule_molar_mass (float): Molecular mass of the molecule type in mol per gram. density_kg_m3 (int): Density of the molecule type in kilogram per cubic meter. Returns: float: Initial box size for a molecule type. \"\"\" AVOGADRO_NUMBER = 6.022 * ( 10 ** 23 ) mass_kg = ( molecule_molar_mass / AVOGADRO_NUMBER ) * total_number_molecules * ( 10 ** ( - 3 )) volume_m3 = mass_kg / density_kg_m3 side_lenght_m = volume_m3 ** ( 1 / 3 ) side_lenght_angstrom = side_lenght_m * ( 10 ** 10 ) return side_lenght_angstrom","title":"estimate_init_box_side_length()"},{"location":"tools/#mixturemm.tools.max_permitted_number_of_molecules","text":"Calculates the maximum number of molecules that can fit inside a PDB file with the given parameters. Parameters: Name Type Description Default molecule_atom_numbers list The number of atoms that the molecule consists of. Defaults to []. [] molecule_molar_ratios list The proportion of the respective molecule type in the mixture. Defaults to []. [] Returns: Name Type Description int The maximum number of molecules that can fit inside a PDB file with the given parameters. Source code in mixturemm/tools.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def max_permitted_number_of_molecules ( molecule_atom_numbers = [], molecule_molar_ratios = []): \"\"\"Calculates the maximum number of molecules that can fit inside a PDB file with the given parameters. Args: molecule_atom_numbers (list, optional): The number of atoms that the molecule consists of. Defaults to []. molecule_molar_ratios (list, optional): The proportion of the respective molecule type in the mixture. Defaults to []. Returns: int: The maximum number of molecules that can fit inside a PDB file with the given parameters. \"\"\" PDB_MAX_ATOMS = 99999 smallest_package_number_atoms = sum ([ n * r for n , r in zip ( molecule_atom_numbers , molecule_molar_ratios )]) max_smallest_package = PDB_MAX_ATOMS / smallest_package_number_atoms max_permitted_number = max_smallest_package * sum ( molecule_molar_ratios ) return int ( max_permitted_number )","title":"max_permitted_number_of_molecules()"},{"location":"usage/","text":"Usage \u00b6 To use mixturemm install the package and import it. All required classes (Project, Molecule, Forcefield and Mixture) for simulation and analysis are added to the namespace. 1 import mixturemm Setup \u00b6 The first step to beginning a project is setting the path to the directory where the project folder should be stored. 1 workdir = 'home/molecule_mixture_project' A project is defined via four setting sections. First, OpenMM is assigned the hardware on which the simulations are to run; if the simulations are to be run on a high-performance computing center, this is overwritten with the hardware resources specified when generating the submissions. Second, the parameter space of box sizes, temperatures, pressures, and dilutions to be considered is set. After that, the settings for the individual ensembles that follow each other in the simulation are made. Finally, the settings for constraints and nonbonded interactions affecting all ensembles are given. example project initiation argument details extend a project 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 project = mixturemm . Project ( workdir , simulation_platform = 'CUDA' , simulation_properties = { 'DeviceIndex' : '0' , 'Precision' : 'double' }, total_number_molecules = [ 2000 , 6000 , 15000 ], init_box_side_length = [ 65 , 75 , 102 ], chi_water_s = [ 0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1 ], temperature_s = [ 298.15 , 308.15 , 318.15 ], npt_equilibration_pressure_s = [ 1 ], npt_equilibration_pressure_coupling_frequency = 500 , npt_equilibration_temperature_coupling_frequency = 0.1 , npt_equilibration_timestep_fs = 2 , npt_equilibration_duration_ns = 12 , reporting_frequency_state_npt_equilibration = 500 , nvt_equilibration_temperature_coupling_frequency = 0.1 , nvt_equilibration_timestep_fs = 2 , nvt_equilibration_duration_ns = 20 , reporting_frequency_state_nvt_equilibration = 4000 , nve_production_timestep_fs = 1 , nve_production_duration_ns = 50 , reporting_frequency_coordinates_unwrapped = 4000 , reporting_frequency_coordinates_wrapped = 8000 , reporting_frequency_state_nve_production = 8000 , replica_count = 40 , pme_error_tolerance = 0.000001 , constraint_tolerance = 0.0000001 , cutoff_distance_nm = 1.4 , cutoff_switch_distance_nm = 1.2 ) argument description workdir The path at which the project should be stored. simulation_platform The platform the simulation should run on. OpenMM ref. simulation_properties The platform properties for the simulation. OpenMM ref. total_number_molecules A list with the number of molecules that should be placed in the simulation box. init_box_side_length The initial box side lengths that should be used by packmol. Packmol ref. chi_water_s A list with all different molar fractions of water that should be simulated. temperature_s A list with all different temperatures in kelvin at which the boxes should be simulated. npt_equilibration_pressure_s A list with all pressures in bar at which the boxes should be simulated. npt_equilibration_pressure_coupling_frequency The pressure coupling frequency at which the Monte Carlo barostat should interact with the system and attempt a Monte Carlo move to adjust the volume during the NpT equilibration in simulation steps. OpenMM ref. npt_equilibration_temperature_coupling_frequency The collision frequency of the Langevin thermostat during the NpT equilibration in inverse picoseconds. OpenMM ref. npt_equilibration_timestep_fs The integration time step during the NpT equilibration in femtoseconds. npt_equilibration_duration_ns The duration of the NpT equilibration in nanoseconds. reporting_frequency_state_npt_equilibration The reporting frequency of the openMM StateDataReporter in simulation steps during the NpT equilibration. OpenMM ref. nvt_equilibration_temperature_coupling_frequency The collision frequency of the Langevin thermostat during the NVT equilibration in inverse picoseconds. OpenMM ref. nvt_equilibration_timestep_fs The integration time step during the NVT equilibration in femtoseconds. nvt_equilibration_duration_ns The duration of the NVT equilibration in nanoseconds. reporting_frequency_state_nvt_equilibration The reporting frequency of the openMM StateDataReporter in simulation steps during the NVT equilibration. OpenMM ref. nve_production_timestep_fs The integration time step during the NVE production in femtoseconds. nve_production_duration_ns The duration of the NVE production in nanoseconds. reporting_frequency_coordinates_unwrapped The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. OpenMM ref. reporting_frequency_coordinates_wrapped The reporting frequency of the trajectory with wrapped coordinates in simulation steps during the NVE production. OpenMM ref. reporting_frequency_state_nve_production The reporting frequency of the openMM StateDataReporter in simulation steps during the NVE production. OpenMM ref. replica_count The number of times the simulation of one system should be replicated. pme_error_tolerance Decides how large the grid for PME is together with the cutoff. OpenMM ref. constraint_tolerance The constraint tolerance specifies the distance tolerance within which constraints are maintained, as a fraction of the constrained distance. cutoff_distance_nm The cutoff distance for nonbonded interactions in nanometers. OpenMM ref. cutoff_switch_distance_nm Starting point of the switching function that makes the energy go smoothly to 0 at the cutoff distance in nanometers. OpenMM ref. A project can easily be extended by adding the new parameters to the existing parameter lists of total molecule number and box size, temperature, pressure and water mole > fraction or increasing the replica count. Subsequently, the molecules contained in the mixture and their force fields are defined and the associated files are added to the project. On the one hand definition and the PDB files of the molecules example methanol/water mixture argument details 1 2 3 4 Water = mixturemm . Molecule ( workdir , 'Water' , 4 , 'home/tip4p.pdb' , 'HOH' , 'O' , '1S/H2O/h1H2' , 18.015 , use_as_water = True ) Methanol = mixturemm . Molecule ( workdir , 'Methanol' , 3 , 'home/methanol.pdb' , 'Me' , 'CO' , '1S/CH4O/c1-2/h2H,1H3' , 32.04 ) project . add_molecule ( Water ) project . add_molecule ( Methanol ) argument description workdir The path at which the project is stored. name Name of the molecule. number_of_atoms The number of atoms that the molecule consists of. path_to_pdb The path to the molecule PDB file. abbreviation The abbreviation of the molecule that is used inside the PDB file. smiles The SMILES code of the molecule. inchi The InChI code of the molecule. molar_mass The molar mass of the molecule. use_as_water Decides whether the molecule is used as water or not. If used as water, the water molar fraction is applied to it while packing boxes. ... on the other hand the definitions of the force fields and the XML files. United-atoms force fields When simulating force fields with united atoms, as in the example here, note that OpenMM recognizes all basic atom types but not united-atoms. These must be added as described as \"elements\". example methanol/water mixture argument details 1 2 3 4 Water_FF = mixturemm . Forcefield ( workdir , 'home/tip4p-fb.xml' , 'tip4p-fb' , built_in = False ) Methanol_FF = mixturemm . Forcefield ( workdir , 'home/trappe_methanol.xml' , 'trappe_methanol' , built_in = False , elements = { '3' : 15.0347 }) project . add_forcefield ( Water_FF ) project . add_forcefield ( Methanol_FF ) argument description workdir The path at which the project is stored. path_to_XML The path to the force field XML file. ff_name The name under which the force field should be stored. built_in Decides whether the fore field is part of openMM or from an external source. If true, declares that a built in forcefield of openmm will be used. elements OpenMM uses Elements to match molecules to the force field. If atomtypes in the force field are unknown to OpenMM, they are registered by giving their name and mass in the form {'name' : mass}. OpenMM ref. Then, the molecule names and their corresponding mole fraction in the mixture are given. example methanol/water mixture argument details 1 2 WaMeMixture = mixturemm . Mixture ({ 'Methanol' : 1 }) project . add_mixture ( WaMeMixture ) argument description mixture_dict Dictionary with molecule names and their corresponding mole fraction in the mixture. All project input information as well as added molecules and forcefields will be stored in a short JSON project description. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 { \"workflow_info\" : { \"general\" : { \"package_name\" : \"mixturemm\" , \"simulation_engine\" : \"OpenMM\" , \"analysis_package\" : \"MDAnalysis\" }, \"simulation\" : { \"ensemble_order\" : \"---(slow heating)---> |NpT| ---(rescale boxes and assign velocities)---> |NVT| ------> |NVE|\" , \"pressure_and_temperature_control\" : { \"NpT\" : \"Langevin thermostat, Monte Carlo barostat\" , \"NVT\" : \"Langevin thermostat\" , \"NVE\" : \"no pressure and temperature control\" }, \"constraints\" : \"hydrogen bonds\" , \"nonbonded forces algorithm\" : \"particle mesh ewald\" } }, \"project\" : { \"simulation_parameters\" : { \"total_number_of_molecules\" : [ 2000 , 6000 , 15000 ], \"initial_box_side_lengths\" : [ 65 , 75 , 102 ], \"water_mole_fractions\" : [ 0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1 ], \"temperature_s_in_kelvin\" : [ 298.15 , 308.15 , 318.15 ], \"pressure_s_in_bar\" : [ 1 ], \"number_of_replicas\" : 40 , \"replica_starting_number\" : 1 , \"overcharged_boxes\" : { \"[2000] molecules\" : \"with 60 replicas\" } }, \"hardware_settings\" : { \"platform\" : \"CUDA\" , \"properties\" : { \"DeviceIndex\" : \"0\" , \"Precision\" : \"double\" } }, \"simulation_settings\" : { \"pme_error_tolerance\" : 1e-06 , \"constraint_tolerance\" : 1e-07 , \"cutoff_distance_in_nm\" : 1.4 , \"switching_function_starting_distance_in_nm\" : 1.2 }, \"npt_equilibration\" : { \"pressure_coupling_frequency\" : 500 , \"temperature_coupling_frequency\" : 0.1 , \"timestep_in_fs\" : 2 , \"duration_in_ns\" : 12 , \"state_data_reporting_frequency\" : 500 }, \"nvt_equilibration\" : { \"temperature_coupling_frequency\" : 0.1 , \"timestep_in_fs\" : 2 , \"duration_in_ns\" : 20 , \"state_data_reporting_frequency\" : 4000 }, \"nve_production\" : { \"timestep_in_fs\" : 1 , \"duration_in_ns\" : 50 , \"state_data_reporting_frequency\" : 8000 , \"unwrapped_trajectory_reporting_frequency\" : 4000 , \"wrapped_trajectory_reporting_frequency\" : 8000 } }, \"molecules\" : { \"Water\" : { \"number_of_atoms\" : 4 , \"abbreviation\" : \"HOH\" , \"molar_ratio\" : 1 , \"smiles_code\" : \"O\" , \"inchi_key\" : \"1S/H2O/h1H2\" , \"molar_mass\" : 18.015 , \"used_as_water\" : true }, \"Methanol\" : { \"number_of_atoms\" : 3 , \"abbreviation\" : \"Me\" , \"molar_ratio\" : 1 , \"smiles_code\" : \"CO\" , \"inchi_key\" : \"1S/CH4O/c1-2/h2H,1H3\" , \"molar_mass\" : 32.04 , \"used_as_water\" : false } }, \"force fields\" : { \"tip4p-fb\" : { \"built_in\" : false , \"added_elements\" : null }, \"trappe_methanol\" : { \"built_in\" : false , \"added_elements\" : { \"3\" : 15.0347 } } } } In the last preparatory step, the simulated systems and their replicas are generated by combining the parameters and the corresponding folder structure is created. Then, the simulation boxes are packed with the PDB files of the molecules corresponding to their proportion in the total number of molecules. In addition, a further number of replicas can be added at this point for individual box sizes. system/replica preparation and box packing without ... and with adding replicas for certain box sizes 1 2 3 project . create_simulationboxes () project . create_systems () project . create_replicas ( start = 1 ) 1 2 3 4 5 project . create_simulationboxes () project . create_systems () project . create_replicas ( start = 1 ) project . overcharge_replicas ( total_number_molecules = [ 2000 ], overcharge_amount = 50 , start = 1 ) project . overcharge_replicas ( total_number_molecules = [ 6000 ], overcharge_amount = 20 , start = 1 ) Simulation \u00b6 There are two ways to run the simulations defined in the project. They can be run locally on the computer where the project was initiated. However, this is not recommended for large-scale projects due to the low computing power. This mode is rather used for test runs and troubleshooting of the system setup. First the NpT equilibration of all systems takes place, then the NVT equilibration and following NVE production of the trajectories of the replicas. 1 2 project . adjust_to_correct_density () project . simulate () The recommended approach for large-scale projects is the submission of the simulations to a high-performance computing center. There, the simulations are transferred via a queuing system to nodes where they run. With the resources available there, it is possible to run many simulations in parallel. To run the simulations on a high performance computing center the executable scripts from the HPC folder of the mixturemm package are needed and the whole project folder has to be transferred to a workspace on the high performance computing center. Submission scripts are required to submit simulations to the queue. These are generated based on the given project and the specification of the hardware resources. To ensure the optimal use of the available resources on the nodes, the simulations can be parallelized according to the available GPUs or CPU cores. Dependencies Be aware that all dependencies have to be available on the high-performance computing center as well. It is therefore recommended to install it into a anaconda environment with OpenMM , packmol , MDAnalysis , mdtraj , seaborn , more-itertools and tidynamics . This environment should be the one you activate on the nodes where the simulations and analyses are submitted to. Additionally, you have to either upload or generate your project folder with all the wanted job scripts to/on your high-performance computing center. Updating the folder on the high-performance computing center when running additional replicas When new replicas are added by increasing the replica number of the project, the folder structure on the high-performance computing center can be extended with 1 project . hpc_extend_replica_folders ( hpc_folder = \"/hpc/workspace/molecule_mixture_project\" ) first submission subsequent submissions argument details NpT equilibration NVT equilibration and NVE production 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 project . create_hpc_submission_adjust_to_correct_density ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_simulation' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 500000 ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 project . create_hpc_submission_simulate ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_simulation' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = 50 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 500000 ) NpT equilibration NVT equilibration and NVE production 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 project . remove_done_jobs_from_replicas ( self , path_to_job_checks = 'workdir/job_checks.txt' ) project . create_hpc_submission_adjust_to_correct_density ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_simulation' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 500000 ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 remove_done_jobs_from_replicas ( self , path_to_job_checks = 'workdir/job_checks.txt' ) project . create_hpc_submission_simulate ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_simulation' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = 50 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 500000 ) argument description hpc_workspace The path to the hpc workspace. hpc_folder The path to the project folder on the hpc. hpc_scripts_folder The path to the python scripts folder. environment_name The name of the anaconda environment containing the dependencies. scheduler The queue scheduler. partition The partition the job should be submitted to. number_of_threads The number of requested threads. number_of_gpus The number of GPUs requested on a node. chunk_size Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. max_runtime_hh_mm_ss Maximum runtime for a job. which_hpc The HPC the script should be run on, currently supported are 'bwUniCluster2.0' and 'HoreKa'. chain_submission_number The number of job submissions that should be submitted as a sequential chain job. dependency_type Dependency keyword of the SLURM workload manager for chain jobs. checkpoint_frequency The frequency at which checkpoints are saved to restart from once a chain job continues. After transferring the folder with the job submission scripts to the high-performance computing center, they are submitted from via the terminal. NpT equilibration NVT equilibration and NVE production 1 bash submit_adjust_to_correct_density.sh 1 bash submit_simulate.sh However, nodes can only be occupied for a limited period of time. This leads to the fact that simulations have to be interrupted and resumed. This is implemented as follows with simulation checkpoints: Since the queues only allow a limited number of job submissions at once, the number of generated job submission scripts is limited to this. Thus, the project is submitted in multiple submission cycles to work through the required simulations. All in all, the simulation takes place on a high-performance data center according to the following scheme: After each simulation cycle on the high-performance data center, the status of the simulations is checked with the job checker. 1 2 3 4 5 6 7 project . hpc_job_checker ( hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , hpc_workspace = \"/hpc/workspace/\" , environment_name = 'conda_env_simulation' , output = 'verbose' , energy_shift_tolerance_percent = 1 ) In addition to the percentage progress of each replica, the average temperature and the percentage deviation of the total energy are determined. At the end of the output txt file, it is summarized how many of the replicas are finished and how many still need to run. In addition, if the given limit for the deviation of the total energy of one or more replicas is exceeded, a warning is added with the name of the replica. With the information about replicas already completed and replicas still to be run, the job submissions of the next simulation cycle are created. The job checker is launched with: 1 batch job_checker.sh Analysis \u00b6 Just as for the simulations, job submissions are generated for the analyses, which are then transferred to the high-performance computing center. The density analysis is then submitted in one step, it refers only to the NpT equilibration phase. example methanol/water mixture argument details 1 2 3 4 5 6 7 8 9 10 project . create_hpc_submission_analyze_density ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , max_runtime_hh_mm_ss = '00:10:00' , conda_module = False ) argument description hpc_workspace The path to the hpc workspace. hpc_folder The path to the project folder on the hpc. hpc_scripts_folder The path to the python scripts folder. environment_name The name of the anaconda environment containing the dependencies. scheduler The queue scheduler. partition The partition the job should be submitted to. number_of_threads The number of requested threads. max_runtime_hh_mm_ss Maximum runtime for a job. which_hpc The HPC the script should be run on, currently supported are 'bwUniCluster2.0' and 'HoreKa'. Launch it with: 1 batch submit_density_analysis.sh The two much more computationally intensive analyses on self-diffusion coefficients, viscosity, and hydrogen bonds do not take place in multiple rounds as do the simulations; however, it can be decided here how many queue submissions an analysis will be distributed among. In addition to the submission, the analysis is concluded after the submitted jobs are completed. example methanol/water mixture argument details 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 project . create_hpc_submission_analyze_msd ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 4 , submission_split = 50 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , fit_starting_percentage = 20 , fit_ending_percentage = 80 , just_conclude = False ) argument description hpc_workspace The path to the hpc workspace. hpc_folder The path to the project folder on the hpc. hpc_scripts_folder The path to the python scripts folder. environment_name The name of the anaconda environment containing the dependencies. scheduler The queue scheduler. partition The partition the job should be submitted to. number_of_threads The number of requested threads. parallel_running The number of replica analyses running in parallel. submission_split The number of job submissions the analysis is split in. max_runtime_hh_mm_ss Maximum runtime for a job. which_hpc The HPC the script should be run on, currently supported are 'bwUniCluster2.0' and 'HoreKa'. fit_starting_percentage Start of the linear fit in percent of NVE production duration. fit_ending_percentage Ending of the linear fit in percent of NVE production duration. just_conclude If true, skips the generation of job submissions scripts and just generates the conclude script. Launch it with: 1 2 batch submit_msd_analysis.sh batch conclude_msd.sh example methanol/water mixture argument details 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 project . create_hpc_submission_analyze_hbonds ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 4 , submission_split = 25 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , donors = 'resname HOH and name O or resname Me and name O' , hydrogens = 'resname HOH and name H1 H2 or resname Me and name H2' , acceptors = 'resname HOH and name O or resname Me and name O' , just_conclude = False ) argument description hpc_workspace The path to the hpc workspace. hpc_folder The path to the project folder on the hpc. hpc_scripts_folder The path to the python scripts folder. environment_name The name of the anaconda environment containing the dependencies. scheduler The queue scheduler. partition The partition the job should be submitted to. number_of_threads The number of requested threads. parallel_running The number of replica analyses running in parallel. submission_split The number of job submissions the analysis is split in. max_runtime_hh_mm_ss Maximum runtime for a job. which_hpc The HPC the script should be run on, currently supported are 'bwUniCluster2.0' and 'HoreKa'. donors Selection of all hydrogen bond donor atoms in MDAnalysis selection syntax. hydrogens Selection of all hydrogen bond hydrogen atoms in MDAnalysis selection syntax. acceptors Selection of all hydrogen bond acceptor atoms in MDAnalysis selection syntax. just_conclude If true, skips the generation of job submissions scripts and just generates the conclude script. Launch it with: 1 2 batch submit_hbonds_analysis.sh batch conclude_hbonds.sh The results of the analyses are each stored in a JSON file that contains metadata for the project in addition to the measurement points, as well as metadata for each individual measurement point. These JSON files are stored inside the results folder. A completed project has the following folder structure with corresponding files:","title":"Usage"},{"location":"usage/#usage","text":"To use mixturemm install the package and import it. All required classes (Project, Molecule, Forcefield and Mixture) for simulation and analysis are added to the namespace. 1 import mixturemm","title":"Usage"},{"location":"usage/#setup","text":"The first step to beginning a project is setting the path to the directory where the project folder should be stored. 1 workdir = 'home/molecule_mixture_project' A project is defined via four setting sections. First, OpenMM is assigned the hardware on which the simulations are to run; if the simulations are to be run on a high-performance computing center, this is overwritten with the hardware resources specified when generating the submissions. Second, the parameter space of box sizes, temperatures, pressures, and dilutions to be considered is set. After that, the settings for the individual ensembles that follow each other in the simulation are made. Finally, the settings for constraints and nonbonded interactions affecting all ensembles are given. example project initiation argument details extend a project 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 project = mixturemm . Project ( workdir , simulation_platform = 'CUDA' , simulation_properties = { 'DeviceIndex' : '0' , 'Precision' : 'double' }, total_number_molecules = [ 2000 , 6000 , 15000 ], init_box_side_length = [ 65 , 75 , 102 ], chi_water_s = [ 0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1 ], temperature_s = [ 298.15 , 308.15 , 318.15 ], npt_equilibration_pressure_s = [ 1 ], npt_equilibration_pressure_coupling_frequency = 500 , npt_equilibration_temperature_coupling_frequency = 0.1 , npt_equilibration_timestep_fs = 2 , npt_equilibration_duration_ns = 12 , reporting_frequency_state_npt_equilibration = 500 , nvt_equilibration_temperature_coupling_frequency = 0.1 , nvt_equilibration_timestep_fs = 2 , nvt_equilibration_duration_ns = 20 , reporting_frequency_state_nvt_equilibration = 4000 , nve_production_timestep_fs = 1 , nve_production_duration_ns = 50 , reporting_frequency_coordinates_unwrapped = 4000 , reporting_frequency_coordinates_wrapped = 8000 , reporting_frequency_state_nve_production = 8000 , replica_count = 40 , pme_error_tolerance = 0.000001 , constraint_tolerance = 0.0000001 , cutoff_distance_nm = 1.4 , cutoff_switch_distance_nm = 1.2 ) argument description workdir The path at which the project should be stored. simulation_platform The platform the simulation should run on. OpenMM ref. simulation_properties The platform properties for the simulation. OpenMM ref. total_number_molecules A list with the number of molecules that should be placed in the simulation box. init_box_side_length The initial box side lengths that should be used by packmol. Packmol ref. chi_water_s A list with all different molar fractions of water that should be simulated. temperature_s A list with all different temperatures in kelvin at which the boxes should be simulated. npt_equilibration_pressure_s A list with all pressures in bar at which the boxes should be simulated. npt_equilibration_pressure_coupling_frequency The pressure coupling frequency at which the Monte Carlo barostat should interact with the system and attempt a Monte Carlo move to adjust the volume during the NpT equilibration in simulation steps. OpenMM ref. npt_equilibration_temperature_coupling_frequency The collision frequency of the Langevin thermostat during the NpT equilibration in inverse picoseconds. OpenMM ref. npt_equilibration_timestep_fs The integration time step during the NpT equilibration in femtoseconds. npt_equilibration_duration_ns The duration of the NpT equilibration in nanoseconds. reporting_frequency_state_npt_equilibration The reporting frequency of the openMM StateDataReporter in simulation steps during the NpT equilibration. OpenMM ref. nvt_equilibration_temperature_coupling_frequency The collision frequency of the Langevin thermostat during the NVT equilibration in inverse picoseconds. OpenMM ref. nvt_equilibration_timestep_fs The integration time step during the NVT equilibration in femtoseconds. nvt_equilibration_duration_ns The duration of the NVT equilibration in nanoseconds. reporting_frequency_state_nvt_equilibration The reporting frequency of the openMM StateDataReporter in simulation steps during the NVT equilibration. OpenMM ref. nve_production_timestep_fs The integration time step during the NVE production in femtoseconds. nve_production_duration_ns The duration of the NVE production in nanoseconds. reporting_frequency_coordinates_unwrapped The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. OpenMM ref. reporting_frequency_coordinates_wrapped The reporting frequency of the trajectory with wrapped coordinates in simulation steps during the NVE production. OpenMM ref. reporting_frequency_state_nve_production The reporting frequency of the openMM StateDataReporter in simulation steps during the NVE production. OpenMM ref. replica_count The number of times the simulation of one system should be replicated. pme_error_tolerance Decides how large the grid for PME is together with the cutoff. OpenMM ref. constraint_tolerance The constraint tolerance specifies the distance tolerance within which constraints are maintained, as a fraction of the constrained distance. cutoff_distance_nm The cutoff distance for nonbonded interactions in nanometers. OpenMM ref. cutoff_switch_distance_nm Starting point of the switching function that makes the energy go smoothly to 0 at the cutoff distance in nanometers. OpenMM ref. A project can easily be extended by adding the new parameters to the existing parameter lists of total molecule number and box size, temperature, pressure and water mole > fraction or increasing the replica count. Subsequently, the molecules contained in the mixture and their force fields are defined and the associated files are added to the project. On the one hand definition and the PDB files of the molecules example methanol/water mixture argument details 1 2 3 4 Water = mixturemm . Molecule ( workdir , 'Water' , 4 , 'home/tip4p.pdb' , 'HOH' , 'O' , '1S/H2O/h1H2' , 18.015 , use_as_water = True ) Methanol = mixturemm . Molecule ( workdir , 'Methanol' , 3 , 'home/methanol.pdb' , 'Me' , 'CO' , '1S/CH4O/c1-2/h2H,1H3' , 32.04 ) project . add_molecule ( Water ) project . add_molecule ( Methanol ) argument description workdir The path at which the project is stored. name Name of the molecule. number_of_atoms The number of atoms that the molecule consists of. path_to_pdb The path to the molecule PDB file. abbreviation The abbreviation of the molecule that is used inside the PDB file. smiles The SMILES code of the molecule. inchi The InChI code of the molecule. molar_mass The molar mass of the molecule. use_as_water Decides whether the molecule is used as water or not. If used as water, the water molar fraction is applied to it while packing boxes. ... on the other hand the definitions of the force fields and the XML files. United-atoms force fields When simulating force fields with united atoms, as in the example here, note that OpenMM recognizes all basic atom types but not united-atoms. These must be added as described as \"elements\". example methanol/water mixture argument details 1 2 3 4 Water_FF = mixturemm . Forcefield ( workdir , 'home/tip4p-fb.xml' , 'tip4p-fb' , built_in = False ) Methanol_FF = mixturemm . Forcefield ( workdir , 'home/trappe_methanol.xml' , 'trappe_methanol' , built_in = False , elements = { '3' : 15.0347 }) project . add_forcefield ( Water_FF ) project . add_forcefield ( Methanol_FF ) argument description workdir The path at which the project is stored. path_to_XML The path to the force field XML file. ff_name The name under which the force field should be stored. built_in Decides whether the fore field is part of openMM or from an external source. If true, declares that a built in forcefield of openmm will be used. elements OpenMM uses Elements to match molecules to the force field. If atomtypes in the force field are unknown to OpenMM, they are registered by giving their name and mass in the form {'name' : mass}. OpenMM ref. Then, the molecule names and their corresponding mole fraction in the mixture are given. example methanol/water mixture argument details 1 2 WaMeMixture = mixturemm . Mixture ({ 'Methanol' : 1 }) project . add_mixture ( WaMeMixture ) argument description mixture_dict Dictionary with molecule names and their corresponding mole fraction in the mixture. All project input information as well as added molecules and forcefields will be stored in a short JSON project description. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 { \"workflow_info\" : { \"general\" : { \"package_name\" : \"mixturemm\" , \"simulation_engine\" : \"OpenMM\" , \"analysis_package\" : \"MDAnalysis\" }, \"simulation\" : { \"ensemble_order\" : \"---(slow heating)---> |NpT| ---(rescale boxes and assign velocities)---> |NVT| ------> |NVE|\" , \"pressure_and_temperature_control\" : { \"NpT\" : \"Langevin thermostat, Monte Carlo barostat\" , \"NVT\" : \"Langevin thermostat\" , \"NVE\" : \"no pressure and temperature control\" }, \"constraints\" : \"hydrogen bonds\" , \"nonbonded forces algorithm\" : \"particle mesh ewald\" } }, \"project\" : { \"simulation_parameters\" : { \"total_number_of_molecules\" : [ 2000 , 6000 , 15000 ], \"initial_box_side_lengths\" : [ 65 , 75 , 102 ], \"water_mole_fractions\" : [ 0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 , 0.6 , 0.7 , 0.8 , 0.9 , 1 ], \"temperature_s_in_kelvin\" : [ 298.15 , 308.15 , 318.15 ], \"pressure_s_in_bar\" : [ 1 ], \"number_of_replicas\" : 40 , \"replica_starting_number\" : 1 , \"overcharged_boxes\" : { \"[2000] molecules\" : \"with 60 replicas\" } }, \"hardware_settings\" : { \"platform\" : \"CUDA\" , \"properties\" : { \"DeviceIndex\" : \"0\" , \"Precision\" : \"double\" } }, \"simulation_settings\" : { \"pme_error_tolerance\" : 1e-06 , \"constraint_tolerance\" : 1e-07 , \"cutoff_distance_in_nm\" : 1.4 , \"switching_function_starting_distance_in_nm\" : 1.2 }, \"npt_equilibration\" : { \"pressure_coupling_frequency\" : 500 , \"temperature_coupling_frequency\" : 0.1 , \"timestep_in_fs\" : 2 , \"duration_in_ns\" : 12 , \"state_data_reporting_frequency\" : 500 }, \"nvt_equilibration\" : { \"temperature_coupling_frequency\" : 0.1 , \"timestep_in_fs\" : 2 , \"duration_in_ns\" : 20 , \"state_data_reporting_frequency\" : 4000 }, \"nve_production\" : { \"timestep_in_fs\" : 1 , \"duration_in_ns\" : 50 , \"state_data_reporting_frequency\" : 8000 , \"unwrapped_trajectory_reporting_frequency\" : 4000 , \"wrapped_trajectory_reporting_frequency\" : 8000 } }, \"molecules\" : { \"Water\" : { \"number_of_atoms\" : 4 , \"abbreviation\" : \"HOH\" , \"molar_ratio\" : 1 , \"smiles_code\" : \"O\" , \"inchi_key\" : \"1S/H2O/h1H2\" , \"molar_mass\" : 18.015 , \"used_as_water\" : true }, \"Methanol\" : { \"number_of_atoms\" : 3 , \"abbreviation\" : \"Me\" , \"molar_ratio\" : 1 , \"smiles_code\" : \"CO\" , \"inchi_key\" : \"1S/CH4O/c1-2/h2H,1H3\" , \"molar_mass\" : 32.04 , \"used_as_water\" : false } }, \"force fields\" : { \"tip4p-fb\" : { \"built_in\" : false , \"added_elements\" : null }, \"trappe_methanol\" : { \"built_in\" : false , \"added_elements\" : { \"3\" : 15.0347 } } } } In the last preparatory step, the simulated systems and their replicas are generated by combining the parameters and the corresponding folder structure is created. Then, the simulation boxes are packed with the PDB files of the molecules corresponding to their proportion in the total number of molecules. In addition, a further number of replicas can be added at this point for individual box sizes. system/replica preparation and box packing without ... and with adding replicas for certain box sizes 1 2 3 project . create_simulationboxes () project . create_systems () project . create_replicas ( start = 1 ) 1 2 3 4 5 project . create_simulationboxes () project . create_systems () project . create_replicas ( start = 1 ) project . overcharge_replicas ( total_number_molecules = [ 2000 ], overcharge_amount = 50 , start = 1 ) project . overcharge_replicas ( total_number_molecules = [ 6000 ], overcharge_amount = 20 , start = 1 )","title":"Setup"},{"location":"usage/#simulation","text":"There are two ways to run the simulations defined in the project. They can be run locally on the computer where the project was initiated. However, this is not recommended for large-scale projects due to the low computing power. This mode is rather used for test runs and troubleshooting of the system setup. First the NpT equilibration of all systems takes place, then the NVT equilibration and following NVE production of the trajectories of the replicas. 1 2 project . adjust_to_correct_density () project . simulate () The recommended approach for large-scale projects is the submission of the simulations to a high-performance computing center. There, the simulations are transferred via a queuing system to nodes where they run. With the resources available there, it is possible to run many simulations in parallel. To run the simulations on a high performance computing center the executable scripts from the HPC folder of the mixturemm package are needed and the whole project folder has to be transferred to a workspace on the high performance computing center. Submission scripts are required to submit simulations to the queue. These are generated based on the given project and the specification of the hardware resources. To ensure the optimal use of the available resources on the nodes, the simulations can be parallelized according to the available GPUs or CPU cores. Dependencies Be aware that all dependencies have to be available on the high-performance computing center as well. It is therefore recommended to install it into a anaconda environment with OpenMM , packmol , MDAnalysis , mdtraj , seaborn , more-itertools and tidynamics . This environment should be the one you activate on the nodes where the simulations and analyses are submitted to. Additionally, you have to either upload or generate your project folder with all the wanted job scripts to/on your high-performance computing center. Updating the folder on the high-performance computing center when running additional replicas When new replicas are added by increasing the replica number of the project, the folder structure on the high-performance computing center can be extended with 1 project . hpc_extend_replica_folders ( hpc_folder = \"/hpc/workspace/molecule_mixture_project\" ) first submission subsequent submissions argument details NpT equilibration NVT equilibration and NVE production 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 project . create_hpc_submission_adjust_to_correct_density ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_simulation' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 500000 ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 project . create_hpc_submission_simulate ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_simulation' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = 50 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 500000 ) NpT equilibration NVT equilibration and NVE production 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 project . remove_done_jobs_from_replicas ( self , path_to_job_checks = 'workdir/job_checks.txt' ) project . create_hpc_submission_adjust_to_correct_density ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_simulation' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 500000 ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 remove_done_jobs_from_replicas ( self , path_to_job_checks = 'workdir/job_checks.txt' ) project . create_hpc_submission_simulate ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_simulation' , scheduler = 'SBATCH' , partition = 'accelerated' , number_of_threads = 152 , number_of_gpus = 4 , chunk_size = 4 , max_number_of_jobs = 50 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , chain_submission_number = 1 , dependency_type = 'afternotok' , checkpoint_frequency = 500000 ) argument description hpc_workspace The path to the hpc workspace. hpc_folder The path to the project folder on the hpc. hpc_scripts_folder The path to the python scripts folder. environment_name The name of the anaconda environment containing the dependencies. scheduler The queue scheduler. partition The partition the job should be submitted to. number_of_threads The number of requested threads. number_of_gpus The number of GPUs requested on a node. chunk_size Number of simulations to submit in a chunk, should correspond to the number of requested GPUs. max_runtime_hh_mm_ss Maximum runtime for a job. which_hpc The HPC the script should be run on, currently supported are 'bwUniCluster2.0' and 'HoreKa'. chain_submission_number The number of job submissions that should be submitted as a sequential chain job. dependency_type Dependency keyword of the SLURM workload manager for chain jobs. checkpoint_frequency The frequency at which checkpoints are saved to restart from once a chain job continues. After transferring the folder with the job submission scripts to the high-performance computing center, they are submitted from via the terminal. NpT equilibration NVT equilibration and NVE production 1 bash submit_adjust_to_correct_density.sh 1 bash submit_simulate.sh However, nodes can only be occupied for a limited period of time. This leads to the fact that simulations have to be interrupted and resumed. This is implemented as follows with simulation checkpoints: Since the queues only allow a limited number of job submissions at once, the number of generated job submission scripts is limited to this. Thus, the project is submitted in multiple submission cycles to work through the required simulations. All in all, the simulation takes place on a high-performance data center according to the following scheme: After each simulation cycle on the high-performance data center, the status of the simulations is checked with the job checker. 1 2 3 4 5 6 7 project . hpc_job_checker ( hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , hpc_workspace = \"/hpc/workspace/\" , environment_name = 'conda_env_simulation' , output = 'verbose' , energy_shift_tolerance_percent = 1 ) In addition to the percentage progress of each replica, the average temperature and the percentage deviation of the total energy are determined. At the end of the output txt file, it is summarized how many of the replicas are finished and how many still need to run. In addition, if the given limit for the deviation of the total energy of one or more replicas is exceeded, a warning is added with the name of the replica. With the information about replicas already completed and replicas still to be run, the job submissions of the next simulation cycle are created. The job checker is launched with: 1 batch job_checker.sh","title":"Simulation"},{"location":"usage/#analysis","text":"Just as for the simulations, job submissions are generated for the analyses, which are then transferred to the high-performance computing center. The density analysis is then submitted in one step, it refers only to the NpT equilibration phase. example methanol/water mixture argument details 1 2 3 4 5 6 7 8 9 10 project . create_hpc_submission_analyze_density ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , max_runtime_hh_mm_ss = '00:10:00' , conda_module = False ) argument description hpc_workspace The path to the hpc workspace. hpc_folder The path to the project folder on the hpc. hpc_scripts_folder The path to the python scripts folder. environment_name The name of the anaconda environment containing the dependencies. scheduler The queue scheduler. partition The partition the job should be submitted to. number_of_threads The number of requested threads. max_runtime_hh_mm_ss Maximum runtime for a job. which_hpc The HPC the script should be run on, currently supported are 'bwUniCluster2.0' and 'HoreKa'. Launch it with: 1 batch submit_density_analysis.sh The two much more computationally intensive analyses on self-diffusion coefficients, viscosity, and hydrogen bonds do not take place in multiple rounds as do the simulations; however, it can be decided here how many queue submissions an analysis will be distributed among. In addition to the submission, the analysis is concluded after the submitted jobs are completed. example methanol/water mixture argument details 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 project . create_hpc_submission_analyze_msd ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 4 , submission_split = 50 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , fit_starting_percentage = 20 , fit_ending_percentage = 80 , just_conclude = False ) argument description hpc_workspace The path to the hpc workspace. hpc_folder The path to the project folder on the hpc. hpc_scripts_folder The path to the python scripts folder. environment_name The name of the anaconda environment containing the dependencies. scheduler The queue scheduler. partition The partition the job should be submitted to. number_of_threads The number of requested threads. parallel_running The number of replica analyses running in parallel. submission_split The number of job submissions the analysis is split in. max_runtime_hh_mm_ss Maximum runtime for a job. which_hpc The HPC the script should be run on, currently supported are 'bwUniCluster2.0' and 'HoreKa'. fit_starting_percentage Start of the linear fit in percent of NVE production duration. fit_ending_percentage Ending of the linear fit in percent of NVE production duration. just_conclude If true, skips the generation of job submissions scripts and just generates the conclude script. Launch it with: 1 2 batch submit_msd_analysis.sh batch conclude_msd.sh example methanol/water mixture argument details 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 project . create_hpc_submission_analyze_hbonds ( hpc_workspace = \"/hpc/workspace/\" , hpc_folder = \"/hpc/workspace/molecule_mixture_project\" , hpc_scripts_folder = \"/hpc/workspace/HPC\" , environment_name = 'conda_env_analysis' , scheduler = 'SBATCH' , partition = 'cpuonly' , number_of_threads = 152 , parallel_running = 4 , submission_split = 25 , max_runtime_hh_mm_ss = '24:00:00' , conda_module = False , donors = 'resname HOH and name O or resname Me and name O' , hydrogens = 'resname HOH and name H1 H2 or resname Me and name H2' , acceptors = 'resname HOH and name O or resname Me and name O' , just_conclude = False ) argument description hpc_workspace The path to the hpc workspace. hpc_folder The path to the project folder on the hpc. hpc_scripts_folder The path to the python scripts folder. environment_name The name of the anaconda environment containing the dependencies. scheduler The queue scheduler. partition The partition the job should be submitted to. number_of_threads The number of requested threads. parallel_running The number of replica analyses running in parallel. submission_split The number of job submissions the analysis is split in. max_runtime_hh_mm_ss Maximum runtime for a job. which_hpc The HPC the script should be run on, currently supported are 'bwUniCluster2.0' and 'HoreKa'. donors Selection of all hydrogen bond donor atoms in MDAnalysis selection syntax. hydrogens Selection of all hydrogen bond hydrogen atoms in MDAnalysis selection syntax. acceptors Selection of all hydrogen bond acceptor atoms in MDAnalysis selection syntax. just_conclude If true, skips the generation of job submissions scripts and just generates the conclude script. Launch it with: 1 2 batch submit_hbonds_analysis.sh batch conclude_hbonds.sh The results of the analyses are each stored in a JSON file that contains metadata for the project in addition to the measurement points, as well as metadata for each individual measurement point. These JSON files are stored inside the results folder. A completed project has the following folder structure with corresponding files:","title":"Analysis"},{"location":"utils/","text":"utils \u00b6 Module with useful functions for preparing a project. MIT License Copyright (c) 2021, Benjamin Schmitz Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. add_chainsubmitter_script ( path ) \u00b6 Adds a chainsubmitter.sh file to the selected folder that can be used to submit chain jobs on a HPC using SLURM. Source code in mixturemm/utils.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def add_chainsubmitter_script ( path ) -> None : \"\"\"Adds a chainsubmitter.sh file to the selected folder that can be used to submit chain jobs on a HPC using SLURM. \"\"\" with open ( f ' { path } /chainsubmitter.sh' , 'w' ) as file : file . write ( '''#!/bin/bash ###################################################### ## submitter script for chain jobs ## ###################################################### ## Define maximum number of jobs via positional parameter 1, default is 5 max_nojob=${1:-5} ## Define location of the job scripts ## as list of strings? chain_link_job=${2:-${PWD}/shscript.sh} ## Define type of dependency via positional parameter 2, default is 'afterok' dep_type=\"${3:-afternotok}\" ## Define the queue you want to use queue=${4:-gpu_4} myloop_counter=1 while [ ${myloop_counter} -le ${max_nojob} ] ; do ## Differ msub_opt depending on chain link number if [ ${myloop_counter} -eq 1 ] ; then slurm_opt=\"\" else slurm_opt=\"-d ${dep_type}:${jobID}\" fi ## Print current iteration number and sbatch command echo \"Chain job iteration = ${myloop_counter}\" echo \"sbatch --export=myloop_counter=${myloop_counter} ${slurm_opt} ${chain_link_job}\" ## Store job ID for next iteration by storing output of sbatch command with empty lines jobID=$(sbatch -p ${queue} --export=ALL,myloop_counter=${myloop_counter} ${slurm_opt} ${chain_link_job} 2>&1 | sed 's/[S,a-z]* //g') ## Check if ERROR occured if [[ \"${jobID}\" =~ \"ERROR\" ]] ; then echo \" -> submission failed!\" ; exit 1 else echo \" -> job number = ${jobID}\" fi ## Increase counter let myloop_counter+=1 done''' ) add_json_entry ( path_to_json , entry , key = None , subkey = None , subsubkey = None , subsubsubkey = None ) \u00b6 Adds an entry to a JSON file at the specified level defined by the given keys. Parameters: Name Type Description Default path_to_json str The path to the JSON file to that the entry should be added. required entry str/int/list/dict The entry that should be added. required key str The first level key of the JSON. Defaults to None. None subkey str The second level key of the JSON. Defaults to None. None subsubkey str The third level key of the JSON. Defaults to None. None subsubsubkey str The fourth level key of the JSON. Defaults to None. None Source code in mixturemm/utils.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 def add_json_entry ( path_to_json , entry , key = None , subkey = None , subsubkey = None , subsubsubkey = None ) -> None : \"\"\"Adds an entry to a JSON file at the specified level defined by the given keys. Args: path_to_json (str): The path to the JSON file to that the entry should be added. entry (str/int/list/dict): The entry that should be added. key (str, optional): The first level key of the JSON. Defaults to None. subkey (str, optional): The second level key of the JSON. Defaults to None. subsubkey (str, optional): The third level key of the JSON. Defaults to None. subsubsubkey (str, optional): The fourth level key of the JSON. Defaults to None. \"\"\" condition = sum ( arg is not None for arg in [ key , subkey , subsubkey , subsubsubkey ]) with open ( f ' { path_to_json } ' , 'r+' , encoding = 'utf-8' ) as f : j_file = json . load ( f ) if condition == 1 : j_file [ key ] = entry elif condition == 2 : if key not in j_file : j_file [ key ] = {} j_file [ key ][ subkey ] = entry elif condition == 3 : if key not in j_file : j_file [ key ] = {} if subkey not in j_file [ key ]: j_file [ key ][ subkey ] = {} j_file [ key ][ subkey ][ subsubkey ] = entry elif condition == 4 : if key not in j_file : j_file [ key ] = {} if subkey not in j_file [ key ]: j_file [ key ][ subkey ] = {} if subsubkey not in j_file [ key ][ subkey ]: j_file [ key ][ subkey ][ subsubkey ] = {} j_file [ key ][ subkey ][ subsubkey ][ subsubsubkey ] = entry f . seek ( 0 ) json . dump ( j_file , f , ensure_ascii = False , indent = 4 ) bash_arg_prepper ( * args ) \u00b6 Prepares the command line arguments for the HPC bash files. Parameters: Name Type Description Default *args Variable length argument list. () Returns: Name Type Description tuple tuple Variable length tuple with the arguments prepared to be able to be read by the bash interpreter. Source code in mixturemm/utils.py 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 def bash_arg_prepper ( * args ) -> tuple : \"\"\"Prepares the command line arguments for the HPC bash files. Args: *args: Variable length argument list. Returns: tuple: Variable length tuple with the arguments prepared to be able to be read by the bash interpreter. \"\"\" result_list = [] for arg in args : if type ( arg ) is list : if any ( isinstance ( x , ( int , float )) for x in arg ): list_with_strings = [ str ( x ) for x in arg ] joined_arg = ',' . join ( list_with_strings ) result_list . append ( joined_arg ) else : joined_arg = ',' . join ( arg ) result_list . append ( joined_arg ) elif type ( arg ) is dict : joined_arg = ',' . join ([ f ' { key } = { value } ' for key , value in arg . items ()]) result_list . append ( joined_arg ) else : result_list . append ( str ( arg )) return tuple ( result_list ) if len ( result_list ) > 1 else result_list [ 0 ] directory_maker ( path ) \u00b6 A function that creates directories. Parameters: Name Type Description Default path str Path to the directory that should be created. required Source code in mixturemm/utils.py 32 33 34 35 36 37 38 39 40 41 def directory_maker ( path ) -> str : \"\"\"A function that creates directories. Args: path (str): Path to the directory that should be created. \"\"\" if not os . path . exists ( path ): os . makedirs ( path ) return path hpc_submission_header ( file_name , process_name , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) \u00b6 Writes the header of a hpc submission script. Parameters: Name Type Description Default file_name str The name of the hpc submission script. required process_name str The process name that the queued job should get. required hpc_workspace str The path to the hpc workspace. required environment_name str The name of the anaconda environment containing the dependencies. required scheduler str The queue scheduler. required partition str The partition the job should be submitted to. required number_of_threads int The number of requested threads. required number_of_gpus int The number of GPUs requested on a node. required max_runtime_hh_mm_ss str Maximum runtime for a job. required conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. required Source code in mixturemm/utils.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def hpc_submission_header ( file_name , process_name , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) -> None : \"\"\"Writes the header of a hpc submission script. Args: file_name (str): The name of the hpc submission script. process_name (str): The process name that the queued job should get. hpc_workspace (str): The path to the hpc workspace. environment_name (str): The name of the anaconda environment containing the dependencies. scheduler (str): The queue scheduler. partition (str): The partition the job should be submitted to. number_of_threads (int): The number of requested threads. number_of_gpus (int): The number of GPUs requested on a node. max_runtime_hh_mm_ss (str): Maximum runtime for a job. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. \"\"\" with open ( f ' { file_name } ' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash # { scheduler } -J { process_name } ''' ) if partition == 'accelerated' : file . write ( f '''# { scheduler } --gres=gpu: { number_of_gpus } ''' ) file . write ( f '''# { scheduler } --ntasks= { number_of_threads } # { scheduler } --time= { max_runtime_hh_mm_ss } # { scheduler } --partition= { partition } ''' ) if not conda_module : file . write ( f '''set +eu module purge module load compiler/pgi/2020 module load devel/cuda/11.0 source { hpc_workspace } /conda/etc/profile.d/conda.sh eval \"$(conda shell.bash hook)\" conda activate { environment_name } set -eu ''' ) if conda_module : file . write ( f '''set +eu module purge module load compiler/pgi/2020 module load devel/cuda/11.0 module load devel/miniconda eval \"$(conda shell.bash hook)\" conda activate { environment_name } set -eu ''' ) file . write ( f '''echo \"-----------------------------------------------------------------------\" echo { process_name } echo $(date -u) \"Job was started\" echo \"-----------------------------------------------------------------------\" ''' ) jsonize_forcefield ( Forcefield ) \u00b6 Creates the JSON structure of the force field by putting project attributes in a dictionary. Parameters: Name Type Description Default Forcefield obj Contains information on the force field. required Returns: Name Type Description dict dict The JSON structure of the project description. Source code in mixturemm/utils.py 268 269 270 271 272 273 274 275 276 277 278 279 280 def jsonize_forcefield ( Forcefield ) -> dict : \"\"\"Creates the JSON structure of the force field by putting project attributes in a dictionary. Args: Forcefield (obj): Contains information on the force field. Returns: dict: The JSON structure of the project description. \"\"\" json_structure = { 'built_in' : Forcefield . built_in , 'added_elements' : Forcefield . elements } return json_structure jsonize_molecule ( Molecule ) \u00b6 Creates the JSON structure of the molecule by putting project attributes in a dictionary. Parameters: Name Type Description Default Molecule obj Contains information on the molecule that is used for packing with packmol and to identify it. required Returns: Name Type Description dict dict The JSON structure of the project description. Source code in mixturemm/utils.py 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def jsonize_molecule ( Molecule ) -> dict : \"\"\"Creates the JSON structure of the molecule by putting project attributes in a dictionary. Args: Molecule (obj): Contains information on the molecule that is used for packing with packmol and to identify it. Returns: dict: The JSON structure of the project description. \"\"\" json_structure = { 'number_of_atoms' : Molecule . number_of_atoms , 'abbreviation' : Molecule . abbreviation , 'smiles_code' : Molecule . smiles , 'inchi_key' : Molecule . inchi , 'molar_mass' : Molecule . molar_mass , 'used_as_water' : Molecule . use_as_water } return json_structure jsonize_project ( Project ) \u00b6 Creates the JSON structure of the project by putting project attributes in a dictionary. Parameters: Name Type Description Default Project obj The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. required Returns: Name Type Description dict dict The JSON structure of the project description. Source code in mixturemm/utils.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def jsonize_project ( Project ) -> dict : \"\"\"Creates the JSON structure of the project by putting project attributes in a dictionary. Args: Project (obj): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Returns: dict: The JSON structure of the project description. \"\"\" json_structure = { 'workflow_info' : { 'general' : { 'package_name' : 'mixturemm' , 'simulation_engine' : 'OpenMM' , 'analysis_package' : 'MDAnalysis' }, 'simulation' : { 'ensemble_order' : '---(slow heating)---> |NpT| ---(rescale boxes and assign velocities)---> |NVT| ------> |NVE|' , 'pressure_and_temperature_control' : { 'NpT' : 'Langevin thermostat, Monte Carlo barostat' , 'NVT' : 'Langevin thermostat' , 'NVE' : 'no pressure and temperature control' }, 'constraints' : 'hydrogen bonds' , 'nonbonded forces algorithm' : 'particle mesh ewald' }}, 'project' : { 'simulation_parameters' : { 'total_number_of_molecules' : Project . total_number_molecules , 'initial_box_side_lengths' : Project . init_box_side_length , 'water_mole_fractions' : Project . chi_water_s , 'temperature_s_in_kelvin' : Project . temperature_s , 'pressure_s_in_bar' : Project . npt_equilibration_pressure_s , 'number_of_replicas' : Project . replica_count }, 'hardware_settings' : { 'platform' : Project . simulation_platform , 'properties' : Project . simulation_properties }, 'simulation_settings' : { 'pme_error_tolerance' : Project . pme_error_tolerance , 'constraint_tolerance' : Project . constraint_tolerance , 'cutoff_distance_in_nm' : Project . cutoff_distance_nm , 'switching_function_starting_distance_in_nm' : Project . cutoff_switch_distance_nm }, 'npt_equilibration' : { 'pressure_coupling_frequency' : Project . npt_equilibration_pressure_coupling_frequency , 'temperature_coupling_frequency' : Project . npt_equilibration_temperature_coupling_frequency , 'timestep_in_fs' : Project . npt_equilibration_timestep_fs , 'duration_in_ns' : Project . npt_equilibration_duration_ns , 'state_data_reporting_frequency' : Project . reporting_frequency_state_npt_equilibration }, 'nvt_equilibration' : { 'temperature_coupling_frequency' : Project . nvt_equilibration_temperature_coupling_frequency , 'timestep_in_fs' : Project . nvt_equilibration_timestep_fs , 'duration_in_ns' : Project . nvt_equilibration_duration_ns , 'state_data_reporting_frequency' : Project . reporting_frequency_state_nvt_equilibration }, 'nve_production' : { 'timestep_in_fs' : Project . nve_production_timestep_fs , 'duration_in_ns' : Project . nve_production_duration_ns , 'state_data_reporting_frequency' : Project . reporting_frequency_state_nve_production , 'unwrapped_trajectory_reporting_frequency' : Project . reporting_frequency_coordinates_unwrapped , 'wrapped_trajectory_reporting_frequency' : Project . reporting_frequency_coordinates_wrapped }}} return json_structure merge_project_descriptions ( path_to_old_description , new_json_structure ) \u00b6 Merges two project descriptions Parameters: Name Type Description Default path_to_old_description str The path to the already existent project description. required new_json_structure dict The newly created json structure that should be merged with the existent one. required Source code in mixturemm/utils.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 def merge_project_descriptions ( path_to_old_description , new_json_structure ) -> None : \"\"\"Merges two project descriptions Args: path_to_old_description (str): The path to the already existent project description. new_json_structure (dict): The newly created json structure that should be merged with the existent one. \"\"\" with open ( f ' { path_to_old_description } ' , 'r+' , encoding = 'utf-8' ) as f : json_base = json . load ( f ) for key , value in json_base [ 'project' ] . items (): if key in new_json_structure [ 'project' ]: for inner_key , inner_value in value . items (): if inner_key in new_json_structure [ 'project' ][ f ' { key } ' ]: if type ( inner_value ) is not list : if inner_value != new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ]: old = inner_value new = new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] json_base [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] = [ old , new ] else : if type ( new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ]) is not list : if new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] not in inner_value : json_base [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] . append ( new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ]) else : inner_value . extend ( x for x in new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] if x not in inner_value ) json_base [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] = inner_value f . seek ( 0 ) json . dump ( json_base , f , ensure_ascii = False , indent = 4 ) msd_opt_prepper ( nve_production_timestep_fs , nve_production_duration_ns , reporting_frequency_coordinates_unwrapped , fit_starting_percentage , fit_ending_percentage ) \u00b6 Prepares the options for the MSD Analysis on the hpc. Parameters: Name Type Description Default nve_production_timestep_fs int The integration time step during the NVE production in femtoseconds. required nve_production_duration_ns int The duration of the NVE production in nanoseconds. required reporting_frequency_coordinates_unwrapped int The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. required fit_starting_percentage int Start of the linear fit in percent of NVE production duration. required fit_ending_percentage int Ending of the linear fit in percent of NVE production duration. required Returns: Name Type Description tuple tuple The options for the MSD Analysis on the hpc, fit_starting_frame, fit_ending_frame and time_between_frames. Source code in mixturemm/utils.py 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 def msd_opt_prepper ( nve_production_timestep_fs , nve_production_duration_ns , reporting_frequency_coordinates_unwrapped , fit_starting_percentage , fit_ending_percentage ) -> tuple : \"\"\"Prepares the options for the MSD Analysis on the hpc. Args: nve_production_timestep_fs (int): The integration time step during the NVE production in femtoseconds. nve_production_duration_ns (int): The duration of the NVE production in nanoseconds. reporting_frequency_coordinates_unwrapped (int): The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. fit_starting_percentage (int): Start of the linear fit in percent of NVE production duration. fit_ending_percentage (int): Ending of the linear fit in percent of NVE production duration. Returns: tuple: The options for the MSD Analysis on the hpc, fit_starting_frame, fit_ending_frame and time_between_frames. \"\"\" time_between_frames = nve_production_timestep_fs * ( 10 ** ( - 3 )) * reporting_frequency_coordinates_unwrapped conversion_factor_ps_to_frame = 1 / time_between_frames fit_starting_dec = fit_starting_percentage * ( 1 / 100 ) fit_ending_dec = fit_ending_percentage * ( 1 / 100 ) fit_starting_frame = int ( fit_starting_dec * nve_production_duration_ns * ( 10 ** 3 ) * conversion_factor_ps_to_frame ) fit_ending_frame = int ( fit_ending_dec * nve_production_duration_ns * ( 10 ** 3 ) * conversion_factor_ps_to_frame ) return fit_starting_frame , fit_ending_frame , time_between_frames","title":"utils module"},{"location":"utils/#utils","text":"Module with useful functions for preparing a project. MIT License Copyright (c) 2021, Benjamin Schmitz Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"utils"},{"location":"utils/#mixturemm.utils.add_chainsubmitter_script","text":"Adds a chainsubmitter.sh file to the selected folder that can be used to submit chain jobs on a HPC using SLURM. Source code in mixturemm/utils.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def add_chainsubmitter_script ( path ) -> None : \"\"\"Adds a chainsubmitter.sh file to the selected folder that can be used to submit chain jobs on a HPC using SLURM. \"\"\" with open ( f ' { path } /chainsubmitter.sh' , 'w' ) as file : file . write ( '''#!/bin/bash ###################################################### ## submitter script for chain jobs ## ###################################################### ## Define maximum number of jobs via positional parameter 1, default is 5 max_nojob=${1:-5} ## Define location of the job scripts ## as list of strings? chain_link_job=${2:-${PWD}/shscript.sh} ## Define type of dependency via positional parameter 2, default is 'afterok' dep_type=\"${3:-afternotok}\" ## Define the queue you want to use queue=${4:-gpu_4} myloop_counter=1 while [ ${myloop_counter} -le ${max_nojob} ] ; do ## Differ msub_opt depending on chain link number if [ ${myloop_counter} -eq 1 ] ; then slurm_opt=\"\" else slurm_opt=\"-d ${dep_type}:${jobID}\" fi ## Print current iteration number and sbatch command echo \"Chain job iteration = ${myloop_counter}\" echo \"sbatch --export=myloop_counter=${myloop_counter} ${slurm_opt} ${chain_link_job}\" ## Store job ID for next iteration by storing output of sbatch command with empty lines jobID=$(sbatch -p ${queue} --export=ALL,myloop_counter=${myloop_counter} ${slurm_opt} ${chain_link_job} 2>&1 | sed 's/[S,a-z]* //g') ## Check if ERROR occured if [[ \"${jobID}\" =~ \"ERROR\" ]] ; then echo \" -> submission failed!\" ; exit 1 else echo \" -> job number = ${jobID}\" fi ## Increase counter let myloop_counter+=1 done''' )","title":"add_chainsubmitter_script()"},{"location":"utils/#mixturemm.utils.add_json_entry","text":"Adds an entry to a JSON file at the specified level defined by the given keys. Parameters: Name Type Description Default path_to_json str The path to the JSON file to that the entry should be added. required entry str/int/list/dict The entry that should be added. required key str The first level key of the JSON. Defaults to None. None subkey str The second level key of the JSON. Defaults to None. None subsubkey str The third level key of the JSON. Defaults to None. None subsubsubkey str The fourth level key of the JSON. Defaults to None. None Source code in mixturemm/utils.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 def add_json_entry ( path_to_json , entry , key = None , subkey = None , subsubkey = None , subsubsubkey = None ) -> None : \"\"\"Adds an entry to a JSON file at the specified level defined by the given keys. Args: path_to_json (str): The path to the JSON file to that the entry should be added. entry (str/int/list/dict): The entry that should be added. key (str, optional): The first level key of the JSON. Defaults to None. subkey (str, optional): The second level key of the JSON. Defaults to None. subsubkey (str, optional): The third level key of the JSON. Defaults to None. subsubsubkey (str, optional): The fourth level key of the JSON. Defaults to None. \"\"\" condition = sum ( arg is not None for arg in [ key , subkey , subsubkey , subsubsubkey ]) with open ( f ' { path_to_json } ' , 'r+' , encoding = 'utf-8' ) as f : j_file = json . load ( f ) if condition == 1 : j_file [ key ] = entry elif condition == 2 : if key not in j_file : j_file [ key ] = {} j_file [ key ][ subkey ] = entry elif condition == 3 : if key not in j_file : j_file [ key ] = {} if subkey not in j_file [ key ]: j_file [ key ][ subkey ] = {} j_file [ key ][ subkey ][ subsubkey ] = entry elif condition == 4 : if key not in j_file : j_file [ key ] = {} if subkey not in j_file [ key ]: j_file [ key ][ subkey ] = {} if subsubkey not in j_file [ key ][ subkey ]: j_file [ key ][ subkey ][ subsubkey ] = {} j_file [ key ][ subkey ][ subsubkey ][ subsubsubkey ] = entry f . seek ( 0 ) json . dump ( j_file , f , ensure_ascii = False , indent = 4 )","title":"add_json_entry()"},{"location":"utils/#mixturemm.utils.bash_arg_prepper","text":"Prepares the command line arguments for the HPC bash files. Parameters: Name Type Description Default *args Variable length argument list. () Returns: Name Type Description tuple tuple Variable length tuple with the arguments prepared to be able to be read by the bash interpreter. Source code in mixturemm/utils.py 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 def bash_arg_prepper ( * args ) -> tuple : \"\"\"Prepares the command line arguments for the HPC bash files. Args: *args: Variable length argument list. Returns: tuple: Variable length tuple with the arguments prepared to be able to be read by the bash interpreter. \"\"\" result_list = [] for arg in args : if type ( arg ) is list : if any ( isinstance ( x , ( int , float )) for x in arg ): list_with_strings = [ str ( x ) for x in arg ] joined_arg = ',' . join ( list_with_strings ) result_list . append ( joined_arg ) else : joined_arg = ',' . join ( arg ) result_list . append ( joined_arg ) elif type ( arg ) is dict : joined_arg = ',' . join ([ f ' { key } = { value } ' for key , value in arg . items ()]) result_list . append ( joined_arg ) else : result_list . append ( str ( arg )) return tuple ( result_list ) if len ( result_list ) > 1 else result_list [ 0 ]","title":"bash_arg_prepper()"},{"location":"utils/#mixturemm.utils.directory_maker","text":"A function that creates directories. Parameters: Name Type Description Default path str Path to the directory that should be created. required Source code in mixturemm/utils.py 32 33 34 35 36 37 38 39 40 41 def directory_maker ( path ) -> str : \"\"\"A function that creates directories. Args: path (str): Path to the directory that should be created. \"\"\" if not os . path . exists ( path ): os . makedirs ( path ) return path","title":"directory_maker()"},{"location":"utils/#mixturemm.utils.hpc_submission_header","text":"Writes the header of a hpc submission script. Parameters: Name Type Description Default file_name str The name of the hpc submission script. required process_name str The process name that the queued job should get. required hpc_workspace str The path to the hpc workspace. required environment_name str The name of the anaconda environment containing the dependencies. required scheduler str The queue scheduler. required partition str The partition the job should be submitted to. required number_of_threads int The number of requested threads. required number_of_gpus int The number of GPUs requested on a node. required max_runtime_hh_mm_ss str Maximum runtime for a job. required conda_module bool Adapts the header to whether there is a conda module available on the hpc or not. required Source code in mixturemm/utils.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def hpc_submission_header ( file_name , process_name , hpc_workspace , environment_name , scheduler , partition , number_of_threads , number_of_gpus , max_runtime_hh_mm_ss , conda_module ) -> None : \"\"\"Writes the header of a hpc submission script. Args: file_name (str): The name of the hpc submission script. process_name (str): The process name that the queued job should get. hpc_workspace (str): The path to the hpc workspace. environment_name (str): The name of the anaconda environment containing the dependencies. scheduler (str): The queue scheduler. partition (str): The partition the job should be submitted to. number_of_threads (int): The number of requested threads. number_of_gpus (int): The number of GPUs requested on a node. max_runtime_hh_mm_ss (str): Maximum runtime for a job. conda_module (bool): Adapts the header to whether there is a conda module available on the hpc or not. \"\"\" with open ( f ' { file_name } ' , 'w' , newline = ' \\n ' ) as file : file . write ( f '''#!/bin/bash # { scheduler } -J { process_name } ''' ) if partition == 'accelerated' : file . write ( f '''# { scheduler } --gres=gpu: { number_of_gpus } ''' ) file . write ( f '''# { scheduler } --ntasks= { number_of_threads } # { scheduler } --time= { max_runtime_hh_mm_ss } # { scheduler } --partition= { partition } ''' ) if not conda_module : file . write ( f '''set +eu module purge module load compiler/pgi/2020 module load devel/cuda/11.0 source { hpc_workspace } /conda/etc/profile.d/conda.sh eval \"$(conda shell.bash hook)\" conda activate { environment_name } set -eu ''' ) if conda_module : file . write ( f '''set +eu module purge module load compiler/pgi/2020 module load devel/cuda/11.0 module load devel/miniconda eval \"$(conda shell.bash hook)\" conda activate { environment_name } set -eu ''' ) file . write ( f '''echo \"-----------------------------------------------------------------------\" echo { process_name } echo $(date -u) \"Job was started\" echo \"-----------------------------------------------------------------------\" ''' )","title":"hpc_submission_header()"},{"location":"utils/#mixturemm.utils.jsonize_forcefield","text":"Creates the JSON structure of the force field by putting project attributes in a dictionary. Parameters: Name Type Description Default Forcefield obj Contains information on the force field. required Returns: Name Type Description dict dict The JSON structure of the project description. Source code in mixturemm/utils.py 268 269 270 271 272 273 274 275 276 277 278 279 280 def jsonize_forcefield ( Forcefield ) -> dict : \"\"\"Creates the JSON structure of the force field by putting project attributes in a dictionary. Args: Forcefield (obj): Contains information on the force field. Returns: dict: The JSON structure of the project description. \"\"\" json_structure = { 'built_in' : Forcefield . built_in , 'added_elements' : Forcefield . elements } return json_structure","title":"jsonize_forcefield()"},{"location":"utils/#mixturemm.utils.jsonize_molecule","text":"Creates the JSON structure of the molecule by putting project attributes in a dictionary. Parameters: Name Type Description Default Molecule obj Contains information on the molecule that is used for packing with packmol and to identify it. required Returns: Name Type Description dict dict The JSON structure of the project description. Source code in mixturemm/utils.py 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 def jsonize_molecule ( Molecule ) -> dict : \"\"\"Creates the JSON structure of the molecule by putting project attributes in a dictionary. Args: Molecule (obj): Contains information on the molecule that is used for packing with packmol and to identify it. Returns: dict: The JSON structure of the project description. \"\"\" json_structure = { 'number_of_atoms' : Molecule . number_of_atoms , 'abbreviation' : Molecule . abbreviation , 'smiles_code' : Molecule . smiles , 'inchi_key' : Molecule . inchi , 'molar_mass' : Molecule . molar_mass , 'used_as_water' : Molecule . use_as_water } return json_structure","title":"jsonize_molecule()"},{"location":"utils/#mixturemm.utils.jsonize_project","text":"Creates the JSON structure of the project by putting project attributes in a dictionary. Parameters: Name Type Description Default Project obj The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. required Returns: Name Type Description dict dict The JSON structure of the project description. Source code in mixturemm/utils.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def jsonize_project ( Project ) -> dict : \"\"\"Creates the JSON structure of the project by putting project attributes in a dictionary. Args: Project (obj): The project holds all parameters and functions to do a complete systematic simulation of different systems in openmm. Returns: dict: The JSON structure of the project description. \"\"\" json_structure = { 'workflow_info' : { 'general' : { 'package_name' : 'mixturemm' , 'simulation_engine' : 'OpenMM' , 'analysis_package' : 'MDAnalysis' }, 'simulation' : { 'ensemble_order' : '---(slow heating)---> |NpT| ---(rescale boxes and assign velocities)---> |NVT| ------> |NVE|' , 'pressure_and_temperature_control' : { 'NpT' : 'Langevin thermostat, Monte Carlo barostat' , 'NVT' : 'Langevin thermostat' , 'NVE' : 'no pressure and temperature control' }, 'constraints' : 'hydrogen bonds' , 'nonbonded forces algorithm' : 'particle mesh ewald' }}, 'project' : { 'simulation_parameters' : { 'total_number_of_molecules' : Project . total_number_molecules , 'initial_box_side_lengths' : Project . init_box_side_length , 'water_mole_fractions' : Project . chi_water_s , 'temperature_s_in_kelvin' : Project . temperature_s , 'pressure_s_in_bar' : Project . npt_equilibration_pressure_s , 'number_of_replicas' : Project . replica_count }, 'hardware_settings' : { 'platform' : Project . simulation_platform , 'properties' : Project . simulation_properties }, 'simulation_settings' : { 'pme_error_tolerance' : Project . pme_error_tolerance , 'constraint_tolerance' : Project . constraint_tolerance , 'cutoff_distance_in_nm' : Project . cutoff_distance_nm , 'switching_function_starting_distance_in_nm' : Project . cutoff_switch_distance_nm }, 'npt_equilibration' : { 'pressure_coupling_frequency' : Project . npt_equilibration_pressure_coupling_frequency , 'temperature_coupling_frequency' : Project . npt_equilibration_temperature_coupling_frequency , 'timestep_in_fs' : Project . npt_equilibration_timestep_fs , 'duration_in_ns' : Project . npt_equilibration_duration_ns , 'state_data_reporting_frequency' : Project . reporting_frequency_state_npt_equilibration }, 'nvt_equilibration' : { 'temperature_coupling_frequency' : Project . nvt_equilibration_temperature_coupling_frequency , 'timestep_in_fs' : Project . nvt_equilibration_timestep_fs , 'duration_in_ns' : Project . nvt_equilibration_duration_ns , 'state_data_reporting_frequency' : Project . reporting_frequency_state_nvt_equilibration }, 'nve_production' : { 'timestep_in_fs' : Project . nve_production_timestep_fs , 'duration_in_ns' : Project . nve_production_duration_ns , 'state_data_reporting_frequency' : Project . reporting_frequency_state_nve_production , 'unwrapped_trajectory_reporting_frequency' : Project . reporting_frequency_coordinates_unwrapped , 'wrapped_trajectory_reporting_frequency' : Project . reporting_frequency_coordinates_wrapped }}} return json_structure","title":"jsonize_project()"},{"location":"utils/#mixturemm.utils.merge_project_descriptions","text":"Merges two project descriptions Parameters: Name Type Description Default path_to_old_description str The path to the already existent project description. required new_json_structure dict The newly created json structure that should be merged with the existent one. required Source code in mixturemm/utils.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 def merge_project_descriptions ( path_to_old_description , new_json_structure ) -> None : \"\"\"Merges two project descriptions Args: path_to_old_description (str): The path to the already existent project description. new_json_structure (dict): The newly created json structure that should be merged with the existent one. \"\"\" with open ( f ' { path_to_old_description } ' , 'r+' , encoding = 'utf-8' ) as f : json_base = json . load ( f ) for key , value in json_base [ 'project' ] . items (): if key in new_json_structure [ 'project' ]: for inner_key , inner_value in value . items (): if inner_key in new_json_structure [ 'project' ][ f ' { key } ' ]: if type ( inner_value ) is not list : if inner_value != new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ]: old = inner_value new = new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] json_base [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] = [ old , new ] else : if type ( new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ]) is not list : if new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] not in inner_value : json_base [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] . append ( new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ]) else : inner_value . extend ( x for x in new_json_structure [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] if x not in inner_value ) json_base [ 'project' ][ f ' { key } ' ][ f ' { inner_key } ' ] = inner_value f . seek ( 0 ) json . dump ( json_base , f , ensure_ascii = False , indent = 4 )","title":"merge_project_descriptions()"},{"location":"utils/#mixturemm.utils.msd_opt_prepper","text":"Prepares the options for the MSD Analysis on the hpc. Parameters: Name Type Description Default nve_production_timestep_fs int The integration time step during the NVE production in femtoseconds. required nve_production_duration_ns int The duration of the NVE production in nanoseconds. required reporting_frequency_coordinates_unwrapped int The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. required fit_starting_percentage int Start of the linear fit in percent of NVE production duration. required fit_ending_percentage int Ending of the linear fit in percent of NVE production duration. required Returns: Name Type Description tuple tuple The options for the MSD Analysis on the hpc, fit_starting_frame, fit_ending_frame and time_between_frames. Source code in mixturemm/utils.py 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 def msd_opt_prepper ( nve_production_timestep_fs , nve_production_duration_ns , reporting_frequency_coordinates_unwrapped , fit_starting_percentage , fit_ending_percentage ) -> tuple : \"\"\"Prepares the options for the MSD Analysis on the hpc. Args: nve_production_timestep_fs (int): The integration time step during the NVE production in femtoseconds. nve_production_duration_ns (int): The duration of the NVE production in nanoseconds. reporting_frequency_coordinates_unwrapped (int): The reporting frequency of the trajectory with unwrapped coordinates in simulation steps during the NVE production. fit_starting_percentage (int): Start of the linear fit in percent of NVE production duration. fit_ending_percentage (int): Ending of the linear fit in percent of NVE production duration. Returns: tuple: The options for the MSD Analysis on the hpc, fit_starting_frame, fit_ending_frame and time_between_frames. \"\"\" time_between_frames = nve_production_timestep_fs * ( 10 ** ( - 3 )) * reporting_frequency_coordinates_unwrapped conversion_factor_ps_to_frame = 1 / time_between_frames fit_starting_dec = fit_starting_percentage * ( 1 / 100 ) fit_ending_dec = fit_ending_percentage * ( 1 / 100 ) fit_starting_frame = int ( fit_starting_dec * nve_production_duration_ns * ( 10 ** 3 ) * conversion_factor_ps_to_frame ) fit_ending_frame = int ( fit_ending_dec * nve_production_duration_ns * ( 10 ** 3 ) * conversion_factor_ps_to_frame ) return fit_starting_frame , fit_ending_frame , time_between_frames","title":"msd_opt_prepper()"}]}